"""
Orchestrator - åè°ƒå™¨
ç®¡ç†Talkerå’ŒThinkerçš„ååŒå·¥ä½œ
"""
import asyncio
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from config import settings
from context.types import AgentRole, HandoffType, Message, ResponseLayer, Task, TaskComplexity
from context.session_context import SessionContext
from context.shared_context import SharedContext, ClarificationStatus
from context.summarizer import ConversationSummarizer
from agents.talker.agent import TalkerAgent
from agents.thinker.agent import ThinkerAgent
from orchestrator.scheduler import TaskScheduler, ComplexityBasedScheduler
from skills.engine import SkillsEngine
from skills.invoker import SkillInvoker
from skills.examples import (
    WeatherSkill,
    SearchSkill,
    KnowledgeSearchSkill,
    CalculatorSkill,
    UnitConverterSkill,
)


class ThinkerStage(Enum):
    """Thinkerå¤„ç†é˜¶æ®µ"""
    IDLE = "idle"
    ANALYZING = "analyzing"      # æ€è€ƒ/åˆ†æ
    PLANNING = "planning"        # è§„åˆ’
    EXECUTING = "executing"      # æ‰§è¡Œæ­¥éª¤
    SYNTHESIZING = "synthesizing"  # æ•´åˆ/ç”Ÿæˆç­”æ¡ˆ
    COMPLETED = "completed"


@dataclass
class ProgressState:
    """è¿›åº¦çŠ¶æ€è·Ÿè¸ª"""
    current_stage: ThinkerStage = ThinkerStage.IDLE
    last_stage_change: float = 0
    last_broadcast: float = 0
    last_broadcast_msg_template: str = ""  # æ¶ˆæ¯æ¨¡æ¿ï¼ˆä¸å«æ—¶é—´ï¼‰
    broadcast_count: int = 0
    current_step: int = 0
    total_steps: int = 0
    step_description: str = ""
    broadcast_history: set = field(default_factory=set)
    last_content_hash: str = ""
    used_message_templates: Dict[str, set] = field(default_factory=dict)  # æŒ‰é˜¶æ®µè®°å½•å·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿


@dataclass
class HandoffContext:
    """Handoffä¸Šä¸‹æ–‡"""
    handoff_type: HandoffType
    from_agent: str
    to_agent: str
    reason: str
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)


class Orchestrator:
    """
    Orchestrator - åè°ƒå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. ä»»åŠ¡è°ƒåº¦å’Œè·¯ç”±
    2. Agentä¹‹é—´çš„Handoffç®¡ç†
    3. ä¸Šä¸‹æ–‡åŒæ­¥
    4. çŠ¶æ€ç»´æŠ¤
    """

    def __init__(
        self,
        talker: Optional[TalkerAgent] = None,
        thinker: Optional[ThinkerAgent] = None,
        task_scheduler: Optional[TaskScheduler] = None,
        session_context: Optional[SessionContext] = None,
        skills_engine: Optional[SkillsEngine] = None,
        summarizer: Optional[ConversationSummarizer] = None,
    ):
        # Agentå®ä¾‹
        self.talker = talker or TalkerAgent()
        self.thinker = thinker or ThinkerAgent()

        # è°ƒåº¦å™¨
        self.task_scheduler = task_scheduler or TaskScheduler()
        self.complexity_scheduler = ComplexityBasedScheduler()

        # ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒRedisæŒä¹…åŒ–ï¼Œä¸å¯ç”¨æ—¶é™çº§åˆ°å†…å­˜ï¼‰
        self.session_context = session_context or SessionContext()

        # å…±äº«ä¸Šä¸‹æ–‡ï¼ˆTalkerå’ŒThinkerä¹‹é—´å…±äº«ï¼‰
        self._shared_contexts: Dict[str, SharedContext] = {}

        # Skillså¼•æ“å’Œè°ƒç”¨å™¨
        self.skills_engine = skills_engine or SkillsEngine()
        self.skill_invoker = SkillInvoker(self.skills_engine)
        self._initialize_default_skills()

        # å°†SkillInvokeræ³¨å…¥åˆ°Thinker
        self.thinker.set_skill_invoker(self.skill_invoker)

        # å¯¹è¯æ‘˜è¦å™¨ï¼ˆç”¨äºé•¿å¯¹è¯å‹ç¼©ï¼‰
        self.summarizer = summarizer or ConversationSummarizer(
            summary_threshold=settings.SUMMARY_THRESHOLD
        )

        # Handoffå†å²
        self._handoff_history: List[HandoffContext] = []

        # å›è°ƒå‡½æ•°
        self._on_response: Optional[Callable] = None
        self._on_handoff: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None

        # è®¾ç½®è¿›åº¦å›è°ƒ
        self.talker.set_progress_callback(self._handle_progress)
        self.thinker.set_progress_callback(self._handle_progress)

        # ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self._precheck_timeout_s = 15.0

        # è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()

    def _initialize_default_skills(self) -> None:
        """åˆå§‹åŒ–é»˜è®¤æŠ€èƒ½"""
        default_skills = [
            WeatherSkill(),
            SearchSkill(),
            KnowledgeSearchSkill(),
            CalculatorSkill(),
            UnitConverterSkill(),
        ]
        for skill in default_skills:
            self.skills_engine.register_skill(skill)

    def _parse_thinker_stage(self, output: str) -> tuple[ThinkerStage, int, int, str]:
        """
        è§£æThinkerè¾“å‡ºï¼Œè¯†åˆ«å½“å‰é˜¶æ®µ

        Returns:
            tuple: (é˜¶æ®µ, å½“å‰æ­¥éª¤, æ€»æ­¥éª¤, æ­¥éª¤æè¿°)
        """
        stage = self._progress_state.current_stage
        current_step = self._progress_state.current_step
        total_steps = self._progress_state.total_steps
        step_desc = ""

        # æ£€æµ‹é˜¶æ®µå˜åŒ–
        if "[æ€è€ƒ]" in output or "æ­£åœ¨åˆ†æ" in output:
            stage = ThinkerStage.ANALYZING
        elif "[è§„åˆ’]" in output:
            stage = ThinkerStage.PLANNING
            # å°è¯•è§£ææ€»æ­¥éª¤æ•°
            steps_match = re.search(r"å…±(\d+)ä¸ªæ­¥éª¤", output)
            if steps_match:
                total_steps = int(steps_match.group(1))
        elif "[æ­¥éª¤" in output:
            stage = ThinkerStage.EXECUTING
            # è§£ææ­¥éª¤ä¿¡æ¯
            step_match = re.search(r"\[æ­¥éª¤(\d+)\]", output)
            if step_match:
                current_step = int(step_match.group(1))
            # è§£ææ­¥éª¤æè¿°
            desc_match = re.search(r"\[æ­¥éª¤\d+\]\s*(.+?)(?:\n|$)", output)
            if desc_match:
                step_desc = desc_match.group(1).strip()
        elif "[æ€è€ƒ] æ•´åˆ" in output or "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ" in output:
            stage = ThinkerStage.SYNTHESIZING
        elif "[ç­”æ¡ˆ]" in output:
            stage = ThinkerStage.COMPLETED

        return stage, current_step, total_steps, step_desc

    def _stage_from_shared_progress(self, stage_name: str) -> ThinkerStage:
        """å°†SharedContextä¸­çš„é˜¶æ®µåæ˜ å°„ä¸ºThinkerStageã€‚"""
        mapping = {
            "idle": ThinkerStage.IDLE,
            "analyzing": ThinkerStage.ANALYZING,
            "planning": ThinkerStage.PLANNING,
            "executing": ThinkerStage.EXECUTING,
            "synthesizing": ThinkerStage.SYNTHESIZING,
            "completed": ThinkerStage.COMPLETED,
        }
        return mapping.get((stage_name or "").lower(), ThinkerStage.IDLE)

    def _latest_shared_step_desc(self, shared: Optional[SharedContext]) -> str:
        """ä»SharedContextæå–æœ€è¿‘çš„Thinkeré˜¶æ®µè¯´æ˜ã€‚"""
        if not shared:
            return ""
        partials = shared.thinker_progress.partial_results
        if not partials:
            return ""
        desc = (partials[-1] or "").strip()
        return desc[:30]

    def _generate_stage_broadcast(
        self,
        stage: ThinkerStage,
        user_query: str,
        elapsed_time: float,
        current_step: int = 0,
        total_steps: int = 0,
        step_desc: str = "",
    ) -> tuple[str, str]:
        """
        æ ¹æ®é˜¶æ®µç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯

        Returns:
            tuple: (å®Œæ•´æ¶ˆæ¯, æ¶ˆæ¯æ¨¡æ¿)
            æ¶ˆæ¯æ¨¡æ¿ç”¨äºå»é‡ï¼Œä¸å«æ—¶é—´æˆ³
        """
        # æå–ä¸»é¢˜
        topic = self._extract_topic(user_query)
        stage_key = stage.value

        # è·å–è¯¥é˜¶æ®µå·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿é›†åˆ
        if stage_key not in self._progress_state.used_message_templates:
            self._progress_state.used_message_templates[stage_key] = set()

        used_templates = self._progress_state.used_message_templates[stage_key]

        # æ ¹æ®å·²è€—æ—¶é€‰æ‹©æ’­æŠ¥é£æ ¼
        if elapsed_time < 10:
            style = "initial"
        elif elapsed_time < 30:
            style = "progress"
        else:
            style = "long_wait"

        def get_unused_template(templates: list, used_set: set) -> str:
            """ä»æœªä½¿ç”¨çš„æ¨¡æ¿ä¸­é€‰æ‹©ä¸€ä¸ª"""
            for t in templates:
                if t not in used_set:
                    used_set.add(t)
                    return t
            # æ‰€æœ‰æ¨¡æ¿éƒ½ç”¨è¿‡äº†ï¼Œè¿”å›é»˜è®¤
            return templates[0]

        if stage == ThinkerStage.IDLE:
            if style == "initial":
                templates = [
                    "Thinkerå·²æ¥æ‰‹ï¼Œæ­£åœ¨åŠ è½½ä¸Šä¸‹æ–‡",
                    "æ­£åœ¨å‡†å¤‡åˆ†æç¯å¢ƒ",
                    "æ­£åœ¨åŒæ­¥ä»»åŠ¡ä¿¡æ¯",
                ]
            elif style == "progress":
                templates = [
                    "ä»åœ¨å‡†å¤‡åˆ†æï¼Œè¯·ç¨å€™",
                    "å³å°†å¼€å§‹æ·±åº¦åˆ†æ",
                ]
            else:
                templates = ["å‡†å¤‡å·¥ä½œè¿›è¡Œä¸­"]

            template = get_unused_template(templates, used_templates)
            if template == "å‡†å¤‡å·¥ä½œè¿›è¡Œä¸­":
                return f"{template} ({elapsed_time:.0f}s)...", template
            return f"{template}...", template

        if stage == ThinkerStage.ANALYZING:
            if style == "initial":
                templates = [
                    f"æ­£åœ¨ç†è§£æ‚¨å…³äºã€Œ{topic}ã€çš„éœ€æ±‚",
                    "æ­£åœ¨åˆ†æé—®é¢˜å…³é”®ç‚¹",
                    f"æ¢³ç†ã€Œ{topic}ã€ç›¸å…³ä¿¡æ¯",
                ]
            elif style == "progress":
                templates = [
                    "æ·±åº¦åˆ†æä¸­ï¼Œè¯·ç¨å€™",
                    "æ­£åœ¨æå–å…³é”®è¦ç´ ",
                ]
            else:
                # é•¿æ—¶é—´ç­‰å¾…ï¼Œæ˜¾ç¤ºå·²ç”¨æ—¶é—´
                templates = ["åˆ†æè¿›è¡Œä¸­"]  # ä¸å«æ—¶é—´ï¼Œæ—¶é—´å•ç‹¬æ˜¾ç¤º

            template = get_unused_template(templates, used_templates)
            # å¦‚æœæ˜¯"åˆ†æè¿›è¡Œä¸­"ï¼ŒåŠ ä¸Šæ—¶é—´
            if template == "åˆ†æè¿›è¡Œä¸­":
                return f"{template} ({elapsed_time:.0f}s)...", template
            return f"{template}...", template

        elif stage == ThinkerStage.PLANNING:
            if style == "initial":
                templates = [
                    f"å·²ç†è§£éœ€æ±‚ï¼Œæ­£åœ¨åˆ¶å®š{topic}æ–¹æ¡ˆ",
                    "è§„åˆ’æœ€ä¼˜è§£å†³è·¯å¾„",
                ]
            elif style == "progress":
                templates = [
                    "æ–¹æ¡ˆè®¾è®¡ä¸­",
                    "æ­£åœ¨åˆ†è§£ä»»åŠ¡æ­¥éª¤",
                ]
            else:
                templates = ["è§„åˆ’ä¸­"]

            template = get_unused_template(templates, used_templates)
            return f"{template}...", template

        elif stage == ThinkerStage.EXECUTING:
            if total_steps > 0 and current_step > 0:
                progress_pct = int((current_step / total_steps) * 100)
                if step_desc:
                    short_desc = step_desc[:15] + "..." if len(step_desc) > 15 else step_desc
                    msg = f"ç¬¬{current_step}/{total_steps}æ­¥: {short_desc} ({progress_pct}%)"
                    template = f"ç¬¬{current_step}/{total_steps}æ­¥"
                    return msg, template
                msg = f"æ‰§è¡Œä¸­: {current_step}/{total_steps} æ­¥ ({progress_pct}%)"
                template = f"ç¬¬{current_step}/{total_steps}æ­¥"
                return msg, template
            templates = [
                "æ­£åœ¨å¤„ç†æ ¸å¿ƒä»»åŠ¡",
                "æ‰§è¡Œå…³é”®æ­¥éª¤",
            ]
            template = get_unused_template(templates, used_templates)
            return f"{template}...", template

        elif stage == ThinkerStage.SYNTHESIZING:
            templates = [
                "æ­£åœ¨æ•´åˆåˆ†æç»“æœ",
                "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¸­",
                "å³å°†å®Œæˆï¼Œè¯·ç¨å€™",
                "æ•´ç†è¾“å‡ºå†…å®¹",
            ]
            template = get_unused_template(templates, used_templates)
            return f"{template}...", template

        elif stage == ThinkerStage.COMPLETED:
            return "å¤„ç†å®Œæˆï¼", "å¤„ç†å®Œæˆ"

        # é»˜è®¤æ¶ˆæ¯
        return f"å¤„ç†ä¸­ ({elapsed_time:.0f}s)...", "å¤„ç†ä¸­"

    def _extract_topic(self, query: str) -> str:
        """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–ä¸»é¢˜"""
        query_lower = query.lower()

        topic_keywords = {
            "é€‰è½¦": ["è½¦", "æ±½è½¦", "è½¦å‹", "å“ç‰Œ", "suv", "è½¿è½¦", "ä¹°è½¦", "é€‰è½¦"],
            "æ—…æ¸¸": ["æ—…æ¸¸", "æ—…è¡Œ", "æ™¯ç‚¹", "é…’åº—", "æœºç¥¨", "å»å“ª"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "é¤å…", "èœ", "åƒ", "æ¨èèœ"],
            "è´­ç‰©": ["ä¹°", "è´­ç‰©", "ä»·æ ¼", "ä¾¿å®œ", "å¯¹æ¯”"],
            "å’–å•¡": ["å’–å•¡", "æ‹¿é“", "æ˜Ÿå·´å…‹", "ç‘å¹¸"],
            "æ‰“è½¦": ["æ‰“è½¦", "æ»´æ»´", "é«˜å¾·", "ä¸“è½¦", "å¿«è½¦"],
        }

        for topic, keywords in topic_keywords.items():
            if any(kw in query_lower for kw in keywords):
                return topic

        # æå–é—®é¢˜ä¸­çš„å…³é”®è¯ä½œä¸ºä¸»é¢˜
        words = re.findall(r'[\u4e00-\u9fa5]{2,4}', query)
        if words:
            return words[0]
        return "æ‚¨çš„é—®é¢˜"

    def _extract_user_preferences(self, text: str) -> Dict[str, Any]:
        """ä»è¾“å…¥ä¸­æå–å¯æŒä¹…åŒ–çš„ç”¨æˆ·åå¥½ï¼ˆé€šç”¨å»ºæ¨¡ï¼Œä¸å¼ºç»‘å®šå…·ä½“åœºæ™¯ï¼‰ã€‚"""
        text = (text or "").lower().strip()
        prefs: Dict[str, Any] = {}
        likes: List[str] = []
        dislikes: List[str] = []
        constraints: List[str] = []

        for pat in [r"æˆ‘å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"åå¥½([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"æ›´å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            likes.extend([m.strip() for m in re.findall(pat, text) if m.strip()])
        for pat in [r"æˆ‘ä¸å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"ä¸è¦([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"é¿å…([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            dislikes.extend([m.strip() for m in re.findall(pat, text) if m.strip()])
        for pat in [r"å¸Œæœ›([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"æœ€å¥½([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"éœ€è¦([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            constraints.extend([m.strip() for m in re.findall(pat, text) if m.strip()])

        if likes:
            prefs["likes"] = list(dict.fromkeys(likes))
        if dislikes:
            prefs["dislikes"] = list(dict.fromkeys(dislikes))
        if constraints:
            prefs["constraints"] = list(dict.fromkeys(constraints))

        # å…¼å®¹æ—¢æœ‰é«˜é¢‘åå¥½å­—æ®µ
        if any(k in text for k in ["å–œæ¬¢åƒè¾£", "çˆ±åƒè¾£", "èƒ½åƒè¾£", "å£å‘³é‡"]):
            prefs["taste"] = "å–œæ¬¢åƒè¾£"
        elif any(k in text for k in ["ä¸åƒè¾£", "ä¸èƒ½åƒè¾£", "æ¸…æ·¡"]):
            prefs["taste"] = "åæ¸…æ·¡/ä¸åƒè¾£"

        budget_match = re.search(r"(\d{1,3})\s*ä¸‡", text)
        if budget_match:
            prefs["budget"] = f"{budget_match.group(1)}ä¸‡"
        amount_match = re.search(r"(\d{2,6})\s*(å…ƒ|å—)", text)
        if amount_match and "budget" not in prefs:
            prefs["budget"] = f"{amount_match.group(1)}{amount_match.group(2)}"

        if "suv" in text or "è¶Šé‡" in text:
            prefs["car_type"] = "åå¥½SUV"
        elif "è½¿è½¦" in text:
            prefs["car_type"] = "åå¥½è½¿è½¦"
        return prefs

    def _merge_user_preferences(self, base: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶åå¥½ï¼šåˆ—è¡¨å»é‡å¹¶ä¿åºï¼Œå­—å…¸é€’å½’åˆå¹¶ï¼Œæ ‡é‡è¦†ç›–ã€‚"""
        merged: Dict[str, Any] = dict(base or {})
        for k, v in (new or {}).items():
            if k not in merged:
                merged[k] = v
                continue
            old = merged[k]
            if isinstance(old, list) and isinstance(v, list):
                merged[k] = list(dict.fromkeys([*old, *v]))
            elif isinstance(old, dict) and isinstance(v, dict):
                merged[k] = {**old, **v}
            else:
                merged[k] = v
        return merged

    async def persist_user_preferences(self, text: str) -> Dict[str, Any]:
        """æå–å¹¶æŒä¹…åŒ–ç”¨æˆ·åå¥½ï¼Œè¿”å›æœ€æ–°åå¥½ã€‚"""
        global_pref_sid = "__global_user__"
        persisted_prefs = await self.session_context.get_session_data(
            global_pref_sid, "user_preferences", {}
        ) or {}
        extracted_prefs = self._extract_user_preferences(text)
        if extracted_prefs:
            persisted_prefs = self._merge_user_preferences(persisted_prefs, extracted_prefs)
            await self.session_context.set_session_data(
                global_pref_sid, "user_preferences", persisted_prefs, ttl=86400 * 30
            )
        return persisted_prefs

    def _should_broadcast(
        self,
        new_stage: ThinkerStage,
        current_step: int,
        elapsed_time: float,
        content_hash: str,
        force_check: bool = False,
    ) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ’­æŠ¥

        Args:
            new_stage: å½“å‰é˜¶æ®µ
            current_step: å½“å‰æ­¥éª¤
            elapsed_time: å·²è€—æ—¶
            force_check: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥ï¼ˆå¿½ç•¥æœ€å°é—´éš”ï¼‰

        Returns:
            tuple: (æ˜¯å¦æ’­æŠ¥, åŸå› )
        """
        state = self._progress_state
        current_time = time.time()

        # é˜¶æ®µå˜åŒ–ï¼Œç«‹å³æ’­æŠ¥
        if new_stage != state.current_stage:
            return True, "stage_changed"

        # æ­¥éª¤å˜åŒ–ï¼ˆæ‰§è¡Œé˜¶æ®µï¼‰
        if new_stage == ThinkerStage.EXECUTING and current_step != state.current_step and current_step > 0:
            return True, "step_changed"

        # æ— è¿›åº¦å˜åŒ–æ—¶ï¼Œé™ä½æ’­æŠ¥é¢‘ç‡ï¼ˆä»…ä¿ç•™å¿ƒè·³æ’­æŠ¥ï¼‰
        if content_hash == state.last_content_hash:
            if current_time - state.last_broadcast < 15:
                return False, "no_progress"
            return True, "heartbeat"

        # æ£€æŸ¥è¯¥é˜¶æ®µå·²ä½¿ç”¨çš„æ¨¡æ¿æ•°é‡
        stage_key = new_stage.value
        template_count = len(state.used_message_templates.get(stage_key, set()))
        max_templates_per_stage = 4  # æ¯é˜¶æ®µæœ€å¤š4æ¡ä¸åŒæ¶ˆæ¯

        if template_count >= max_templates_per_stage:
            return False, "max_templates_reached"

        return True, "interval_elapsed"

    def _hash_broadcast_content(self, stage: ThinkerStage, step: int, elapsed: float) -> str:
        """ç”Ÿæˆæ’­æŠ¥å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        # ä½¿ç”¨é˜¶æ®µå’Œæ­¥éª¤çš„æ•´æ•°éƒ¨åˆ†ä½œä¸ºå“ˆå¸ŒåŸºç¡€
        elapsed_bucket = int(elapsed // 5) * 5  # æ¯5ç§’ä¸€ä¸ªæ¡¶
        return f"{stage.value}_{step}_{elapsed_bucket}"

    def set_callbacks(
        self,
        on_response: Optional[Callable] = None,
        on_handoff: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
    ) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_response = on_response
        self._on_handoff = on_handoff
        self._on_progress = on_progress

    async def process(
        self,
        user_input: str,
        session_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        received_time: Optional[float] = None,
    ) -> AsyncIterator[str]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡
            received_time: æ¶ˆæ¯æ¥æ”¶æ—¶é—´

        Yields:
            str: å“åº”å†…å®¹
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        if received_time is None:
            received_time = start_time

        # åˆå§‹åŒ–ä¼šè¯
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())

        # ä½¿ç”¨SessionContextè·å–ä¼šè¯ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        session = await self._get_or_create_session(session_id)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°SessionContext
        user_message = Message(
            role="user",
            content=user_input,
            timestamp=time.time(),
        )
        await self.session_context.add_message(session_id, user_message)

        # åˆ›å»º/è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = self._get_or_create_shared_context(session_id)
        persisted_prefs = await self.persist_user_preferences(user_input)
        shared.user_preferences = persisted_prefs
        if not shared.needs_clarification():
            shared.user_input = user_input
            shared.clarified_intent = user_input
        shared.is_processing = True

        effective_input = user_input

        # === æ£€æŸ¥æ˜¯å¦æ˜¯å›ç­”æ¾„æ¸…é—®é¢˜ ===
        if shared.needs_clarification():
            # ç”¨æˆ·å¯èƒ½æ˜¯åœ¨å›ç­”æ¾„æ¸…é—®é¢˜
            pending = shared.get_pending_clarification()
            if pending:
                # è®°å½•å›ç­”
                shared.answer_clarification(user_input)
                # æ›´æ–°æ„å›¾
                shared.update_intent_with_clarification(user_input)
                effective_input = shared.clarified_intent or shared.user_input or user_input

                # ç»™ç”¨æˆ·ç¡®è®¤åé¦ˆ
                ts = time.strftime("%H:%M:%S", time.localtime())
                ms = int((time.time() % 1) * 1000)
                yield f"\n[{ts}.{ms:03d}] Talker: æ”¶åˆ°ï¼Œå·²æ›´æ–°æ‚¨çš„éœ€æ±‚ä¿¡æ¯"
                shared.add_talker_interaction("æ”¶åˆ°ï¼Œå·²æ›´æ–°æ‚¨çš„éœ€æ±‚ä¿¡æ¯", "clarification")

                # æ ‡è®°ä¸ºç»§ç»­å¤„ç†ï¼Œä½†ä½¿ç”¨æ›´æ–°åçš„æ„å›¾
                # å¦‚æœæ¾„æ¸…åçš„æ„å›¾è¶³å¤Ÿç®€å•ï¼Œå¯ä»¥è®©Talkerå¤„ç†
                # å¦åˆ™ç»§ç»­äº¤ç»™Thinker

        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å…±äº«ä¸Šä¸‹æ–‡å’Œæ‘˜è¦ï¼‰
        # è·å–ä¼šè¯æ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        session_summary = await self.session_context.get_summary(session_id)

        # å¦‚æœæ²¡æœ‰æ‘˜è¦ä¸”æ¶ˆæ¯è¾ƒå¤šï¼Œç”Ÿæˆæ‘˜è¦
        messages = await self.session_context.get_messages(session_id, limit=50)
        if not session_summary and len(messages) >= settings.SUMMARY_THRESHOLD:
            session_summary = await self.summarizer.summarize_recent_messages(messages)
            if session_summary:
                await self.session_context.set_summary(session_id, session_summary)

        full_context = {
            **(context or {}),
            "session_id": session_id,
            "messages": session["messages"],
            "received_time": received_time,
            "shared": shared,  # æ·»åŠ å…±äº«ä¸Šä¸‹æ–‡
            "session_summary": session_summary,  # æ·»åŠ ä¼šè¯æ‘˜è¦
            "effective_input": effective_input,
            "user_preferences": persisted_prefs,
        }

        # æ”¶é›†åŠ©æ‰‹å“åº”ç”¨äºä¿å­˜åˆ°ä¼šè¯
        assistant_response_chunks = []

        try:
            # ä½¿ç”¨Talkerè¿›è¡Œæ„å›¾åˆ†ç±»
            classification = await self.talker.classify_intent(effective_input, full_context)

            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
            if classification.complexity == TaskComplexity.COMPLEX:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨åä½œæ¨¡å¼
                self._stats["thinker_handled"] += 1
                async for chunk in self._collaboration_handoff(
                    effective_input, full_context, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk
            else:
                # ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼šTalkerå¤„ç†
                self._stats["talker_handled"] += 1
                async for chunk in self._delegation_handoff(
                    effective_input, full_context, classification, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk

        except Exception as e:
            self._stats["errors"] += 1
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            assistant_response_chunks.append(error_msg)
            yield error_msg

        finally:
            # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°ä¼šè¯ï¼ˆæ¸…ç†æ‰å…ƒæ•°æ®æ ‡è®°ï¼‰
            assistant_response = "".join(assistant_response_chunks)
            # ç§»é™¤æ—¶é—´æˆ³å’ŒAgentæ ‡è¯†ç­‰å…ƒæ•°æ®ï¼Œåªä¿ç•™å®é™…å›å¤å†…å®¹
            # ç§»é™¤ç±»ä¼¼ [HH:MM:SS.mmm] Talker: çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[\d{2}:\d{2}:\d{2}\.\d{3}\]\s*(Talker|Thinker):\s*', '', assistant_response)
            # ç§»é™¤ç±»ä¼¼ [Talker] ... çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker\][^\n]*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker\][^\n]*', '', clean_response)
            # ç§»é™¤ [Talker -> Thinker | ...] çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker[^\]]*\]\s*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker[^\]]*\]\s*', '', clean_response)
            # ç§»é™¤æ€§èƒ½æŒ‡æ ‡åŒºå—ï¼ˆåŒ…å«ğŸ“Šç¬¦å·çš„éƒ¨åˆ†ï¼‰
            clean_response = re.sub(r'\n-{10,}.*?-{10,}', '', clean_response, flags=re.DOTALL)
            # ç§»é™¤å‰©ä½™çš„æŒ‡æ ‡è¡Œ
            clean_response = re.sub(r'\n\s*ğŸ“Š[^\n]*', '', clean_response)
            clean_response = re.sub(r'\n\s*(Tokens|TTFT|TPOT|TPS|æ€»ç”Ÿæˆæ—¶å»¶|LLMè¯·æ±‚æ—¶é—´)[^\n]*', '', clean_response)
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            clean_response = re.sub(r'\n{3,}', '\n\n', clean_response)
            clean_response = clean_response.strip()

            if clean_response:
                # ä½¿ç”¨SessionContextä¿å­˜åŠ©æ‰‹å“åº”
                assistant_message = Message(
                    role="assistant",
                    content=clean_response,
                    timestamp=time.time(),
                )
                await self.session_context.add_message(session_id, assistant_message)

            # æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡çŠ¶æ€
            shared.is_processing = False

            elapsed = (time.time() - start_time) * 1000
            await self.session_context.set_session_data(session_id, "last_latency_ms", elapsed)

    async def _delegation_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        classification,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        å§”æ‰˜æ¨¡å¼Handoff

        Talkerå¤„ç†ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å§”æ‰˜ç»™Thinker
        æ”¹è¿›ï¼šç‹¬ç«‹äºTalkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        # è®°å½•LLMè¯·æ±‚å‘é€æ—¶é—´
        llm_request_time = time.time()

        # ä½¿ç”¨é˜Ÿåˆ—æ”¶é›†Talkerè¾“å‡º
        talker_queue = asyncio.Queue()
        talker_complete = False

        async def run_talker():
            """è¿è¡ŒTalkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal talker_complete
            async for chunk in self.talker.process(user_input, context):
                await talker_queue.put(chunk)
            talker_complete = True

        # å¯åŠ¨Talkerä»»åŠ¡
        talker_task = asyncio.create_task(run_talker())

        # å¤„ç†Talkerè¾“å‡º
        first_token_time = None
        first_timestamp_shown = False
        last_broadcast_time = llm_request_time
        broadcast_count = 0
        used_broadcast_templates = set()  # è¿½è¸ªå·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿

        def get_talker_broadcast_interval(elapsed: float) -> float:
            """åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš” - æ›´ä¿å®ˆ"""
            if elapsed < 15:
                return 4.0  # åˆå§‹4ç§’
            elif elapsed < 30:
                return 6.0  # ä¸­æœŸ6ç§’
            else:
                return 8.0  # åæœŸ8ç§’

        while not talker_complete or not talker_queue.empty():
            current_time = time.time()
            elapsed = current_time - llm_request_time

            # === æ’­æŠ¥æ£€æŸ¥ ===
            broadcast_interval = get_talker_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                ts = format_timestamp(current_time)

                # æ ¹æ®æ—¶é—´é€‰æ‹©æ’­æŠ¥æ¨¡æ¿
                if elapsed < 15:
                    templates = ["æ­£åœ¨å¤„ç†", "æ€è€ƒä¸­"]
                elif elapsed < 30:
                    templates = ["ä»åœ¨å¤„ç†ä¸­", "è¯·ç¨å€™"]
                else:
                    templates = ["å“åº”è¾ƒæ…¢"]  # æ¨¡æ¿ä¸å«æ—¶é—´

                # é€‰æ‹©æœªä½¿ç”¨çš„æ¨¡æ¿
                template = None
                for t in templates:
                    if t not in used_broadcast_templates:
                        template = t
                        used_broadcast_templates.add(t)
                        break

                if template is None:
                    # æ‰€æœ‰æ¨¡æ¿éƒ½ç”¨è¿‡äº†ï¼Œç”¨é»˜è®¤
                    template = "å¤„ç†ä¸­"

                # ç”Ÿæˆå®Œæ•´æ¶ˆæ¯
                if template == "å“åº”è¾ƒæ…¢":
                    msg = f"{template} ({elapsed:.0f}s)..."
                else:
                    msg = f"{template}..."

                yield f"\n[{ts}] Talker: {msg}"
                last_broadcast_time = current_time
                broadcast_count += 1

                # é™åˆ¶æœ€å¤§æ’­æŠ¥æ¬¡æ•°
                if broadcast_count >= 5:
                    break

            # å°è¯•è·å–è¾“å‡º
            try:
                chunk = await asyncio.wait_for(talker_queue.get(), timeout=0.1)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äº¤ç»™Thinker
                if "[NEEDS_THINKER]" in chunk:
                    # è®°å½•Handoff
                    self._record_handoff(
                        HandoffType.DELEGATION,
                        "talker",
                        "thinker",
                        "ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡Talkerèƒ½åŠ›",
                    )

                    # åˆ‡æ¢åˆ°åä½œæ¨¡å¼
                    async for thinker_chunk in self._collaboration_handoff(
                        user_input, context, llm_request_time, received_time=received_time
                    ):
                        yield thinker_chunk
                    return

                # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå†…å®¹çš„æ—¶é—´
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                    # åœ¨å†…å®¹å‰æ˜¾ç¤ºTalkeræ—¶é—´æˆ³
                    if settings.SHOW_AGENT_IDENTITY and not first_timestamp_shown:
                        yield f"\n[{format_timestamp(first_token_time)}] Talker: "
                        first_timestamp_shown = True

                yield chunk

            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯æ£€æŸ¥æ’­æŠ¥
                continue

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, llm_request_time, first_token_time)

    def _format_metrics(self, metrics: dict, llm_request_time: float, first_token_time: float = None) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        lines = ["-" * 50]
        lines.append("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")

        # Tokenç»Ÿè®¡
        input_tokens = metrics.get("input_tokens", 0)
        output_tokens = metrics.get("output_tokens", 0)
        if input_tokens or output_tokens:
            lines.append(f"  Tokens: è¾“å…¥={input_tokens} | è¾“å‡º={output_tokens}")

        # æ—¶å»¶æŒ‡æ ‡
        ttft = metrics.get("ttft_ms", 0)
        tpot = metrics.get("tpot_ms", 0)
        total_time = metrics.get("total_time_ms", 0)

        if ttft:
            lines.append(f"  TTFT(é¦–Tokenå“åº”æ—¶å»¶): {ttft:.0f}ms")
        if total_time:
            lines.append(f"  å“åº”æ—¶å»¶(ç”Ÿæˆæ€»è€—æ—¶): {total_time:.0f}ms")
        if tpot:
            lines.append(f"  TPOT(å¹³å‡æ¯Tokenæ—¶å»¶): {tpot:.1f}ms")

        # TPSåå
        tps = metrics.get("tps", 0)
        if tps:
            lines.append(f"  TPS(æ¨¡å‹åå): {tps:.1f} tokens/s")

        # æ—¶é—´æˆ³
        lines.append(f"  LLMè¯·æ±‚å‘é€æ—¶é—´: {format_timestamp(llm_request_time)}")
        if first_token_time:
            lines.append(f"  LLMé¦–Tokenæ—¶é—´: {format_timestamp(first_token_time)}")
        lines.append("-" * 50)

        return "\n".join(lines)

    async def _collaboration_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        llm_request_time: float = None,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        åä½œæ¨¡å¼Handoff

        Talkeræ”¶é›†ä¿¡æ¯ï¼ŒThinkeræ·±åº¦å¤„ç†ï¼ŒTalkeræ’­æŠ¥
        å…³é”®æ”¹è¿›ï¼šç‹¬ç«‹äºThinkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        thinker_start = time.time()
        if llm_request_time is None:
            llm_request_time = thinker_start

        # é‡ç½®è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()
        self._progress_state.last_stage_change = thinker_start
        self._progress_state.last_broadcast = thinker_start - 3  # å…è®¸ç«‹å³æ’­æŠ¥

        # è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = context.get("shared")

        # ç¡®ä¿Thinkeræœ‰å…±äº«ä¸Šä¸‹æ–‡çš„å¼•ç”¨
        if shared:
            self.thinker.set_shared_context(shared)

        # Talkeré¦–å…ˆç»™ç”¨æˆ·åé¦ˆ
        if settings.SHOW_AGENT_IDENTITY:
            timestamp = format_timestamp(thinker_start)
            yield f"\n[{timestamp}] Talker: å¥½çš„ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦æ·±åº¦æ€è€ƒï¼Œå·²è½¬äº¤ç»™Thinkerå¤„ç†"
            precheck_ts = format_timestamp(time.time())
            yield f"\n[{precheck_ts}] Talker: æ­£åœ¨åŒæ­¥ä¸Šä¸‹æ–‡å¹¶è§„åˆ’æ­¥éª¤ï¼Œè¯·ç¨å€™..."

        # === æ¾„æ¸…æœºåˆ¶ï¼šæ£€æµ‹æ˜¯å¦éœ€è¦æ¾„æ¸…ï¼ˆå¸¦ä¸»åŠ¨æ’­æŠ¥ï¼‰ ===
        async def run_precheck():
            quick_plan = await self.thinker.plan_task(user_input, context)
            needs_clarification, reason, missing_info = await self.thinker.needs_clarification(
                user_input, quick_plan, context
            )
            question = None
            if needs_clarification and missing_info and shared:
                question = await self.thinker.generate_clarification_question(
                    user_input, missing_info, context
                )
            return quick_plan, needs_clarification, reason, missing_info, question

        precheck_task = asyncio.create_task(run_precheck())
        precheck_last_broadcast = thinker_start
        precheck_templates = ["ä»åœ¨åˆ†æå…³é”®ä¿¡æ¯", "æ­£åœ¨æ ¸å¯¹å¿…è¦æ¡ä»¶", "å³å°†è¿›å…¥è¯¦ç»†æ¨ç†"]
        precheck_idx = 0
        last_precheck_template = ""
        precheck_timed_out = False

        while not precheck_task.done():
            now = time.time()
            if now - thinker_start >= self._precheck_timeout_s:
                precheck_timed_out = True
                precheck_task.cancel()
                ts = format_timestamp(now)
                timeout_msg = "é¢„åˆ†æè€—æ—¶è¾ƒé•¿ï¼Œå…ˆè¿›å…¥è¯¦ç»†å¤„ç†"
                yield f"\n[{ts}] Talker: {timeout_msg}..."
                if shared:
                    shared.add_talker_interaction(timeout_msg, "broadcast")
                break
            if now - precheck_last_broadcast >= 5.0:
                if precheck_idx < len(precheck_templates):
                    msg = precheck_templates[precheck_idx]
                    msg_template = f"precheck_{precheck_idx}"
                else:
                    elapsed = int(now - thinker_start)
                    msg = f"é¢„åˆ†æè¿›è¡Œä¸­ï¼ˆ{elapsed}sï¼‰"
                    msg_template = f"precheck_elapsed_{elapsed // 10}"
                if msg_template != last_precheck_template:
                    ts = format_timestamp(now)
                    yield f"\n[{ts}] Talker: {msg}..."
                    if shared:
                        shared.add_talker_interaction(msg, "broadcast")
                    last_precheck_template = msg_template
                precheck_last_broadcast = now
                precheck_idx += 1
            await asyncio.sleep(0.1)

        quick_plan = None
        try:
            if not precheck_timed_out:
                quick_plan, needs_clarification, reason, missing_info, question = await precheck_task
                if not needs_clarification and quick_plan and getattr(quick_plan, "steps", None):
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Talker: Thinkerå·²å®Œæˆè§„åˆ’ï¼Œé¢„è®¡{len(quick_plan.steps)}æ­¥æ‰§è¡Œ"
                if needs_clarification and missing_info and shared and question:
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Talker: {question}"
                    shared.add_talker_interaction(question, "clarification")
                    shared.add_clarification_request(question, reason or "", [])
                    shared.clarification_status = ClarificationStatus.PENDING
                    return
        except asyncio.CancelledError:
            pass
        except Exception:
            pass

        # è®°å½•Handoffåˆ°Thinker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "talker",
            "thinker",
            "å¯åŠ¨åä½œæ¨¡å¼",
        )

        # Thinkerå¼€å§‹å·¥ä½œçš„æç¤º
        ts = format_timestamp(time.time())
        yield f"\n[{ts}] Thinker: å¼€å§‹å¤„ç†..."

        # æ”¶é›†Thinkerçš„è¾“å‡º
        thinker_output = []
        thinker_complete = False
        accumulated_output = ""
        thinker_first_token_shown = False

        # æ’­æŠ¥æ§åˆ¶ - ä½¿ç”¨ç‹¬ç«‹çš„æ—¶é—´æ£€æŸ¥ï¼ˆåŠ¨æ€é—´éš”ï¼‰
        last_broadcast_time = thinker_start

        def get_broadcast_interval(elapsed: float) -> float:
            """æ ¹æ®å·²è€—æ—¶åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš” - æ›´ä¿å®ˆ"""
            if elapsed < 15:
                return 4.0  # åˆå§‹4ç§’
            elif elapsed < 30:
                return 6.0  # ä¸­æœŸ6ç§’
            else:
                return 8.0  # åæœŸ8ç§’
        output_index = 0

        async def run_thinker():
            """è¿è¡ŒThinkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal thinker_complete
            async for chunk in self.thinker.process(user_input, context):
                thinker_output.append(chunk)
            thinker_complete = True

        # å¯åŠ¨Thinkerä»»åŠ¡
        thinker_task = asyncio.create_task(run_thinker())

        # ä¸»å¾ªç¯ï¼šå¤„ç†Thinkerè¾“å‡ºå’Œæ’­æŠ¥
        while not thinker_complete or output_index < len(thinker_output):
            current_time = time.time()
            elapsed = current_time - thinker_start

            # === æ’­æŠ¥æ£€æŸ¥ ===
            broadcast_interval = get_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                # ä¼˜å…ˆä½¿ç”¨SharedContextä¸­çš„å®æ—¶è¿›åº¦ï¼Œå›é€€åˆ°è¾“å‡ºè§£æ
                if shared and shared.thinker_progress.current_stage != "idle":
                    new_stage = self._stage_from_shared_progress(shared.thinker_progress.current_stage)
                    current_step = shared.thinker_progress.current_step
                    total_steps = shared.thinker_progress.total_steps
                    step_desc = self._latest_shared_step_desc(shared)
                else:
                    new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥
                content_hash = f"{new_stage.value}:{current_step}:{total_steps}:{step_desc[:20]}"
                should_broadcast, reason = self._should_broadcast(
                    new_stage,
                    current_step,
                    elapsed,
                    content_hash,
                )

                if should_broadcast:
                    # ç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯å’Œæ¨¡æ¿
                    if reason == "heartbeat":
                        stage_zh = {
                            ThinkerStage.ANALYZING: "åˆ†æ",
                            ThinkerStage.PLANNING: "è§„åˆ’",
                            ThinkerStage.EXECUTING: "æ‰§è¡Œ",
                            ThinkerStage.SYNTHESIZING: "æ•´åˆ",
                            ThinkerStage.IDLE: "å‡†å¤‡",
                            ThinkerStage.COMPLETED: "æ”¶å°¾",
                        }.get(new_stage, "å¤„ç†")
                        bucket = int(elapsed // 15)
                        broadcast_msg = f"ä»åœ¨{stage_zh}é˜¶æ®µï¼ˆ{elapsed:.0f}sï¼‰"
                        msg_template = f"heartbeat_{new_stage.value}_{bucket}"
                    else:
                        broadcast_msg, msg_template = self._generate_stage_broadcast(
                            stage=new_stage,
                            user_query=user_input,
                            elapsed_time=elapsed,
                            current_step=current_step,
                            total_steps=total_steps,
                            step_desc=step_desc,
                        )

                    # åŸºäºæ¨¡æ¿å»é‡ï¼ˆä¸æ˜¯å®Œæ•´æ¶ˆæ¯ï¼‰
                    if msg_template != self._progress_state.last_broadcast_msg_template:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Talker: {broadcast_msg}"
                        if shared:
                            shared.add_talker_interaction(broadcast_msg, "broadcast")
                        self._progress_state.last_broadcast = current_time
                        self._progress_state.last_broadcast_msg_template = msg_template
                        self._progress_state.broadcast_count += 1

                    # æ›´æ–°çŠ¶æ€
                    if new_stage != self._progress_state.current_stage:
                        self._progress_state.current_stage = new_stage
                        self._progress_state.last_stage_change = current_time
                        # é˜¶æ®µå˜åŒ–æ—¶é‡ç½®æ¨¡æ¿é›†åˆ
                        self._progress_state.used_message_templates = {}
                    self._progress_state.current_step = current_step
                    self._progress_state.total_steps = total_steps
                    self._progress_state.last_content_hash = content_hash

                last_broadcast_time = current_time

            # === å¤„ç†Thinkerè¾“å‡º ===
            if output_index < len(thinker_output):
                chunk = thinker_output[output_index]
                output_index += 1
                accumulated_output += chunk

                # è§£æé˜¶æ®µï¼ˆç”¨äºçŠ¶æ€æ›´æ–°ï¼‰
                if shared and shared.thinker_progress.current_stage != "idle":
                    new_stage = self._stage_from_shared_progress(shared.thinker_progress.current_stage)
                    current_step = shared.thinker_progress.current_step
                    total_steps = shared.thinker_progress.total_steps
                    step_desc = self._latest_shared_step_desc(shared)
                else:
                    new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ›´æ–°çŠ¶æ€
                if new_stage != self._progress_state.current_stage:
                    self._progress_state.current_stage = new_stage
                    self._progress_state.last_stage_change = current_time
                self._progress_state.current_step = current_step
                self._progress_state.total_steps = total_steps
                self._progress_state.last_content_hash = f"{new_stage.value}:{current_step}:{total_steps}:{step_desc[:20]}"

                # Thinkerè¾“å‡ºåŠ æ—¶é—´æˆ³
                if chunk.strip():
                    if not thinker_first_token_shown:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Thinker: "
                        thinker_first_token_shown = True
                    yield chunk
            else:
                # æ²¡æœ‰æ–°è¾“å‡ºæ—¶çŸ­æš‚ç­‰å¾…
                await asyncio.sleep(0.05)

        # ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½å·²å¤„ç†
        while output_index < len(thinker_output):
            chunk = thinker_output[output_index]
            output_index += 1
            if chunk.strip():
                if not thinker_first_token_shown:
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Thinker: "
                    thinker_first_token_shown = True
            yield chunk

        # è®°å½•Handoffå›Talker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "thinker",
            "talker",
            "Thinkerå¤„ç†å®Œæˆ",
        )

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, thinker_start, thinker_start)

    async def _parallel_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        å¹¶è¡Œæ¨¡å¼Handoff

        Talkerå’ŒThinkeråŒæ—¶å·¥ä½œ
        """
        # å¹¶è¡Œå¯åŠ¨
        talker_task = asyncio.create_task(
            self._collect_stream(self.talker.process(user_input, context))
        )
        thinker_task = asyncio.create_task(
            self._collect_stream(self.thinker.process(user_input, context))
        )

        # å…ˆè¿”å›Talkerçš„å¿«é€Ÿå“åº”
        talker_result = await talker_task
        yield "".join(talker_result)

        # ç­‰å¾…Thinkerå®Œæˆ
        thinker_result = await thinker_task

        # å¦‚æœThinkerçš„ç­”æ¡ˆæ›´å¥½ï¼Œè¡¥å……è¯´æ˜
        if thinker_result:
            yield "\n\nã€è¡¥å……è¯´æ˜ã€‘\n"
            yield "".join(thinker_result)

    async def _iterative_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        è¿­ä»£æ¨¡å¼Handoff

        Talkeræä¾›åˆæ­¥ç­”æ¡ˆï¼ŒThinkeræ ¹æ®ç”¨æˆ·åé¦ˆæ”¹è¿›
        """
        # Talkerå…ˆæä¾›åˆæ­¥ç­”æ¡ˆ
        yield "ã€åˆæ­¥ç­”æ¡ˆã€‘\n"
        async for chunk in self.talker.process(user_input, context):
            yield chunk

        yield "\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚"

    async def _collect_stream(self, stream: AsyncIterator[str]) -> List[str]:
        """æ”¶é›†æµå¼è¾“å‡º"""
        result = []
        async for chunk in stream:
            result.append(chunk)
        return result

    async def _get_or_create_session(self, session_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆä½¿ç”¨SessionContextæŒä¹…åŒ–ï¼‰"""
        if not await self.session_context.exists(session_id):
            await self.session_context.set_session_data(session_id, "created_at", time.time())
            await self.session_context.set_session_data(session_id, "state", "active")

        # è¿”å›å…¼å®¹æ ¼å¼
        messages = await self.session_context.get_messages(session_id, limit=100)
        return {
            "messages": [m.to_dict() for m in messages],
            "created_at": await self.session_context.get_session_data(session_id, "created_at", time.time()),
            "state": await self.session_context.get_session_data(session_id, "state", "active"),
        }

    def _get_or_create_shared_context(self, session_id: str, user_input: str = "") -> SharedContext:
        """è·å–æˆ–åˆ›å»ºå…±äº«ä¸Šä¸‹æ–‡"""
        if session_id not in self._shared_contexts:
            self._shared_contexts[session_id] = SharedContext(user_input=user_input)
        elif user_input:
            self._shared_contexts[session_id].user_input = user_input
        return self._shared_contexts[session_id]

    def get_shared_context(self, session_id: str) -> Optional[SharedContext]:
        """è·å–ä¼šè¯å…±äº«ä¸Šä¸‹æ–‡ï¼ˆåªè¯»è®¿é—®ï¼‰ã€‚"""
        return self._shared_contexts.get(session_id)

    def _record_handoff(
        self,
        handoff_type: HandoffType,
        from_agent: str,
        to_agent: str,
        reason: str,
    ) -> None:
        """è®°å½•Handoff"""
        self._stats["handoffs"] += 1
        handoff = HandoffContext(
            handoff_type=handoff_type,
            from_agent=from_agent,
            to_agent=to_agent,
            reason=reason,
        )
        self._handoff_history.append(handoff)

        # è§¦å‘å›è°ƒ
        if self._on_handoff:
            asyncio.create_task(self._on_handoff(handoff))

    async def _handle_progress(self, progress_info: Dict[str, Any]) -> None:
        """å¤„ç†è¿›åº¦æ›´æ–°"""
        if self._on_progress:
            await self._on_progress(progress_info)

    async def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        if await self.session_context.exists(session_id):
            return await self._get_or_create_session(session_id)
        return None

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "active_sessions": len(self._shared_contexts),
            "recent_handoffs": len(self._handoff_history[-10:]),
            "talker_stats": self.talker.get_stats(),
            "thinker_stats": self.thinker.get_stats(),
        }

    def get_handoff_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–Handoffå†å²"""
        return [
            {
                "type": h.handoff_type.value,
                "from": h.from_agent,
                "to": h.to_agent,
                "reason": h.reason,
                "timestamp": h.timestamp,
            }
            for h in self._handoff_history[-limit:]
        ]

    async def clear_session(self, session_id: str) -> None:
        """æ¸…é™¤ä¼šè¯"""
        await self.session_context.delete_session(session_id)
        if session_id in self._shared_contexts:
            del self._shared_contexts[session_id]

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self.talker.reset_stats()
        self.thinker.reset_stats()
