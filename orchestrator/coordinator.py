"""
Orchestrator - åè°ƒå™¨
ç®¡ç†Talkerå’ŒThinkerçš„ååŒå·¥ä½œ
"""
import asyncio
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from config import settings
from context.types import AgentRole, HandoffType, Message, ResponseLayer, Task, TaskComplexity
from context.session_context import SessionContext
from context.shared_context import SharedContext, ClarificationStatus
from context.summarizer import ConversationSummarizer
from agents.talker.agent import TalkerAgent
from agents.thinker.agent import ThinkerAgent
from orchestrator.scheduler import TaskScheduler, ComplexityBasedScheduler
from skills.engine import SkillsEngine
from skills.invoker import SkillInvoker
from skills.examples import (
    WeatherSkill,
    SearchSkill,
    KnowledgeSearchSkill,
    CalculatorSkill,
    UnitConverterSkill,
)


class ThinkerStage(Enum):
    """Thinkerå¤„ç†é˜¶æ®µ"""
    IDLE = "idle"
    ANALYZING = "analyzing"      # æ€è€ƒ/åˆ†æ
    PLANNING = "planning"        # è§„åˆ’
    EXECUTING = "executing"      # æ‰§è¡Œæ­¥éª¤
    SYNTHESIZING = "synthesizing"  # æ•´åˆ/ç”Ÿæˆç­”æ¡ˆ
    COMPLETED = "completed"


@dataclass
class ProgressState:
    """è¿›åº¦çŠ¶æ€è·Ÿè¸ª"""
    current_stage: ThinkerStage = ThinkerStage.IDLE
    last_stage_change: float = 0
    last_broadcast: float = 0
    last_broadcast_msg: str = ""
    broadcast_count: int = 0
    current_step: int = 0
    total_steps: int = 0
    step_description: str = ""
    broadcast_history: set = field(default_factory=set)  # ç”¨äºå»é‡
    last_content_hash: str = ""  # ç”¨äºå†…å®¹å»é‡
    used_messages: Dict[str, set] = field(default_factory=dict)  # æŒ‰é˜¶æ®µè®°å½•å·²ä½¿ç”¨çš„æ¶ˆæ¯


@dataclass
class HandoffContext:
    """Handoffä¸Šä¸‹æ–‡"""
    handoff_type: HandoffType
    from_agent: str
    to_agent: str
    reason: str
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)


class Orchestrator:
    """
    Orchestrator - åè°ƒå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. ä»»åŠ¡è°ƒåº¦å’Œè·¯ç”±
    2. Agentä¹‹é—´çš„Handoffç®¡ç†
    3. ä¸Šä¸‹æ–‡åŒæ­¥
    4. çŠ¶æ€ç»´æŠ¤
    """

    def __init__(
        self,
        talker: Optional[TalkerAgent] = None,
        thinker: Optional[ThinkerAgent] = None,
        task_scheduler: Optional[TaskScheduler] = None,
        session_context: Optional[SessionContext] = None,
        skills_engine: Optional[SkillsEngine] = None,
        summarizer: Optional[ConversationSummarizer] = None,
    ):
        # Agentå®ä¾‹
        self.talker = talker or TalkerAgent()
        self.thinker = thinker or ThinkerAgent()

        # è°ƒåº¦å™¨
        self.task_scheduler = task_scheduler or TaskScheduler()
        self.complexity_scheduler = ComplexityBasedScheduler()

        # ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒRedisæŒä¹…åŒ–ï¼Œä¸å¯ç”¨æ—¶é™çº§åˆ°å†…å­˜ï¼‰
        self.session_context = session_context or SessionContext()

        # å…±äº«ä¸Šä¸‹æ–‡ï¼ˆTalkerå’ŒThinkerä¹‹é—´å…±äº«ï¼‰
        self._shared_contexts: Dict[str, SharedContext] = {}

        # Skillså¼•æ“å’Œè°ƒç”¨å™¨
        self.skills_engine = skills_engine or SkillsEngine()
        self.skill_invoker = SkillInvoker(self.skills_engine)
        self._initialize_default_skills()

        # å°†SkillInvokeræ³¨å…¥åˆ°Thinker
        self.thinker.set_skill_invoker(self.skill_invoker)

        # å¯¹è¯æ‘˜è¦å™¨ï¼ˆç”¨äºé•¿å¯¹è¯å‹ç¼©ï¼‰
        self.summarizer = summarizer or ConversationSummarizer(
            summary_threshold=settings.SUMMARY_THRESHOLD
        )

        # Handoffå†å²
        self._handoff_history: List[HandoffContext] = []

        # å›è°ƒå‡½æ•°
        self._on_response: Optional[Callable] = None
        self._on_handoff: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None

        # è®¾ç½®è¿›åº¦å›è°ƒ
        self.talker.set_progress_callback(self._handle_progress)
        self.thinker.set_progress_callback(self._handle_progress)

        # ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }

        # è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()

    def _initialize_default_skills(self) -> None:
        """åˆå§‹åŒ–é»˜è®¤æŠ€èƒ½"""
        default_skills = [
            WeatherSkill(),
            SearchSkill(),
            KnowledgeSearchSkill(),
            CalculatorSkill(),
            UnitConverterSkill(),
        ]
        for skill in default_skills:
            self.skills_engine.register_skill(skill)

    def _parse_thinker_stage(self, output: str) -> tuple[ThinkerStage, int, int, str]:
        """
        è§£æThinkerè¾“å‡ºï¼Œè¯†åˆ«å½“å‰é˜¶æ®µ

        Returns:
            tuple: (é˜¶æ®µ, å½“å‰æ­¥éª¤, æ€»æ­¥éª¤, æ­¥éª¤æè¿°)
        """
        stage = self._progress_state.current_stage
        current_step = self._progress_state.current_step
        total_steps = self._progress_state.total_steps
        step_desc = ""

        # æ£€æµ‹é˜¶æ®µå˜åŒ–
        if "[æ€è€ƒ]" in output or "æ­£åœ¨åˆ†æ" in output:
            stage = ThinkerStage.ANALYZING
        elif "[è§„åˆ’]" in output:
            stage = ThinkerStage.PLANNING
            # å°è¯•è§£ææ€»æ­¥éª¤æ•°
            steps_match = re.search(r"å…±(\d+)ä¸ªæ­¥éª¤", output)
            if steps_match:
                total_steps = int(steps_match.group(1))
        elif "[æ­¥éª¤" in output:
            stage = ThinkerStage.EXECUTING
            # è§£ææ­¥éª¤ä¿¡æ¯
            step_match = re.search(r"\[æ­¥éª¤(\d+)\]", output)
            if step_match:
                current_step = int(step_match.group(1))
            # è§£ææ­¥éª¤æè¿°
            desc_match = re.search(r"\[æ­¥éª¤\d+\]\s*(.+?)(?:\n|$)", output)
            if desc_match:
                step_desc = desc_match.group(1).strip()
        elif "[æ€è€ƒ] æ•´åˆ" in output or "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ" in output:
            stage = ThinkerStage.SYNTHESIZING
        elif "[ç­”æ¡ˆ]" in output:
            stage = ThinkerStage.COMPLETED

        return stage, current_step, total_steps, step_desc

    def _generate_stage_broadcast(
        self,
        stage: ThinkerStage,
        user_query: str,
        elapsed_time: float,
        current_step: int = 0,
        total_steps: int = 0,
        step_desc: str = "",
    ) -> str:
        """
        æ ¹æ®é˜¶æ®µç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯ï¼ˆåŸºäºä¸Šä¸‹æ–‡çš„åŠ¨æ€æ¶ˆæ¯ï¼‰
        å…³é”®æ”¹è¿›ï¼šæ ¹æ®æ—¶é—´è¿›åº¦ç”Ÿæˆä¸åŒé£æ ¼çš„æ’­æŠ¥ï¼Œé¿å…é‡å¤
        ä½¿ç”¨å·²ä½¿ç”¨æ¶ˆæ¯è¿½è¸ªæ¥é¿å…é‡å¤
        """
        # æå–ä¸»é¢˜
        topic = self._extract_topic(user_query)
        stage_key = stage.value

        # è·å–è¯¥é˜¶æ®µå·²ä½¿ç”¨çš„æ¶ˆæ¯é›†åˆ
        if stage_key not in self._progress_state.used_messages:
            self._progress_state.used_messages[stage_key] = set()

        used = self._progress_state.used_messages[stage_key]

        # æ ¹æ®å·²è€—æ—¶é€‰æ‹©æ’­æŠ¥é£æ ¼
        if elapsed_time < 8:
            style = "initial"
        elif elapsed_time < 15:
            style = "progress"
        elif elapsed_time < 25:
            style = "reassure"
        else:
            style = "urgent"

        def get_unused_message(msgs: list, used_set: set) -> str:
            """ä»æœªä½¿ç”¨çš„æ¶ˆæ¯ä¸­é€‰æ‹©ä¸€ä¸ªï¼Œå¦‚æœéƒ½ç”¨è¿‡åˆ™é‡ç½®"""
            for msg in msgs:
                if msg not in used_set:
                    used_set.add(msg)
                    return msg
            # æ‰€æœ‰æ¶ˆæ¯éƒ½ç”¨è¿‡äº†ï¼Œæ¸…ç©ºå¹¶é‡æ–°å¼€å§‹
            used_set.clear()
            used_set.add(msgs[0])
            return msgs[0]

        if stage == ThinkerStage.ANALYZING:
            if style == "initial":
                msgs = [
                    f"æ­£åœ¨ç†è§£æ‚¨å…³äºã€Œ{topic}ã€çš„éœ€æ±‚...",
                    "æ­£åœ¨åˆ†æé—®é¢˜å…³é”®ç‚¹...",
                    f"æ¢³ç†ã€Œ{topic}ã€ç›¸å…³ä¿¡æ¯...",
                ]
            elif style == "progress":
                msgs = [
                    "æ·±åº¦åˆ†æä¸­ï¼Œè¯·ç¨å€™...",
                    "æ­£åœ¨æå–å…³é”®è¦ç´ ...",
                ]
            else:
                # æ¯æ¬¡ç”Ÿæˆå¸¦æ—¶é—´çš„å”¯ä¸€æ¶ˆæ¯ï¼Œè‡ªç„¶ä¸ä¼šé‡å¤
                msgs = [
                    f"åˆ†æè¿›è¡Œä¸­ ({elapsed_time:.0f}s)...",
                ]
            return get_unused_message(msgs, used)

        elif stage == ThinkerStage.PLANNING:
            if style == "initial":
                msgs = [
                    f"å·²ç†è§£éœ€æ±‚ï¼Œæ­£åœ¨åˆ¶å®š{topic}æ–¹æ¡ˆ...",
                    "è§„åˆ’æœ€ä¼˜è§£å†³è·¯å¾„...",
                ]
            elif style == "progress":
                msgs = [
                    "æ–¹æ¡ˆè®¾è®¡ä¸­...",
                    "æ­£åœ¨åˆ†è§£ä»»åŠ¡æ­¥éª¤...",
                ]
            else:
                msgs = [
                    f"è§„åˆ’ä¸­ ({elapsed_time:.0f}s)...",
                ]
            return get_unused_message(msgs, used)

        elif stage == ThinkerStage.EXECUTING:
            if total_steps > 0 and current_step > 0:
                progress_pct = int((current_step / total_steps) * 100)
                if step_desc:
                    short_desc = step_desc[:15] + "..." if len(step_desc) > 15 else step_desc
                    return f"ç¬¬{current_step}/{total_steps}æ­¥: {short_desc} ({progress_pct}%)"
                return f"æ‰§è¡Œä¸­: {current_step}/{total_steps} æ­¥ ({progress_pct}%)"
            # æ²¡æœ‰æ­¥éª¤ä¿¡æ¯æ—¶ä½¿ç”¨é€šç”¨æ¶ˆæ¯
            msgs = [
                "æ­£åœ¨å¤„ç†æ ¸å¿ƒä»»åŠ¡...",
                "æ‰§è¡Œå…³é”®æ­¥éª¤...",
            ]
            return get_unused_message(msgs, used)

        elif stage == ThinkerStage.SYNTHESIZING:
            msgs = [
                "æ­£åœ¨æ•´åˆåˆ†æç»“æœ...",
                "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¸­...",
                "å³å°†å®Œæˆï¼Œè¯·ç¨å€™...",
                "æ•´ç†è¾“å‡ºå†…å®¹...",
            ]
            return get_unused_message(msgs, used)

        elif stage == ThinkerStage.COMPLETED:
            return "å¤„ç†å®Œæˆï¼"

        # é»˜è®¤æ¶ˆæ¯
        return f"å¤„ç†ä¸­ ({elapsed_time:.0f}s)..."

    def _extract_topic(self, query: str) -> str:
        """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–ä¸»é¢˜"""
        query_lower = query.lower()

        topic_keywords = {
            "é€‰è½¦": ["è½¦", "æ±½è½¦", "è½¦å‹", "å“ç‰Œ", "suv", "è½¿è½¦", "ä¹°è½¦", "é€‰è½¦"],
            "æ—…æ¸¸": ["æ—…æ¸¸", "æ—…è¡Œ", "æ™¯ç‚¹", "é…’åº—", "æœºç¥¨", "å»å“ª"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "é¤å…", "èœ", "åƒ", "æ¨èèœ"],
            "è´­ç‰©": ["ä¹°", "è´­ç‰©", "ä»·æ ¼", "ä¾¿å®œ", "å¯¹æ¯”"],
            "å’–å•¡": ["å’–å•¡", "æ‹¿é“", "æ˜Ÿå·´å…‹", "ç‘å¹¸"],
            "æ‰“è½¦": ["æ‰“è½¦", "æ»´æ»´", "é«˜å¾·", "ä¸“è½¦", "å¿«è½¦"],
        }

        for topic, keywords in topic_keywords.items():
            if any(kw in query_lower for kw in keywords):
                return topic

        # æå–é—®é¢˜ä¸­çš„å…³é”®è¯ä½œä¸ºä¸»é¢˜
        words = re.findall(r'[\u4e00-\u9fa5]{2,4}', query)
        if words:
            return words[0]
        return "æ‚¨çš„é—®é¢˜"

    def _should_broadcast(
        self,
        new_stage: ThinkerStage,
        current_step: int,
        elapsed_time: float,
        force_check: bool = False,
    ) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ’­æŠ¥

        Args:
            new_stage: å½“å‰é˜¶æ®µ
            current_step: å½“å‰æ­¥éª¤
            elapsed_time: å·²è€—æ—¶
            force_check: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥ï¼ˆå¿½ç•¥æœ€å°é—´éš”ï¼‰

        Returns:
            tuple: (æ˜¯å¦æ’­æŠ¥, åŸå› )
        """
        state = self._progress_state
        current_time = time.time()

        # åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš”ï¼šåˆå§‹é€‚ä¸­ï¼ŒåæœŸå»¶é•¿
        def get_min_interval(elapsed: float, stage: ThinkerStage) -> float:
            """æ ¹æ®è€—æ—¶å’Œé˜¶æ®µåŠ¨æ€è®¡ç®—æœ€å°é—´éš”"""
            # æ›´ä¿å®ˆçš„é—´éš”ç­–ç•¥
            if elapsed < 10:
                base_interval = 4.0  # åˆå§‹4ç§’
            elif elapsed < 20:
                base_interval = 5.0  # ä¸­æœŸ5ç§’
            elif elapsed < 40:
                base_interval = 6.0  # åæœŸ6ç§’
            else:
                base_interval = 8.0  # é•¿æ—¶é—´ä»»åŠ¡8ç§’

            # è§„åˆ’é˜¶æ®µå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œç¨å¾®å»¶é•¿é—´éš”
            if stage == ThinkerStage.PLANNING:
                base_interval = min(base_interval + 1.0, 10.0)
            return base_interval

        min_interval = get_min_interval(elapsed_time, new_stage)

        # é˜¶æ®µå˜åŒ–ï¼Œç«‹å³æ’­æŠ¥
        if new_stage != state.current_stage:
            return True, "stage_changed"

        # æ­¥éª¤å˜åŒ–ï¼ˆæ‰§è¡Œé˜¶æ®µï¼‰
        if new_stage == ThinkerStage.EXECUTING and current_step != state.current_step and current_step > 0:
            return True, "step_changed"

        # åŒé˜¶æ®µå†…ï¼Œæ£€æŸ¥æ—¶é—´é—´éš”
        time_since_last = current_time - state.last_broadcast
        if time_since_last >= min_interval:
            # é™åˆ¶æ¯é˜¶æ®µçš„æ’­æŠ¥æ¬¡æ•°
            stage_key = new_stage.value
            stage_broadcast_count = len(state.used_messages.get(stage_key, set()))
            max_broadcasts_per_stage = 5  # æ¯é˜¶æ®µæœ€å¤š5æ¡ä¸åŒæ¶ˆæ¯

            if stage_broadcast_count < max_broadcasts_per_stage:
                return True, "interval_elapsed"

        return False, "skip"

    def _hash_broadcast_content(self, stage: ThinkerStage, step: int, elapsed: float) -> str:
        """ç”Ÿæˆæ’­æŠ¥å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        # ä½¿ç”¨é˜¶æ®µå’Œæ­¥éª¤çš„æ•´æ•°éƒ¨åˆ†ä½œä¸ºå“ˆå¸ŒåŸºç¡€
        elapsed_bucket = int(elapsed // 5) * 5  # æ¯5ç§’ä¸€ä¸ªæ¡¶
        return f"{stage.value}_{step}_{elapsed_bucket}"

    def set_callbacks(
        self,
        on_response: Optional[Callable] = None,
        on_handoff: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
    ) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_response = on_response
        self._on_handoff = on_handoff
        self._on_progress = on_progress

    async def process(
        self,
        user_input: str,
        session_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        received_time: Optional[float] = None,
    ) -> AsyncIterator[str]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡
            received_time: æ¶ˆæ¯æ¥æ”¶æ—¶é—´

        Yields:
            str: å“åº”å†…å®¹
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        if received_time is None:
            received_time = start_time

        # åˆå§‹åŒ–ä¼šè¯
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())

        # ä½¿ç”¨SessionContextè·å–ä¼šè¯ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        session = await self._get_or_create_session(session_id)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°SessionContext
        user_message = Message(
            role="user",
            content=user_input,
            timestamp=time.time(),
        )
        await self.session_context.add_message(session_id, user_message)

        # åˆ›å»º/è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = self._get_or_create_shared_context(session_id, user_input)
        shared.is_processing = True

        # === æ£€æŸ¥æ˜¯å¦æ˜¯å›ç­”æ¾„æ¸…é—®é¢˜ ===
        if shared.needs_clarification():
            # ç”¨æˆ·å¯èƒ½æ˜¯åœ¨å›ç­”æ¾„æ¸…é—®é¢˜
            pending = shared.get_pending_clarification()
            if pending:
                # è®°å½•å›ç­”
                shared.answer_clarification(user_input)
                # æ›´æ–°æ„å›¾
                shared.update_intent_with_clarification(user_input)

                # ç»™ç”¨æˆ·ç¡®è®¤åé¦ˆ
                ts = time.strftime("%H:%M:%S", time.localtime())
                ms = int((time.time() % 1) * 1000)
                yield f"\n[{ts}.{ms:03d}] Talker: æ”¶åˆ°ï¼Œå·²æ›´æ–°æ‚¨çš„éœ€æ±‚ä¿¡æ¯"

                # æ ‡è®°ä¸ºç»§ç»­å¤„ç†ï¼Œä½†ä½¿ç”¨æ›´æ–°åçš„æ„å›¾
                # å¦‚æœæ¾„æ¸…åçš„æ„å›¾è¶³å¤Ÿç®€å•ï¼Œå¯ä»¥è®©Talkerå¤„ç†
                # å¦åˆ™ç»§ç»­äº¤ç»™Thinker

        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å…±äº«ä¸Šä¸‹æ–‡å’Œæ‘˜è¦ï¼‰
        # è·å–ä¼šè¯æ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        session_summary = await self.session_context.get_summary(session_id)

        # å¦‚æœæ²¡æœ‰æ‘˜è¦ä¸”æ¶ˆæ¯è¾ƒå¤šï¼Œç”Ÿæˆæ‘˜è¦
        messages = await self.session_context.get_messages(session_id, limit=50)
        if not session_summary and len(messages) >= settings.SUMMARY_THRESHOLD:
            session_summary = await self.summarizer.summarize_recent_messages(messages)
            if session_summary:
                await self.session_context.set_summary(session_id, session_summary)

        full_context = {
            **(context or {}),
            "session_id": session_id,
            "messages": session["messages"],
            "received_time": received_time,
            "shared": shared,  # æ·»åŠ å…±äº«ä¸Šä¸‹æ–‡
            "session_summary": session_summary,  # æ·»åŠ ä¼šè¯æ‘˜è¦
        }

        # æ”¶é›†åŠ©æ‰‹å“åº”ç”¨äºä¿å­˜åˆ°ä¼šè¯
        assistant_response_chunks = []

        try:
            # ä½¿ç”¨Talkerè¿›è¡Œæ„å›¾åˆ†ç±»
            classification = await self.talker.classify_intent(user_input, full_context)

            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
            if classification.complexity == TaskComplexity.COMPLEX:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨åä½œæ¨¡å¼
                self._stats["thinker_handled"] += 1
                async for chunk in self._collaboration_handoff(
                    user_input, full_context, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk
            else:
                # ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼šTalkerå¤„ç†
                self._stats["talker_handled"] += 1
                async for chunk in self._delegation_handoff(
                    user_input, full_context, classification, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk

        except Exception as e:
            self._stats["errors"] += 1
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            assistant_response_chunks.append(error_msg)
            yield error_msg

        finally:
            # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°ä¼šè¯ï¼ˆæ¸…ç†æ‰å…ƒæ•°æ®æ ‡è®°ï¼‰
            assistant_response = "".join(assistant_response_chunks)
            # ç§»é™¤æ—¶é—´æˆ³å’ŒAgentæ ‡è¯†ç­‰å…ƒæ•°æ®ï¼Œåªä¿ç•™å®é™…å›å¤å†…å®¹
            # ç§»é™¤ç±»ä¼¼ [HH:MM:SS.mmm] Talker: çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[\d{2}:\d{2}:\d{2}\.\d{3}\]\s*(Talker|Thinker):\s*', '', assistant_response)
            # ç§»é™¤ç±»ä¼¼ [Talker] ... çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker\][^\n]*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker\][^\n]*', '', clean_response)
            # ç§»é™¤ [Talker -> Thinker | ...] çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker[^\]]*\]\s*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker[^\]]*\]\s*', '', clean_response)
            # ç§»é™¤æ€§èƒ½æŒ‡æ ‡åŒºå—ï¼ˆåŒ…å«ğŸ“Šç¬¦å·çš„éƒ¨åˆ†ï¼‰
            clean_response = re.sub(r'\n-{10,}.*?-{10,}', '', clean_response, flags=re.DOTALL)
            # ç§»é™¤å‰©ä½™çš„æŒ‡æ ‡è¡Œ
            clean_response = re.sub(r'\n\s*ğŸ“Š[^\n]*', '', clean_response)
            clean_response = re.sub(r'\n\s*(Tokens|TTFT|TPOT|TPS|æ€»ç”Ÿæˆæ—¶å»¶|LLMè¯·æ±‚æ—¶é—´)[^\n]*', '', clean_response)
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            clean_response = re.sub(r'\n{3,}', '\n\n', clean_response)
            clean_response = clean_response.strip()

            if clean_response:
                # ä½¿ç”¨SessionContextä¿å­˜åŠ©æ‰‹å“åº”
                assistant_message = Message(
                    role="assistant",
                    content=clean_response,
                    timestamp=time.time(),
                )
                await self.session_context.add_message(session_id, assistant_message)

            # æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡çŠ¶æ€
            shared.is_processing = False

            elapsed = (time.time() - start_time) * 1000
            await self.session_context.set_session_data(session_id, "last_latency_ms", elapsed)

    async def _delegation_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        classification,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        å§”æ‰˜æ¨¡å¼Handoff

        Talkerå¤„ç†ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å§”æ‰˜ç»™Thinker
        æ”¹è¿›ï¼šç‹¬ç«‹äºTalkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        # è®°å½•LLMè¯·æ±‚å‘é€æ—¶é—´
        llm_request_time = time.time()

        # ä½¿ç”¨é˜Ÿåˆ—æ”¶é›†Talkerè¾“å‡º
        talker_queue = asyncio.Queue()
        talker_complete = False

        async def run_talker():
            """è¿è¡ŒTalkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal talker_complete
            async for chunk in self.talker.process(user_input, context):
                await talker_queue.put(chunk)
            talker_complete = True

        # å¯åŠ¨Talkerä»»åŠ¡
        talker_task = asyncio.create_task(run_talker())

        # å¤„ç†Talkerè¾“å‡º
        first_token_time = None
        first_timestamp_shown = False
        last_broadcast_time = llm_request_time
        broadcast_count = 0
        used_broadcast_msgs = set()  # è¿½è¸ªå·²ä½¿ç”¨çš„æ¶ˆæ¯

        def get_talker_broadcast_interval(elapsed: float) -> float:
            """åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš”"""
            if elapsed < 10:
                return 4.0  # åˆå§‹4ç§’
            elif elapsed < 20:
                return 5.0  # ä¸­æœŸ5ç§’
            else:
                return 6.0  # åæœŸ6ç§’

        while not talker_complete or not talker_queue.empty():
            current_time = time.time()
            elapsed = current_time - llm_request_time

            # === å…³é”®æ”¹è¿›ï¼šæ¯æ¬¡å¾ªç¯éƒ½æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥ ===
            broadcast_interval = get_talker_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                ts = format_timestamp(current_time)

                # æ ¹æ®æ—¶é—´åŠ¨æ€é€‰æ‹©æ’­æŠ¥å†…å®¹ï¼Œé¿å…é‡å¤
                if elapsed < 10:
                    all_msgs = ["æ­£åœ¨å¤„ç†...", "æ€è€ƒä¸­..."]
                elif elapsed < 20:
                    all_msgs = ["ä»åœ¨å¤„ç†ä¸­...", "è¯·ç¨å€™..."]
                else:
                    # é•¿æ—¶é—´ä»»åŠ¡ï¼Œå¸¦æ—¶é—´æç¤º
                    all_msgs = [f"å“åº”è¾ƒæ…¢ ({elapsed:.0f}s)..."]

                # é€‰æ‹©ä¸€ä¸ªæœªä½¿ç”¨çš„æ¶ˆæ¯
                msg = None
                for m in all_msgs:
                    if m not in used_broadcast_msgs:
                        msg = m
                        used_broadcast_msgs.add(m)
                        break

                if msg is None:
                    # æ‰€æœ‰æ¶ˆæ¯éƒ½ç”¨è¿‡äº†ï¼Œæ¸…ç©ºé‡æ¥ï¼ˆä½†è¿™ä¸åº”è¯¥é¢‘ç¹å‘ç”Ÿï¼‰
                    used_broadcast_msgs.clear()
                    msg = all_msgs[0]

                yield f"\n[{ts}] Talker: {msg}"
                last_broadcast_time = current_time
                broadcast_count += 1

                # é™åˆ¶æœ€å¤§æ’­æŠ¥æ¬¡æ•°
                if broadcast_count >= 8:
                    break

            # å°è¯•è·å–è¾“å‡º
            try:
                chunk = await asyncio.wait_for(talker_queue.get(), timeout=0.1)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äº¤ç»™Thinker
                if "[NEEDS_THINKER]" in chunk:
                    # è®°å½•Handoff
                    self._record_handoff(
                        HandoffType.DELEGATION,
                        "talker",
                        "thinker",
                        "ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡Talkerèƒ½åŠ›",
                    )

                    # åˆ‡æ¢åˆ°åä½œæ¨¡å¼
                    async for thinker_chunk in self._collaboration_handoff(
                        user_input, context, llm_request_time, received_time=received_time
                    ):
                        yield thinker_chunk
                    return

                # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå†…å®¹çš„æ—¶é—´
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                    # åœ¨å†…å®¹å‰æ˜¾ç¤ºTalkeræ—¶é—´æˆ³
                    if settings.SHOW_AGENT_IDENTITY and not first_timestamp_shown:
                        yield f"\n[{format_timestamp(first_token_time)}] Talker: "
                        first_timestamp_shown = True

                yield chunk

            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯æ£€æŸ¥æ’­æŠ¥
                continue

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, llm_request_time, first_token_time)

    def _format_metrics(self, metrics: dict, llm_request_time: float, first_token_time: float = None) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        lines = ["-" * 50]
        lines.append("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")

        # Tokenç»Ÿè®¡
        input_tokens = metrics.get("input_tokens", 0)
        output_tokens = metrics.get("output_tokens", 0)
        if input_tokens or output_tokens:
            lines.append(f"  Tokens: è¾“å…¥={input_tokens} | è¾“å‡º={output_tokens}")

        # æ—¶å»¶æŒ‡æ ‡
        ttft = metrics.get("ttft_ms", 0)
        tpot = metrics.get("tpot_ms", 0)
        total_time = metrics.get("total_time_ms", 0)

        if ttft:
            lines.append(f"  TTFT(é¦–Tokenå“åº”æ—¶å»¶): {ttft:.0f}ms")
        if total_time:
            lines.append(f"  å“åº”æ—¶å»¶(ç”Ÿæˆæ€»è€—æ—¶): {total_time:.0f}ms")
        if tpot:
            lines.append(f"  TPOT(å¹³å‡æ¯Tokenæ—¶å»¶): {tpot:.1f}ms")

        # TPSåå
        tps = metrics.get("tps", 0)
        if tps:
            lines.append(f"  TPS(æ¨¡å‹åå): {tps:.1f} tokens/s")

        # æ—¶é—´æˆ³
        lines.append(f"  LLMè¯·æ±‚å‘é€æ—¶é—´: {format_timestamp(llm_request_time)}")
        if first_token_time:
            lines.append(f"  LLMé¦–Tokenæ—¶é—´: {format_timestamp(first_token_time)}")
        lines.append("-" * 50)

        return "\n".join(lines)

    async def _collaboration_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        llm_request_time: float = None,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        åä½œæ¨¡å¼Handoff

        Talkeræ”¶é›†ä¿¡æ¯ï¼ŒThinkeræ·±åº¦å¤„ç†ï¼ŒTalkeræ’­æŠ¥
        å…³é”®æ”¹è¿›ï¼šç‹¬ç«‹äºThinkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        thinker_start = time.time()
        if llm_request_time is None:
            llm_request_time = thinker_start

        # é‡ç½®è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()
        self._progress_state.last_stage_change = thinker_start
        self._progress_state.last_broadcast = thinker_start - 3  # å…è®¸ç«‹å³æ’­æŠ¥

        # è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = context.get("shared")

        # ç¡®ä¿Thinkeræœ‰å…±äº«ä¸Šä¸‹æ–‡çš„å¼•ç”¨
        if shared:
            self.thinker.set_shared_context(shared)

        # Talkeré¦–å…ˆç»™ç”¨æˆ·åé¦ˆ
        if settings.SHOW_AGENT_IDENTITY:
            timestamp = format_timestamp(thinker_start)
            yield f"\n[{timestamp}] Talker: å¥½çš„ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦æ·±åº¦æ€è€ƒï¼Œå·²è½¬äº¤ç»™Thinkerå¤„ç†"

        # === æ¾„æ¸…æœºåˆ¶ï¼šæ£€æµ‹æ˜¯å¦éœ€è¦æ¾„æ¸… ===
        try:
            # å¿«é€Ÿè§„åˆ’ä»¥æ£€æµ‹æ˜¯å¦éœ€è¦æ¾„æ¸…
            quick_plan = await self.thinker.plan_task(user_input, context)
            needs_clarification, reason, missing_info = await self.thinker.needs_clarification(
                user_input, quick_plan, context
            )

            if needs_clarification and missing_info and shared:
                # ç”Ÿæˆæ¾„æ¸…é—®é¢˜
                question = await self.thinker.generate_clarification_question(
                    user_input, missing_info, context
                )

                # é€šè¿‡Talkerå‘ç”¨æˆ·æé—®
                ts = format_timestamp(time.time())
                yield f"\n[{ts}] Talker: {question}"

                # è®°å½•æ¾„æ¸…è¯·æ±‚
                shared.add_clarification_request(question, reason or "", [])

                # ç­‰å¾…ç”¨æˆ·å›ç­”ï¼ˆé€šè¿‡é˜Ÿåˆ—æœºåˆ¶ï¼‰
                # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ–¹å¼ï¼Œå®é™…å›ç­”ä¼šåœ¨ä¸‹ä¸€æ¬¡processä¸­å¤„ç†
                # å°†æ¾„æ¸…çŠ¶æ€ä¿å­˜åˆ°å…±äº«ä¸Šä¸‹æ–‡ä¾›ä¸‹æ¬¡ä½¿ç”¨
                shared.clarification_status = ClarificationStatus.PENDING

        except Exception:
            # æ¾„æ¸…æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸å¤„ç†
            pass

        # è®°å½•Handoffåˆ°Thinker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "talker",
            "thinker",
            "å¯åŠ¨åä½œæ¨¡å¼",
        )

        # Thinkerå¼€å§‹å·¥ä½œçš„æç¤º
        ts = format_timestamp(time.time())
        yield f"\n[{ts}] Thinker: å¼€å§‹å¤„ç†..."

        # æ”¶é›†Thinkerçš„è¾“å‡º
        thinker_output = []
        thinker_complete = False
        accumulated_output = ""
        thinker_first_token_shown = False

        # æ’­æŠ¥æ§åˆ¶ - ä½¿ç”¨ç‹¬ç«‹çš„æ—¶é—´æ£€æŸ¥ï¼ˆåŠ¨æ€é—´éš”ï¼‰
        last_broadcast_time = thinker_start

        def get_broadcast_interval(elapsed: float) -> float:
            """æ ¹æ®å·²è€—æ—¶åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš”"""
            # åˆå§‹é˜¶æ®µæ›´é¢‘ç¹ï¼ˆ2-3ç§’ï¼‰ï¼ŒåæœŸç¨³å®šåœ¨3-4ç§’
            if elapsed < 10:
                return 2.5  # åˆå§‹2.5ç§’
            elif elapsed < 20:
                return 3.0  # ä¸­æœŸ3ç§’
            else:
                return 4.0  # åæœŸ4ç§’ï¼ˆä¸Šé™ï¼‰
        output_index = 0

        async def run_thinker():
            """è¿è¡ŒThinkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal thinker_complete
            async for chunk in self.thinker.process(user_input, context):
                thinker_output.append(chunk)
            thinker_complete = True

        # å¯åŠ¨Thinkerä»»åŠ¡
        thinker_task = asyncio.create_task(run_thinker())

        # ä¸»å¾ªç¯ï¼šå¤„ç†Thinkerè¾“å‡ºå’Œæ’­æŠ¥
        while not thinker_complete or output_index < len(thinker_output):
            current_time = time.time()
            elapsed = current_time - thinker_start

            # === å…³é”®æ”¹è¿›ï¼šæ¯æ¬¡å¾ªç¯éƒ½æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥ ===
            # ä½¿ç”¨åŠ¨æ€é—´éš”ï¼šåˆå§‹é¢‘ç¹ï¼ŒåæœŸç¨³å®š
            broadcast_interval = get_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                # è§£æå½“å‰é˜¶æ®µï¼ˆåŸºäºå·²æœ‰è¾“å‡ºï¼‰
                new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥
                should_broadcast, reason = self._should_broadcast(new_stage, current_step, elapsed)

                if should_broadcast:
                    # ä½¿ç”¨å†…å®¹å“ˆå¸Œå»é‡
                    content_hash = self._hash_broadcast_content(new_stage, current_step, elapsed)
                    if content_hash not in self._progress_state.broadcast_history:
                        broadcast_msg = self._generate_stage_broadcast(
                            stage=new_stage,
                            user_query=user_input,
                            elapsed_time=elapsed,
                            current_step=current_step,
                            total_steps=total_steps,
                            step_desc=step_desc,
                        )

                        # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿æ¶ˆæ¯ä¸é‡å¤
                        if broadcast_msg != self._progress_state.last_broadcast_msg:
                            ts = format_timestamp(current_time)
                            yield f"\n[{ts}] Talker: {broadcast_msg}"
                            self._progress_state.last_broadcast = current_time
                            self._progress_state.last_broadcast_msg = broadcast_msg
                            self._progress_state.broadcast_count += 1
                            self._progress_state.broadcast_history.add(content_hash)

                        # æ›´æ–°çŠ¶æ€
                        if new_stage != self._progress_state.current_stage:
                            self._progress_state.current_stage = new_stage
                            self._progress_state.last_stage_change = current_time
                        self._progress_state.current_step = current_step
                        self._progress_state.total_steps = total_steps

                last_broadcast_time = current_time

            # === å¤„ç†Thinkerè¾“å‡º ===
            if output_index < len(thinker_output):
                chunk = thinker_output[output_index]
                output_index += 1
                accumulated_output += chunk

                # è§£æé˜¶æ®µï¼ˆç”¨äºçŠ¶æ€æ›´æ–°ï¼‰
                new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ›´æ–°çŠ¶æ€
                if new_stage != self._progress_state.current_stage:
                    self._progress_state.current_stage = new_stage
                    self._progress_state.last_stage_change = current_time
                self._progress_state.current_step = current_step
                self._progress_state.total_steps = total_steps

                # Thinkerè¾“å‡ºåŠ æ—¶é—´æˆ³
                if chunk.strip():
                    if not thinker_first_token_shown:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Thinker: "
                        thinker_first_token_shown = True
                    yield chunk
            else:
                # æ²¡æœ‰æ–°è¾“å‡ºæ—¶çŸ­æš‚ç­‰å¾…
                await asyncio.sleep(0.05)

        # ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½å·²å¤„ç†
        while output_index < len(thinker_output):
            chunk = thinker_output[output_index]
            output_index += 1
            if chunk.strip():
                if not thinker_first_token_shown:
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Thinker: "
                    thinker_first_token_shown = True
            yield chunk

        # è®°å½•Handoffå›Talker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "thinker",
            "talker",
            "Thinkerå¤„ç†å®Œæˆ",
        )

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, thinker_start, thinker_start)

    async def _parallel_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        å¹¶è¡Œæ¨¡å¼Handoff

        Talkerå’ŒThinkeråŒæ—¶å·¥ä½œ
        """
        # å¹¶è¡Œå¯åŠ¨
        talker_task = asyncio.create_task(
            self._collect_stream(self.talker.process(user_input, context))
        )
        thinker_task = asyncio.create_task(
            self._collect_stream(self.thinker.process(user_input, context))
        )

        # å…ˆè¿”å›Talkerçš„å¿«é€Ÿå“åº”
        talker_result = await talker_task
        yield "".join(talker_result)

        # ç­‰å¾…Thinkerå®Œæˆ
        thinker_result = await thinker_task

        # å¦‚æœThinkerçš„ç­”æ¡ˆæ›´å¥½ï¼Œè¡¥å……è¯´æ˜
        if thinker_result:
            yield "\n\nã€è¡¥å……è¯´æ˜ã€‘\n"
            yield "".join(thinker_result)

    async def _iterative_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        è¿­ä»£æ¨¡å¼Handoff

        Talkeræä¾›åˆæ­¥ç­”æ¡ˆï¼ŒThinkeræ ¹æ®ç”¨æˆ·åé¦ˆæ”¹è¿›
        """
        # Talkerå…ˆæä¾›åˆæ­¥ç­”æ¡ˆ
        yield "ã€åˆæ­¥ç­”æ¡ˆã€‘\n"
        async for chunk in self.talker.process(user_input, context):
            yield chunk

        yield "\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚"

    async def _collect_stream(self, stream: AsyncIterator[str]) -> List[str]:
        """æ”¶é›†æµå¼è¾“å‡º"""
        result = []
        async for chunk in stream:
            result.append(chunk)
        return result

    async def _get_or_create_session(self, session_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆä½¿ç”¨SessionContextæŒä¹…åŒ–ï¼‰"""
        if not await self.session_context.exists(session_id):
            await self.session_context.set_session_data(session_id, "created_at", time.time())
            await self.session_context.set_session_data(session_id, "state", "active")

        # è¿”å›å…¼å®¹æ ¼å¼
        messages = await self.session_context.get_messages(session_id, limit=100)
        return {
            "messages": [m.to_dict() for m in messages],
            "created_at": await self.session_context.get_session_data(session_id, "created_at", time.time()),
            "state": await self.session_context.get_session_data(session_id, "state", "active"),
        }

    def _get_or_create_shared_context(self, session_id: str, user_input: str = "") -> SharedContext:
        """è·å–æˆ–åˆ›å»ºå…±äº«ä¸Šä¸‹æ–‡"""
        if session_id not in self._shared_contexts:
            self._shared_contexts[session_id] = SharedContext(user_input=user_input)
        elif user_input:
            self._shared_contexts[session_id].user_input = user_input
        return self._shared_contexts[session_id]

    def _record_handoff(
        self,
        handoff_type: HandoffType,
        from_agent: str,
        to_agent: str,
        reason: str,
    ) -> None:
        """è®°å½•Handoff"""
        self._stats["handoffs"] += 1
        handoff = HandoffContext(
            handoff_type=handoff_type,
            from_agent=from_agent,
            to_agent=to_agent,
            reason=reason,
        )
        self._handoff_history.append(handoff)

        # è§¦å‘å›è°ƒ
        if self._on_handoff:
            asyncio.create_task(self._on_handoff(handoff))

    async def _handle_progress(self, progress_info: Dict[str, Any]) -> None:
        """å¤„ç†è¿›åº¦æ›´æ–°"""
        if self._on_progress:
            await self._on_progress(progress_info)

    async def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        if await self.session_context.exists(session_id):
            return await self._get_or_create_session(session_id)
        return None

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "active_sessions": len(self._shared_contexts),
            "recent_handoffs": len(self._handoff_history[-10:]),
            "talker_stats": self.talker.get_stats(),
            "thinker_stats": self.thinker.get_stats(),
        }

    def get_handoff_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–Handoffå†å²"""
        return [
            {
                "type": h.handoff_type.value,
                "from": h.from_agent,
                "to": h.to_agent,
                "reason": h.reason,
                "timestamp": h.timestamp,
            }
            for h in self._handoff_history[-limit:]
        ]

    async def clear_session(self, session_id: str) -> None:
        """æ¸…é™¤ä¼šè¯"""
        await self.session_context.delete_session(session_id)
        if session_id in self._shared_contexts:
            del self._shared_contexts[session_id]

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self.talker.reset_stats()
        self.thinker.reset_stats()
