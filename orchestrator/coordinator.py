"""
Orchestrator - åè°ƒå™¨
ç®¡ç†Talkerå’ŒThinkerçš„ååŒå·¥ä½œ
"""
import asyncio
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from config import settings
from context.types import AgentRole, HandoffType, Message, ResponseLayer, Task, TaskComplexity
from agents.talker.agent import TalkerAgent
from agents.thinker.agent import ThinkerAgent
from orchestrator.scheduler import TaskScheduler, ComplexityBasedScheduler


class ThinkerStage(Enum):
    """Thinkerå¤„ç†é˜¶æ®µ"""
    IDLE = "idle"
    ANALYZING = "analyzing"      # æ€è€ƒ/åˆ†æ
    PLANNING = "planning"        # è§„åˆ’
    EXECUTING = "executing"      # æ‰§è¡Œæ­¥éª¤
    SYNTHESIZING = "synthesizing"  # æ•´åˆ/ç”Ÿæˆç­”æ¡ˆ
    COMPLETED = "completed"


@dataclass
class ProgressState:
    """è¿›åº¦çŠ¶æ€è·Ÿè¸ª"""
    current_stage: ThinkerStage = ThinkerStage.IDLE
    last_stage_change: float = 0
    last_broadcast: float = 0
    last_broadcast_msg: str = ""
    broadcast_count: int = 0
    current_step: int = 0
    total_steps: int = 0
    step_description: str = ""


@dataclass
class HandoffContext:
    """Handoffä¸Šä¸‹æ–‡"""
    handoff_type: HandoffType
    from_agent: str
    to_agent: str
    reason: str
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)


class Orchestrator:
    """
    Orchestrator - åè°ƒå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. ä»»åŠ¡è°ƒåº¦å’Œè·¯ç”±
    2. Agentä¹‹é—´çš„Handoffç®¡ç†
    3. ä¸Šä¸‹æ–‡åŒæ­¥
    4. çŠ¶æ€ç»´æŠ¤
    """

    def __init__(
        self,
        talker: Optional[TalkerAgent] = None,
        thinker: Optional[ThinkerAgent] = None,
        task_scheduler: Optional[TaskScheduler] = None,
    ):
        # Agentå®ä¾‹
        self.talker = talker or TalkerAgent()
        self.thinker = thinker or ThinkerAgent()

        # è°ƒåº¦å™¨
        self.task_scheduler = task_scheduler or TaskScheduler()
        self.complexity_scheduler = ComplexityBasedScheduler()

        # ä¼šè¯çŠ¶æ€
        self._sessions: Dict[str, Dict[str, Any]] = {}
        self._handoff_history: List[HandoffContext] = []

        # å›è°ƒå‡½æ•°
        self._on_response: Optional[Callable] = None
        self._on_handoff: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None

        # è®¾ç½®è¿›åº¦å›è°ƒ
        self.talker.set_progress_callback(self._handle_progress)
        self.thinker.set_progress_callback(self._handle_progress)

        # ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }

        # è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()

    def _parse_thinker_stage(self, output: str) -> tuple[ThinkerStage, int, int, str]:
        """
        è§£æThinkerè¾“å‡ºï¼Œè¯†åˆ«å½“å‰é˜¶æ®µ

        Returns:
            tuple: (é˜¶æ®µ, å½“å‰æ­¥éª¤, æ€»æ­¥éª¤, æ­¥éª¤æè¿°)
        """
        stage = self._progress_state.current_stage
        current_step = self._progress_state.current_step
        total_steps = self._progress_state.total_steps
        step_desc = ""

        # æ£€æµ‹é˜¶æ®µå˜åŒ–
        if "[æ€è€ƒ]" in output or "æ­£åœ¨åˆ†æ" in output:
            stage = ThinkerStage.ANALYZING
        elif "[è§„åˆ’]" in output:
            stage = ThinkerStage.PLANNING
            # å°è¯•è§£ææ€»æ­¥éª¤æ•°
            steps_match = re.search(r"å…±(\d+)ä¸ªæ­¥éª¤", output)
            if steps_match:
                total_steps = int(steps_match.group(1))
        elif "[æ­¥éª¤" in output:
            stage = ThinkerStage.EXECUTING
            # è§£ææ­¥éª¤ä¿¡æ¯
            step_match = re.search(r"\[æ­¥éª¤(\d+)\]", output)
            if step_match:
                current_step = int(step_match.group(1))
            # è§£ææ­¥éª¤æè¿°
            desc_match = re.search(r"\[æ­¥éª¤\d+\]\s*(.+?)(?:\n|$)", output)
            if desc_match:
                step_desc = desc_match.group(1).strip()
        elif "[æ€è€ƒ] æ•´åˆ" in output or "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ" in output:
            stage = ThinkerStage.SYNTHESIZING
        elif "[ç­”æ¡ˆ]" in output:
            stage = ThinkerStage.COMPLETED

        return stage, current_step, total_steps, step_desc

    def _generate_stage_broadcast(
        self,
        stage: ThinkerStage,
        user_query: str,
        elapsed_time: float,
        current_step: int = 0,
        total_steps: int = 0,
        step_desc: str = "",
    ) -> str:
        """
        æ ¹æ®é˜¶æ®µç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯ï¼ˆåŸºäºä¸Šä¸‹æ–‡çš„åŠ¨æ€æ¶ˆæ¯ï¼‰
        """
        # ä»ç”¨æˆ·é—®é¢˜ä¸­æå–å…³é”®ä¿¡æ¯
        query_lower = user_query.lower()

        # æå–ä¸»é¢˜
        topic = self._extract_topic(user_query)

        # æ ¹æ®é˜¶æ®µå’Œå·²æ’­æŠ¥æ¬¡æ•°ç”Ÿæˆä¸åŒé£æ ¼çš„æ¶ˆæ¯
        broadcast_count = self._progress_state.broadcast_count

        if stage == ThinkerStage.ANALYZING:
            if broadcast_count == 0:
                return f"æ­£åœ¨ç†è§£æ‚¨å…³äºã€Œ{topic}ã€çš„éœ€æ±‚..."
            elif broadcast_count < 2:
                return "æ­£åœ¨æ¢³ç†å…³é”®è¦ç‚¹..."
            else:
                return f"åˆ†æä¸­ï¼Œé©¬ä¸Šå°±å¥½... (å·²è€—æ—¶ {elapsed_time:.0f}s)"

        elif stage == ThinkerStage.PLANNING:
            if broadcast_count == 0:
                return f"å·²ç†è§£éœ€æ±‚ï¼Œæ­£åœ¨åˆ¶å®š{topic}åˆ†ææ–¹æ¡ˆ..."
            elif broadcast_count < 2:
                return "æ­£åœ¨è®¾è®¡æœ€ä¼˜åˆ†æè·¯å¾„..."
            else:
                return f"è§„åˆ’ä¸­ï¼Œè¯·ç¨å€™... (å·²è€—æ—¶ {elapsed_time:.0f}s)"

        elif stage == ThinkerStage.EXECUTING:
            if total_steps > 0 and current_step > 0:
                progress_pct = int((current_step / total_steps) * 100)
                if step_desc:
                    return f"æ‰§è¡Œä¸­ ({progress_pct}%): {step_desc[:20]}..."
                return f"å·²å®Œæˆ {current_step}/{total_steps} ä¸ªæ­¥éª¤ ({progress_pct}%)..."
            return f"æ­£åœ¨å¤„ç†ä¸­... (å·²è€—æ—¶ {elapsed_time:.0f}s)"

        elif stage == ThinkerStage.SYNTHESIZING:
            if broadcast_count == 0:
                return "æ­£åœ¨æ•´åˆåˆ†æç»“æœ..."
            else:
                return "å³å°†å®Œæˆï¼Œæ­£åœ¨æ•´ç†ç­”æ¡ˆ..."

        return f"å¤„ç†ä¸­... (å·²è€—æ—¶ {elapsed_time:.0f}s)"

    def _extract_topic(self, query: str) -> str:
        """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–ä¸»é¢˜"""
        query_lower = query.lower()

        topic_keywords = {
            "é€‰è½¦": ["è½¦", "æ±½è½¦", "è½¦å‹", "å“ç‰Œ", "suv", "è½¿è½¦", "ä¹°è½¦", "é€‰è½¦"],
            "æ—…æ¸¸": ["æ—…æ¸¸", "æ—…è¡Œ", "æ™¯ç‚¹", "é…’åº—", "æœºç¥¨", "å»å“ª"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "é¤å…", "èœ", "åƒ", "æ¨èèœ"],
            "è´­ç‰©": ["ä¹°", "è´­ç‰©", "ä»·æ ¼", "ä¾¿å®œ", "å¯¹æ¯”"],
            "å’–å•¡": ["å’–å•¡", "æ‹¿é“", "æ˜Ÿå·´å…‹", "ç‘å¹¸"],
            "æ‰“è½¦": ["æ‰“è½¦", "æ»´æ»´", "é«˜å¾·", "ä¸“è½¦", "å¿«è½¦"],
        }

        for topic, keywords in topic_keywords.items():
            if any(kw in query_lower for kw in keywords):
                return topic

        # æå–é—®é¢˜ä¸­çš„å…³é”®è¯ä½œä¸ºä¸»é¢˜
        words = re.findall(r'[\u4e00-\u9fa5]{2,4}', query)
        if words:
            return words[0]
        return "æ‚¨çš„é—®é¢˜"

    def _should_broadcast(
        self,
        new_stage: ThinkerStage,
        current_step: int,
        elapsed_time: float,
    ) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ’­æŠ¥

        Returns:
            tuple: (æ˜¯å¦æ’­æŠ¥, åŸå› )
        """
        state = self._progress_state
        current_time = time.time()

        # æ ¹æ®é˜¶æ®µè°ƒæ•´æ’­æŠ¥é—´éš”
        if new_stage == ThinkerStage.ANALYZING:
            min_interval = 5.0
        elif new_stage == ThinkerStage.PLANNING:
            min_interval = 8.0  # è§„åˆ’é˜¶æ®µå¯èƒ½è¾ƒé•¿
        elif new_stage == ThinkerStage.EXECUTING:
            min_interval = 5.0
        else:
            min_interval = 6.0

        # é˜¶æ®µå˜åŒ–ï¼Œç«‹å³æ’­æŠ¥
        if new_stage != state.current_stage:
            return True, "stage_changed"

        # æ­¥éª¤å˜åŒ–ï¼ˆæ‰§è¡Œé˜¶æ®µï¼‰
        if new_stage == ThinkerStage.EXECUTING and current_step != state.current_step and current_step > 0:
            return True, "step_changed"

        # åŒé˜¶æ®µå†…ï¼Œæ£€æŸ¥æ—¶é—´é—´éš”
        if current_time - state.last_broadcast >= min_interval:
            # é™åˆ¶æ€»æ’­æŠ¥æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™æ’­æŠ¥ï¼‰
            if state.broadcast_count < 8:
                return True, "interval_elapsed"

        return False, "skip"

    def set_callbacks(
        self,
        on_response: Optional[Callable] = None,
        on_handoff: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
    ) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_response = on_response
        self._on_handoff = on_handoff
        self._on_progress = on_progress

    async def process(
        self,
        user_input: str,
        session_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        received_time: Optional[float] = None,
    ) -> AsyncIterator[str]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡
            received_time: æ¶ˆæ¯æ¥æ”¶æ—¶é—´

        Yields:
            str: å“åº”å†…å®¹
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        if received_time is None:
            received_time = start_time

        # åˆå§‹åŒ–ä¼šè¯
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())

        session = self._get_or_create_session(session_id)
        session["messages"].append({
            "role": "user",
            "content": user_input,
            "timestamp": time.time(),
        })

        # æ„å»ºä¸Šä¸‹æ–‡
        full_context = {
            **(context or {}),
            "session_id": session_id,
            "messages": session["messages"],
            "received_time": received_time,
        }

        # æ”¶é›†åŠ©æ‰‹å“åº”ç”¨äºä¿å­˜åˆ°ä¼šè¯
        assistant_response_chunks = []

        try:
            # ä½¿ç”¨Talkerè¿›è¡Œæ„å›¾åˆ†ç±»
            classification = await self.talker.classify_intent(user_input, full_context)

            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
            if classification.complexity == TaskComplexity.COMPLEX:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨åä½œæ¨¡å¼
                self._stats["thinker_handled"] += 1
                async for chunk in self._collaboration_handoff(
                    user_input, full_context, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk
            else:
                # ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼šTalkerå¤„ç†
                self._stats["talker_handled"] += 1
                async for chunk in self._delegation_handoff(
                    user_input, full_context, classification, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk

        except Exception as e:
            self._stats["errors"] += 1
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            assistant_response_chunks.append(error_msg)
            yield error_msg

        finally:
            # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°ä¼šè¯ï¼ˆæ¸…ç†æ‰å…ƒæ•°æ®æ ‡è®°ï¼‰
            assistant_response = "".join(assistant_response_chunks)
            # ç§»é™¤æ—¶é—´æˆ³å’ŒAgentæ ‡è¯†ç­‰å…ƒæ•°æ®ï¼Œåªä¿ç•™å®é™…å›å¤å†…å®¹
            # ç§»é™¤ç±»ä¼¼ [HH:MM:SS.mmm] Talker: çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[\d{2}:\d{2}:\d{2}\.\d{3}\]\s*(Talker|Thinker):\s*', '', assistant_response)
            # ç§»é™¤ç±»ä¼¼ [Talker] ... çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker\][^\n]*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker\][^\n]*', '', clean_response)
            # ç§»é™¤ [Talker -> Thinker | ...] çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker[^\]]*\]\s*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker[^\]]*\]\s*', '', clean_response)
            # ç§»é™¤æ€§èƒ½æŒ‡æ ‡åŒºå—ï¼ˆåŒ…å«ğŸ“Šç¬¦å·çš„éƒ¨åˆ†ï¼‰
            clean_response = re.sub(r'\n-{10,}.*?-{10,}', '', clean_response, flags=re.DOTALL)
            # ç§»é™¤å‰©ä½™çš„æŒ‡æ ‡è¡Œ
            clean_response = re.sub(r'\n\s*ğŸ“Š[^\n]*', '', clean_response)
            clean_response = re.sub(r'\n\s*(Tokens|TTFT|TPOT|TPS|æ€»ç”Ÿæˆæ—¶å»¶|LLMè¯·æ±‚æ—¶é—´)[^\n]*', '', clean_response)
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            clean_response = re.sub(r'\n{3,}', '\n\n', clean_response)
            clean_response = clean_response.strip()

            if clean_response:
                session["messages"].append({
                    "role": "assistant",
                    "content": clean_response,
                    "timestamp": time.time(),
                })

            elapsed = (time.time() - start_time) * 1000
            session["last_latency_ms"] = elapsed

    async def _delegation_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        classification,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        å§”æ‰˜æ¨¡å¼Handoff

        Talkerå¤„ç†ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å§”æ‰˜ç»™Thinker
        """
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        # è®°å½•LLMè¯·æ±‚å‘é€æ—¶é—´
        llm_request_time = time.time()

        # ä½¿ç”¨é˜Ÿåˆ—æ”¶é›†Talkerè¾“å‡º
        talker_queue = asyncio.Queue()
        talker_complete = False

        async def run_talker():
            """è¿è¡ŒTalkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal talker_complete
            async for chunk in self.talker.process(user_input, context):
                await talker_queue.put(chunk)
            talker_complete = True

        # å¯åŠ¨Talkerä»»åŠ¡
        talker_task = asyncio.create_task(run_talker())

        # å¤„ç†Talkerè¾“å‡º
        first_token_time = None
        first_timestamp_shown = False
        last_output_time = time.time()
        last_broadcast_time = time.time()
        broadcast_interval = 4.0  # 4ç§’æ— è¾“å‡ºåˆ™æ’­æŠ¥

        while not talker_complete or not talker_queue.empty():
            try:
                # å°è¯•è·å–è¾“å‡ºï¼Œå¸¦è¶…æ—¶
                chunk = await asyncio.wait_for(talker_queue.get(), timeout=0.5)
                last_output_time = time.time()

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äº¤ç»™Thinker
                if "[NEEDS_THINKER]" in chunk:
                    # è®°å½•Handoff
                    self._record_handoff(
                        HandoffType.DELEGATION,
                        "talker",
                        "thinker",
                        "ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡Talkerèƒ½åŠ›",
                    )

                    # åˆ‡æ¢åˆ°åä½œæ¨¡å¼
                    async for thinker_chunk in self._collaboration_handoff(
                        user_input, context, llm_request_time, received_time=received_time
                    ):
                        yield thinker_chunk
                    return

                # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå†…å®¹çš„æ—¶é—´
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                    # åœ¨å†…å®¹å‰æ˜¾ç¤ºTalkeræ—¶é—´æˆ³
                    if settings.SHOW_AGENT_IDENTITY and not first_timestamp_shown:
                        yield f"\n[{format_timestamp(first_token_time)}] Talker: "
                        first_timestamp_shown = True

                yield chunk

            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥
                current_time = time.time()
                if current_time - last_output_time >= broadcast_interval:
                    elapsed = current_time - llm_request_time
                    ts = format_timestamp(current_time)

                    # åŠ¨æ€æ’­æŠ¥å†…å®¹
                    if elapsed < 10:
                        msg = "æ­£åœ¨å¤„ç†..."
                    elif elapsed < 20:
                        msg = f"ä»åœ¨å¤„ç†ä¸­... (å·²è€—æ—¶ {elapsed:.0f}s)"
                    else:
                        msg = f"å“åº”è¾ƒæ…¢ï¼Œè¯·ç¨å€™... (å·²è€—æ—¶ {elapsed:.0f}s)"

                    yield f"\n[{ts}] Talker: {msg}"
                    last_output_time = current_time
                    last_broadcast_time = current_time

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, llm_request_time, first_token_time)

    def _format_metrics(self, metrics: dict, llm_request_time: float, first_token_time: float = None) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        lines = ["-" * 50]
        lines.append("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")

        # Tokenç»Ÿè®¡
        input_tokens = metrics.get("input_tokens", 0)
        output_tokens = metrics.get("output_tokens", 0)
        if input_tokens or output_tokens:
            lines.append(f"  Tokens: è¾“å…¥={input_tokens} | è¾“å‡º={output_tokens}")

        # æ—¶å»¶æŒ‡æ ‡
        ttft = metrics.get("ttft_ms", 0)
        tpot = metrics.get("tpot_ms", 0)
        total_time = metrics.get("total_time_ms", 0)

        if ttft:
            lines.append(f"  TTFT(é¦–Tokenå“åº”æ—¶å»¶): {ttft:.0f}ms")
        if total_time:
            lines.append(f"  å“åº”æ—¶å»¶(ç”Ÿæˆæ€»è€—æ—¶): {total_time:.0f}ms")
        if tpot:
            lines.append(f"  TPOT(å¹³å‡æ¯Tokenæ—¶å»¶): {tpot:.1f}ms")

        # TPSåå
        tps = metrics.get("tps", 0)
        if tps:
            lines.append(f"  TPS(æ¨¡å‹åå): {tps:.1f} tokens/s")

        # æ—¶é—´æˆ³
        lines.append(f"  LLMè¯·æ±‚å‘é€æ—¶é—´: {format_timestamp(llm_request_time)}")
        if first_token_time:
            lines.append(f"  LLMé¦–Tokenæ—¶é—´: {format_timestamp(first_token_time)}")
        lines.append("-" * 50)

        return "\n".join(lines)

    async def _collaboration_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        llm_request_time: float = None,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        åä½œæ¨¡å¼Handoff

        Talkeræ”¶é›†ä¿¡æ¯ï¼ŒThinkeræ·±åº¦å¤„ç†ï¼ŒTalkeræ’­æŠ¥
        """
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        thinker_start = time.time()
        if llm_request_time is None:
            llm_request_time = thinker_start

        # é‡ç½®è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()
        self._progress_state.last_stage_change = thinker_start
        self._progress_state.last_broadcast = thinker_start - 3  # å…è®¸ç«‹å³æ’­æŠ¥

        # Talkeré¦–å…ˆç»™ç”¨æˆ·åé¦ˆ
        if settings.SHOW_AGENT_IDENTITY:
            timestamp = format_timestamp(thinker_start)
            yield f"\n[{timestamp}] Talker: å¥½çš„ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦æ·±åº¦æ€è€ƒï¼Œå·²è½¬äº¤ç»™Thinkerå¤„ç†"

        # è®°å½•Handoffåˆ°Thinker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "talker",
            "thinker",
            "å¯åŠ¨åä½œæ¨¡å¼",
        )

        # æ”¶é›†Thinkerçš„è¾“å‡º
        thinker_output = []
        thinker_complete = False
        accumulated_output = ""
        thinker_first_token_shown = False
        last_broadcast_check = time.time()
        broadcast_check_interval = 2.0  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦æ’­æŠ¥

        async def run_thinker():
            """è¿è¡ŒThinkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal thinker_complete
            async for chunk in self.thinker.process(user_input, context):
                thinker_output.append(chunk)
            thinker_complete = True

        # å¯åŠ¨Thinkerä»»åŠ¡
        thinker_task = asyncio.create_task(run_thinker())

        # å¤„ç†Thinkerè¾“å‡º
        output_index = 0
        while not thinker_complete or output_index < len(thinker_output):
            current_time = time.time()
            elapsed = current_time - thinker_start

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„Thinkerè¾“å‡º
            if output_index < len(thinker_output):
                chunk = thinker_output[output_index]
                output_index += 1
                accumulated_output += chunk

                # è§£æå½“å‰é˜¶æ®µ
                new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥ï¼ˆé˜¶æ®µå˜åŒ–æˆ–æ­¥éª¤å˜åŒ–ï¼‰
                should_broadcast, reason = self._should_broadcast(new_stage, current_step, elapsed)

                if should_broadcast:
                    broadcast_msg = self._generate_stage_broadcast(
                        stage=new_stage,
                        user_query=user_input,
                        elapsed_time=elapsed,
                        current_step=current_step,
                        total_steps=total_steps,
                        step_desc=step_desc,
                    )

                    if broadcast_msg != self._progress_state.last_broadcast_msg:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Talker: {broadcast_msg}"
                        self._progress_state.last_broadcast = current_time
                        self._progress_state.last_broadcast_msg = broadcast_msg
                        self._progress_state.broadcast_count += 1

                # æ›´æ–°çŠ¶æ€
                if new_stage != self._progress_state.current_stage:
                    self._progress_state.current_stage = new_stage
                    self._progress_state.last_stage_change = current_time
                self._progress_state.current_step = current_step
                self._progress_state.total_steps = total_steps

                # Thinkerè¾“å‡ºåŠ æ—¶é—´æˆ³
                if chunk.strip():
                    if not thinker_first_token_shown:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Thinker: "
                        thinker_first_token_shown = True
                    yield chunk

                last_broadcast_check = current_time

            else:
                # æ²¡æœ‰æ–°è¾“å‡ºæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥ï¼ˆé•¿æ—¶é—´æ— å“åº”ï¼‰
                if current_time - last_broadcast_check >= broadcast_check_interval:
                    elapsed = current_time - thinker_start
                    should_broadcast, reason = self._should_broadcast(
                        self._progress_state.current_stage,
                        self._progress_state.current_step,
                        elapsed
                    )

                    if should_broadcast:
                        broadcast_msg = self._generate_stage_broadcast(
                            stage=self._progress_state.current_stage,
                            user_query=user_input,
                            elapsed_time=elapsed,
                            current_step=self._progress_state.current_step,
                            total_steps=self._progress_state.total_steps,
                            step_desc=self._progress_state.step_description,
                        )

                        if broadcast_msg != self._progress_state.last_broadcast_msg:
                            ts = format_timestamp(current_time)
                            yield f"\n[{ts}] Talker: {broadcast_msg}"
                            self._progress_state.last_broadcast = current_time
                            self._progress_state.last_broadcast_msg = broadcast_msg
                            self._progress_state.broadcast_count += 1

                    last_broadcast_check = current_time

                await asyncio.sleep(0.1)

        # ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½å·²å¤„ç†
        while output_index < len(thinker_output):
            chunk = thinker_output[output_index]
            output_index += 1
            if chunk.strip():
                if not thinker_first_token_shown:
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Thinker: "
                    thinker_first_token_shown = True
            yield chunk

        # è®°å½•Handoffå›Talker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "thinker",
            "talker",
            "Thinkerå¤„ç†å®Œæˆ",
        )

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, thinker_start, thinker_start)

    async def _parallel_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        å¹¶è¡Œæ¨¡å¼Handoff

        Talkerå’ŒThinkeråŒæ—¶å·¥ä½œ
        """
        # å¹¶è¡Œå¯åŠ¨
        talker_task = asyncio.create_task(
            self._collect_stream(self.talker.process(user_input, context))
        )
        thinker_task = asyncio.create_task(
            self._collect_stream(self.thinker.process(user_input, context))
        )

        # å…ˆè¿”å›Talkerçš„å¿«é€Ÿå“åº”
        talker_result = await talker_task
        yield "".join(talker_result)

        # ç­‰å¾…Thinkerå®Œæˆ
        thinker_result = await thinker_task

        # å¦‚æœThinkerçš„ç­”æ¡ˆæ›´å¥½ï¼Œè¡¥å……è¯´æ˜
        if thinker_result:
            yield "\n\nã€è¡¥å……è¯´æ˜ã€‘\n"
            yield "".join(thinker_result)

    async def _iterative_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        è¿­ä»£æ¨¡å¼Handoff

        Talkeræä¾›åˆæ­¥ç­”æ¡ˆï¼ŒThinkeræ ¹æ®ç”¨æˆ·åé¦ˆæ”¹è¿›
        """
        # Talkerå…ˆæä¾›åˆæ­¥ç­”æ¡ˆ
        yield "ã€åˆæ­¥ç­”æ¡ˆã€‘\n"
        async for chunk in self.talker.process(user_input, context):
            yield chunk

        yield "\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚"

    async def _collect_stream(self, stream: AsyncIterator[str]) -> List[str]:
        """æ”¶é›†æµå¼è¾“å‡º"""
        result = []
        async for chunk in stream:
            result.append(chunk)
        return result

    def _get_or_create_session(self, session_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id not in self._sessions:
            self._sessions[session_id] = {
                "messages": [],
                "created_at": time.time(),
                "state": "active",
            }
        return self._sessions[session_id]

    def _record_handoff(
        self,
        handoff_type: HandoffType,
        from_agent: str,
        to_agent: str,
        reason: str,
    ) -> None:
        """è®°å½•Handoff"""
        self._stats["handoffs"] += 1
        handoff = HandoffContext(
            handoff_type=handoff_type,
            from_agent=from_agent,
            to_agent=to_agent,
            reason=reason,
        )
        self._handoff_history.append(handoff)

        # è§¦å‘å›è°ƒ
        if self._on_handoff:
            asyncio.create_task(self._on_handoff(handoff))

    async def _handle_progress(self, progress_info: Dict[str, Any]) -> None:
        """å¤„ç†è¿›åº¦æ›´æ–°"""
        if self._on_progress:
            await self._on_progress(progress_info)

    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return self._sessions.get(session_id)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "active_sessions": len(self._sessions),
            "recent_handoffs": len(self._handoff_history[-10:]),
            "talker_stats": self.talker.get_stats(),
            "thinker_stats": self.thinker.get_stats(),
        }

    def get_handoff_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–Handoffå†å²"""
        return [
            {
                "type": h.handoff_type.value,
                "from": h.from_agent,
                "to": h.to_agent,
                "reason": h.reason,
                "timestamp": h.timestamp,
            }
            for h in self._handoff_history[-limit:]
        ]

    def clear_session(self, session_id: str) -> None:
        """æ¸…é™¤ä¼šè¯"""
        if session_id in self._sessions:
            del self._sessions[session_id]

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self.talker.reset_stats()
        self.thinker.reset_stats()
