"""
Orchestrator - åè°ƒå™¨
ç®¡ç†Talkerå’ŒThinkerçš„ååŒå·¥ä½œ
"""
import asyncio
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from config import settings
from context.types import AgentRole, HandoffType, Message, ResponseLayer, Task, TaskComplexity
from context.session_context import SessionContext
from context.shared_context import SharedContext, ClarificationStatus
from context.summarizer import ConversationSummarizer
from agents.talker.agent import TalkerAgent
from agents.thinker.agent import ThinkerAgent
from orchestrator.scheduler import TaskScheduler, ComplexityBasedScheduler
from skills.engine import SkillsEngine
from skills.invoker import SkillInvoker
from skills.examples import (
    WeatherSkill,
    SearchSkill,
    KnowledgeSearchSkill,
    CalculatorSkill,
    UnitConverterSkill,
)


class ThinkerStage(Enum):
    """Thinkerå¤„ç†é˜¶æ®µ"""
    IDLE = "idle"
    ANALYZING = "analyzing"      # æ€è€ƒ/åˆ†æ
    PLANNING = "planning"        # è§„åˆ’
    EXECUTING = "executing"      # æ‰§è¡Œæ­¥éª¤
    SYNTHESIZING = "synthesizing"  # æ•´åˆ/ç”Ÿæˆç­”æ¡ˆ
    COMPLETED = "completed"


@dataclass
class ProgressState:
    """è¿›åº¦çŠ¶æ€è·Ÿè¸ª"""
    current_stage: ThinkerStage = ThinkerStage.IDLE
    last_stage_change: float = 0
    last_broadcast: float = 0
    last_broadcast_msg_template: str = ""  # æ¶ˆæ¯æ¨¡æ¿ï¼ˆä¸å«æ—¶é—´ï¼‰
    broadcast_count: int = 0
    current_step: int = 0
    total_steps: int = 0
    step_description: str = ""
    broadcast_history: set = field(default_factory=set)
    last_content_hash: str = ""
    used_message_templates: Dict[str, set] = field(default_factory=dict)  # æŒ‰é˜¶æ®µè®°å½•å·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿
    recent_message_fingerprints: List[str] = field(default_factory=list)  # æœ€è¿‘æ¶ˆæ¯æŒ‡çº¹ï¼ˆç”¨äºè¯­ä¹‰å»é‡ï¼‰


@dataclass
class HandoffContext:
    """Handoffä¸Šä¸‹æ–‡"""
    handoff_type: HandoffType
    from_agent: str
    to_agent: str
    reason: str
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)


class Orchestrator:
    """
    Orchestrator - åè°ƒå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. ä»»åŠ¡è°ƒåº¦å’Œè·¯ç”±
    2. Agentä¹‹é—´çš„Handoffç®¡ç†
    3. ä¸Šä¸‹æ–‡åŒæ­¥
    4. çŠ¶æ€ç»´æŠ¤
    """

    def __init__(
        self,
        talker: Optional[TalkerAgent] = None,
        thinker: Optional[ThinkerAgent] = None,
        task_scheduler: Optional[TaskScheduler] = None,
        session_context: Optional[SessionContext] = None,
        skills_engine: Optional[SkillsEngine] = None,
        summarizer: Optional[ConversationSummarizer] = None,
    ):
        # Agentå®ä¾‹
        self.talker = talker or TalkerAgent()
        self.thinker = thinker or ThinkerAgent()

        # è°ƒåº¦å™¨
        self.task_scheduler = task_scheduler or TaskScheduler()
        self.complexity_scheduler = ComplexityBasedScheduler()

        # ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒRedisæŒä¹…åŒ–ï¼Œä¸å¯ç”¨æ—¶é™çº§åˆ°å†…å­˜ï¼‰
        self.session_context = session_context or SessionContext()

        # å…±äº«ä¸Šä¸‹æ–‡ï¼ˆTalkerå’ŒThinkerä¹‹é—´å…±äº«ï¼‰
        self._shared_contexts: Dict[str, SharedContext] = {}

        # Skillså¼•æ“å’Œè°ƒç”¨å™¨
        self.skills_engine = skills_engine or SkillsEngine()
        self.skill_invoker = SkillInvoker(self.skills_engine)
        self._initialize_default_skills()

        # å°†SkillInvokeræ³¨å…¥åˆ°Thinker
        self.thinker.set_skill_invoker(self.skill_invoker)

        # å¯¹è¯æ‘˜è¦å™¨ï¼ˆç”¨äºé•¿å¯¹è¯å‹ç¼©ï¼‰
        self.summarizer = summarizer or ConversationSummarizer(
            summary_threshold=settings.SUMMARY_THRESHOLD
        )

        # Handoffå†å²
        self._handoff_history: List[HandoffContext] = []

        # å›è°ƒå‡½æ•°
        self._on_response: Optional[Callable] = None
        self._on_handoff: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None

        # è®¾ç½®è¿›åº¦å›è°ƒ
        self.talker.set_progress_callback(self._handle_progress)
        self.thinker.set_progress_callback(self._handle_progress)

        # ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self._precheck_timeout_s = 15.0

        # è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()

    def _initialize_default_skills(self) -> None:
        """åˆå§‹åŒ–é»˜è®¤æŠ€èƒ½"""
        default_skills = [
            WeatherSkill(),
            SearchSkill(),
            KnowledgeSearchSkill(),
            CalculatorSkill(),
            UnitConverterSkill(),
        ]
        for skill in default_skills:
            self.skills_engine.register_skill(skill)

    def _parse_thinker_stage(self, output: str) -> tuple[ThinkerStage, int, int, str]:
        """
        è§£æThinkerè¾“å‡ºï¼Œè¯†åˆ«å½“å‰é˜¶æ®µ

        Returns:
            tuple: (é˜¶æ®µ, å½“å‰æ­¥éª¤, æ€»æ­¥éª¤, æ­¥éª¤æè¿°)
        """
        stage = self._progress_state.current_stage
        current_step = self._progress_state.current_step
        total_steps = self._progress_state.total_steps
        step_desc = ""

        # æ£€æµ‹é˜¶æ®µå˜åŒ–
        if "[æ€è€ƒ]" in output or "æ­£åœ¨åˆ†æ" in output:
            stage = ThinkerStage.ANALYZING
        elif "[è§„åˆ’]" in output:
            stage = ThinkerStage.PLANNING
            # å°è¯•è§£ææ€»æ­¥éª¤æ•°
            steps_match = re.search(r"å…±(\d+)ä¸ªæ­¥éª¤", output)
            if steps_match:
                total_steps = int(steps_match.group(1))
        elif "[æ­¥éª¤" in output:
            stage = ThinkerStage.EXECUTING
            # è§£ææ­¥éª¤ä¿¡æ¯
            step_match = re.search(r"\[æ­¥éª¤(\d+)\]", output)
            if step_match:
                current_step = int(step_match.group(1))
            # è§£ææ­¥éª¤æè¿°
            desc_match = re.search(r"\[æ­¥éª¤\d+\]\s*(.+?)(?:\n|$)", output)
            if desc_match:
                step_desc = desc_match.group(1).strip()
        elif "[æ€è€ƒ] æ•´åˆ" in output or "ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ" in output:
            stage = ThinkerStage.SYNTHESIZING
        elif "[ç­”æ¡ˆ]" in output:
            stage = ThinkerStage.COMPLETED

        return stage, current_step, total_steps, step_desc

    def _stage_from_shared_progress(self, stage_name: str) -> ThinkerStage:
        """å°†SharedContextä¸­çš„é˜¶æ®µåæ˜ å°„ä¸ºThinkerStageã€‚"""
        mapping = {
            "idle": ThinkerStage.IDLE,
            "analyzing": ThinkerStage.ANALYZING,
            "planning": ThinkerStage.PLANNING,
            "executing": ThinkerStage.EXECUTING,
            "synthesizing": ThinkerStage.SYNTHESIZING,
            "completed": ThinkerStage.COMPLETED,
        }
        return mapping.get((stage_name or "").lower(), ThinkerStage.IDLE)

    def _latest_shared_step_desc(self, shared: Optional[SharedContext]) -> str:
        """ä»SharedContextæå–æœ€è¿‘çš„Thinkeré˜¶æ®µè¯´æ˜ã€‚"""
        if not shared:
            return ""
        partials = shared.thinker_progress.partial_results
        if not partials:
            return ""
        desc = (partials[-1] or "").strip()
        return desc[:30]


    def _is_semantic_duplicate(self, message_text: str) -> bool:
        """æ£€æµ‹æ¶ˆæ¯æ˜¯å¦ä¸ºè¯­ä¹‰é‡å¤"""
        # è®¡ç®—æ¶ˆæ¯çš„è¯­ä¹‰æŒ‡çº¹ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        keywords = self._extract_semantic_keywords(message_text)
        fingerprint = f"{self._progress_state.current_stage.value}:{keywords}"

        # æ£€æŸ¥æœ€è¿‘ N æ¡æ¶ˆæ¯
        recent_fingerprints = self._progress_state.recent_message_fingerprints[-5:]
        if fingerprint in recent_fingerprints:
            return True

        # æ·»åŠ æ–°æŒ‡çº¹
        self._progress_state.recent_message_fingerprints.append(fingerprint)
        # é™åˆ¶åˆ—è¡¨é•¿åº¦
        if len(self._progress_state.recent_message_fingerprints) > 10:
            self._progress_state.recent_message_fingerprints = self._progress_state.recent_message_fingerprints[-10:]
        return False

    def _extract_semantic_keywords(self, text: str) -> str:
        """æå–æ¶ˆæ¯çš„è¯­ä¹‰å…³é”®è¯"""
        # ç§»é™¤æ—¶é—´æˆ³ã€è¿›åº¦æ¡ç­‰å˜é‡
        text = re.sub(r'\d+s', '', text)
        text = re.sub(r'\[.+?\]', '', text)
        text = re.sub(r'[â–‘â–ˆ\d%]', '', text)

        # ä¿ç•™æ ¸å¿ƒåŠ¨è¯å’Œåè¯
        keywords = re.findall(r'[æ•´åˆ | åˆ†æ | è§„åˆ’ | æ‰§è¡Œ | æ£€æŸ¥ | ä¼˜åŒ– | ç­”æ¡ˆ | ç»“æœ | æ­¥éª¤]', text)
        return ''.join(sorted(set(keywords)))

    def _generate_stage_broadcast(
        self,
        stage: ThinkerStage,
        user_query: str,
        elapsed_time: float,
        current_step: int = 0,
        total_steps: int = 0,
        step_desc: str = "",
        partial_results: Optional[List[str]] = None,
    ) -> tuple[str, str]:
        """
        æ ¹æ®é˜¶æ®µç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯

        Returns:
            tuple: (å®Œæ•´æ¶ˆæ¯, æ¶ˆæ¯æ¨¡æ¿)
            æ¶ˆæ¯æ¨¡æ¿ç”¨äºå»é‡ï¼Œä¸å«æ—¶é—´æˆ³
        """
        # æå–ä¸»é¢˜
        topic = self._extract_topic(user_query)
        stage_key = stage.value

        # è·å–è¯¥é˜¶æ®µå·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿é›†åˆ
        if stage_key not in self._progress_state.used_message_templates:
            self._progress_state.used_message_templates[stage_key] = set()

        used_templates = self._progress_state.used_message_templates[stage_key]

        # æ ¹æ®å·²è€—æ—¶é€‰æ‹©æ’­æŠ¥é£æ ¼
        if elapsed_time < 10:
            style = "initial"
        elif elapsed_time < 30:
            style = "progress"
        else:
            style = "long_wait"

        def get_unused_template(templates: list, used_set: set) -> str:
            """ä»æœªä½¿ç”¨çš„æ¨¡æ¿ä¸­é€‰æ‹©ä¸€ä¸ª"""
            for t in templates:
                if t not in used_set:
                    used_set.add(t)
                    return t
            # æ‰€æœ‰æ¨¡æ¿éƒ½ç”¨è¿‡äº†ï¼Œè¿”å›é»˜è®¤
            return templates[0]

        if stage == ThinkerStage.IDLE:
            if style == "initial":
                templates = [
                    f"æ·±åº¦æ€è€ƒæ¨¡å—å·²æ¥æ‰‹ï¼Œæ­£åœ¨åŠ è½½å…³äºã€Œ{topic}ã€çš„ä¸Šä¸‹æ–‡",
                    "æ­£åœ¨å‡†å¤‡åˆ†æç¯å¢ƒ",
                    f"æ­£åœ¨åŒæ­¥ã€Œ{topic}ã€ç›¸å…³ä¿¡æ¯",
                ]
            elif style == "progress":
                templates = [
                    f"ä»åœ¨å‡†å¤‡ã€Œ{topic}ã€åˆ†æï¼Œè¯·ç¨å€™",
                    f"å³å°†å¼€å§‹åˆ†æã€Œ{topic}ã€",
                ]
            else:
                templates = ["å‡†å¤‡å·¥ä½œè¿›è¡Œä¸­"]

            template = get_unused_template(templates, used_templates)
            if template == "å‡†å¤‡å·¥ä½œè¿›è¡Œä¸­":
                return f"{template} ({elapsed_time:.0f}s)...", template
            # æ³¨å…¥ä¸­é—´ç»“æœåˆ°æ’­æŠ¥
            if partial_results and partial_results[-1]:
                latest = partial_results[-1][:25]
                return f"{template}ï¼ˆ{latest}ï¼‰...", template
            return f"{template}...", template

        if stage == ThinkerStage.ANALYZING:
            if style == "initial":
                templates = [
                    f"æ­£åœ¨ç†è§£æ‚¨å…³äºã€Œ{topic}ã€çš„éœ€æ±‚",
                    f"æ­£åœ¨åˆ†æã€Œ{topic}ã€é—®é¢˜å…³é”®ç‚¹",
                    f"æ¢³ç†ã€Œ{topic}ã€ç›¸å…³ä¿¡æ¯",
                ]
            elif style == "progress":
                templates = [
                    f"æ·±åº¦åˆ†æã€Œ{topic}ã€ä¸­ï¼Œè¯·ç¨å€™",
                    f"æ­£åœ¨æå–ã€Œ{topic}ã€å…³é”®è¦ç´ ",
                ]
            else:
                # é•¿æ—¶é—´ç­‰å¾…ï¼Œæ˜¾ç¤ºå·²ç”¨æ—¶é—´
                templates = [f"ã€Œ{topic}ã€åˆ†æè¿›è¡Œä¸­"]  # ä¸å«æ—¶é—´ï¼Œæ—¶é—´å•ç‹¬æ˜¾ç¤º

            template = get_unused_template(templates, used_templates)
            # å¦‚æœæ˜¯"åˆ†æè¿›è¡Œä¸­"ï¼ŒåŠ ä¸Šæ—¶é—´
            if "åˆ†æè¿›è¡Œä¸­" in template:
                return f"{template} ({elapsed_time:.0f}s)...", template
            # æ³¨å…¥ä¸­é—´ç»“æœåˆ°æ’­æŠ¥
            if partial_results and partial_results[-1]:
                latest = partial_results[-1][:25]
                return f"{template}ï¼ˆ{latest}ï¼‰...", template
            return f"{template}...", template

        elif stage == ThinkerStage.PLANNING:
            if style == "initial":
                templates = [
                    f"å·²ç†è§£ã€Œ{topic}ã€éœ€æ±‚ï¼Œæ­£åœ¨åˆ¶å®šæ–¹æ¡ˆ",
                    f"è§„åˆ’ã€Œ{topic}ã€æœ€ä¼˜è§£å†³è·¯å¾„",
                ]
            elif style == "progress":
                templates = [
                    f"ã€Œ{topic}ã€æ–¹æ¡ˆè®¾è®¡ä¸­",
                    f"æ­£åœ¨åˆ†è§£ã€Œ{topic}ã€ä»»åŠ¡æ­¥éª¤",
                ]
            else:
                templates = [f"ã€Œ{topic}ã€è§„åˆ’ä¸­"]

            template = get_unused_template(templates, used_templates)
            # æ³¨å…¥ä¸­é—´ç»“æœåˆ°æ’­æŠ¥
            if partial_results and partial_results[-1]:
                latest = partial_results[-1][:25]
                return f"{template}ï¼ˆ{latest}ï¼‰...", template
            return f"{template}...", template

        elif stage == ThinkerStage.EXECUTING:
            if total_steps > 0 and current_step > 0:
                progress_pct = int((current_step / total_steps) * 100)
                # æ¸…ç†æ­¥éª¤æè¿°ä¸­çš„å†—ä½™å†…å®¹
                clean_step_desc = step_desc.strip()
                # ç§»é™¤æ­¥éª¤æè¿°ä¸­çš„"æ­£åœ¨"ã€"æœç´¢"ç­‰å†—ä½™å‰ç¼€
                for prefix in ["æ­£åœ¨", "å¼€å§‹", "è¿›è¡Œ", "æœç´¢", "è·å–", "åˆ†æ"]:
                    if clean_step_desc.startswith(prefix):
                        clean_step_desc = clean_step_desc[len(prefix):].strip()
                        break
                # é™åˆ¶æè¿°é•¿åº¦
                if len(clean_step_desc) > 20:
                    clean_step_desc = clean_step_desc[:17] + "..."
                # ç”Ÿæˆè¿›åº¦æ¡
                progress_bar = self._format_progress_bar(current_step, total_steps)
                msg = f"æ­¥éª¤{current_step}/{total_steps}: {clean_step_desc} {progress_bar}"
                template = f"step_{current_step}_{total_steps}"
                return msg, template
            # æ²¡æœ‰å…·ä½“æ­¥éª¤ä¿¡æ¯æ—¶çš„é™çº§æ’­æŠ¥
            templates = [
                f"æ­£åœ¨å¤„ç†ã€Œ{topic}ã€æ ¸å¿ƒä»»åŠ¡",
                f"æ‰§è¡Œã€Œ{topic}ã€å…³é”®æ­¥éª¤",
            ]
            template = get_unused_template(templates, used_templates)
            # æ³¨å…¥ä¸­é—´ç»“æœåˆ°æ’­æŠ¥
            if partial_results and partial_results[-1]:
                latest = partial_results[-1][:25]
                return f"{template}ï¼ˆ{latest}ï¼‰...", template
            return f"{template}...", template

        elif stage == ThinkerStage.SYNTHESIZING:
            # æŒ‰æ—¶é—´é¡ºåºä½¿ç”¨ä¸åŒæ¨¡æ¿ï¼Œé¿å…éšæœºé€‰æ‹©å¯¼è‡´é‡å¤
            if elapsed_time < 10:
                templates = [f"æ­£åœ¨æ•´åˆã€Œ{topic}ã€åˆ†æç»“æœï¼Œè¯·ç¨å€™..."]
            elif elapsed_time < 20:
                templates = [f"æ­£åœ¨æ•´ç†ã€Œ{topic}ã€æœ€ç»ˆç­”æ¡ˆ..."]
            elif elapsed_time < 30:
                templates = [f"å³å°†å®Œæˆï¼Œæ­£åœ¨è¿›è¡Œã€Œ{topic}ã€è´¨é‡æ£€æŸ¥..."]
            else:
                templates = [f"æ­£åœ¨ä¼˜åŒ–ã€Œ{topic}ã€ç­”æ¡ˆï¼Œæ„Ÿè°¢è€å¿ƒç­‰å¾…..."]

            # ä½¿ç”¨æ—¶é—´åˆ†æ®µé€‰æ‹©æ¨¡æ¿
            elapsed_bucket = int(elapsed_time // 10)
            template = templates[elapsed_bucket % len(templates)]
            return template, f"synthesize_bucket_{elapsed_bucket}"

        elif stage == ThinkerStage.COMPLETED:
            return f"ã€Œ{topic}ã€å¤„ç†å®Œæˆï¼", "å¤„ç†å®Œæˆ"

        # é»˜è®¤æ¶ˆæ¯
        return f"å¤„ç†ä¸­ ({elapsed_time:.0f}s)...", "å¤„ç†ä¸­"

    def _is_silent_marker(self, chunk: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºåº”é™é»˜å¤„ç†çš„æ ‡è®°"""
        silent_patterns = [
            r'âœ“\s*å®Œæˆ\s*\(\d+ms\)',
            r'âœ“\s*å·²éªŒè¯',
            r'^[-=]{3,}',
            r'æ‰§è¡Œè¿›åº¦\s*:',
        ]
        return any(re.match(p, chunk.strip()) for p in silent_patterns)

    def _try_rewrite_step_marker(self, chunk: str, total_steps: int) -> Optional[str]:
        """ç»Ÿä¸€å¤„ç†æ­¥éª¤æ ‡è®°"""
        # åŒ¹é…æ­¥éª¤æ ‡è®°ï¼š[æ­¥éª¤ X] æè¿°... æˆ– [æ­¥éª¤ X] æè¿°
        match = re.match(r'\[æ­¥éª¤ (\d+)\] (.+?)\.\.\.', chunk.strip())
        if match and total_steps > 0:
            step_num = int(match.group(1))
            step_name = match.group(2).strip()
            progress_pct = int((step_num / total_steps) * 100)
            return f"æ­¥éª¤{step_num}/{total_steps}: {step_name} ({progress_pct}%)"

        # æ— çœç•¥å·çš„å˜ä½“
        match = re.match(r'\[æ­¥éª¤ (\d+)\] (.+)', chunk.strip())
        if match and total_steps > 0:
            step_num = int(match.group(1))
            step_name = match.group(2).strip()
            progress_pct = int((step_num / total_steps) * 100)
            return f"æ­¥éª¤{step_num}/{total_steps}: {step_name} ({progress_pct}%)"

        return None

    def _try_rewrite_synthesize_marker(self, chunk: str) -> Optional[str]:
        """ç»Ÿä¸€å¤„ç†æ•´åˆ/ç­”æ¡ˆç›¸å…³æ ‡è®° - ä½¿ç”¨æ˜ å°„è¡¨é¿å…é‡å¤"""
        synthesize_map = {
            # ç²¾ç¡®åŒ¹é…ä¼˜å…ˆ
            ("æ•´åˆ", "ç­”æ¡ˆ"): "å³å°†å®Œæˆï¼Œæ­£åœ¨æ•´åˆç­”æ¡ˆ...",
            ("æ•´åˆç»“æœ", "æœ€ç»ˆç­”æ¡ˆ"): "å³å°†å®Œæˆï¼Œæ­£åœ¨æ•´ç†æœ€ç»ˆç­”æ¡ˆ...",
            # é€šç”¨æ¨¡å¼
            ("æ•´åˆ", None): "æ­£åœ¨æ•´åˆå†…å®¹ï¼Œè¯·ç¨å€™...",
            ("æ£€æŸ¥", "è´¨é‡"): "æ­£åœ¨è¿›è¡Œè´¨é‡æ£€æŸ¥...",
            ("ä¼˜åŒ–", "ç­”æ¡ˆ"): "æ­£åœ¨ä¼˜åŒ–ç­”æ¡ˆï¼Œè¯·ç¨å€™...",
        }

        for (k1, k2), rewrite in synthesize_map.items():
            if k1 in chunk and (k2 is None or k2 in chunk):
                return rewrite
        return None

    def _try_rewrite_thinking_marker(self, chunk, stage, current_step, total_steps) -> Optional[str]:
        """å¤„ç†æ€è€ƒ/è§„åˆ’/åˆ†ææ ‡è®°"""
        chunk_stripped = chunk.strip()

        # [æ€è€ƒ] æ­£åœ¨ xxx...ï¼ˆæ”¯æŒä¸­æ–‡æ‹¬å·ï¼‰
        thinking_match = re.match(r'\[æ€è€ƒ\]\s*(.+)\.\.\.', chunk_stripped)
        if thinking_match:
            action = thinking_match.group(1)
            # æ ¹æ®é˜¶æ®µç»™å‡ºæ›´å‹å¥½çš„æè¿°
            if stage == ThinkerStage.ANALYZING:
                return f"æ­£åœ¨{action}ï¼Œè¯·ç¨å€™..."
            elif stage == ThinkerStage.PLANNING:
                return f"å·²ç†è§£éœ€æ±‚ï¼Œ{action}..."
            elif stage == ThinkerStage.EXECUTING:
                return f"{action}ï¼Œè¿›åº¦{current_step}/{total_steps}..."
            else:
                return f"æ­£åœ¨{action}..."

        # [æ€è€ƒ] æ²¡æœ‰çœç•¥å·çš„å˜ä½“
        thinking_no_dots = re.match(r'\[æ€è€ƒ\]\s*(.+)', chunk_stripped)
        if thinking_no_dots and '...' not in chunk_stripped:
            action = thinking_no_dots.group(1).strip()
            return f"æ­£åœ¨{action}ï¼Œè¯·ç¨å€™..."

        # [è§„åˆ’] ä»»åŠ¡ç›®æ ‡ï¼šxxx
        plan_target_match = re.match(r'\[è§„åˆ’\]\s*ä»»åŠ¡ç›®æ ‡:\s*(.+)', chunk_stripped)
        if plan_target_match:
            target = plan_target_match.group(1)
            return f"å·²ç†è§£ä»»åŠ¡ç›®æ ‡ï¼š{target}"

        # [è§„åˆ’] å…± X ä¸ªæ­¥éª¤
        plan_steps_match = re.match(r'\[è§„åˆ’\]\s*å…±\s*(\d+)\s*ä¸ªæ­¥éª¤', chunk_stripped)
        if plan_steps_match:
            num_steps = int(plan_steps_match.group(1))
            return f"ä»»åŠ¡å·²åˆ†è§£ä¸º{num_steps}ä¸ªæ­¥éª¤ï¼Œå¼€å§‹æ‰§è¡Œ..."

        # [è§„åˆ’] é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("[è§„åˆ’]") or chunk_stripped.startswith("ï¼»è§„åˆ’ï¼½"):
            return "æ­£åœ¨è§„åˆ’ä»»åŠ¡æ‰§è¡Œæ–¹æ¡ˆ..."

        # [åˆ†æ] é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("[åˆ†æ]") or chunk_stripped.startswith("ï¼»åˆ†æï¼½"):
            return "æ­£åœ¨åˆ†æé—®é¢˜ï¼Œè¯·ç¨å€™..."

        return None

    def _try_rewrite_thinker_output(
        self,
        chunk: str,
        stage: ThinkerStage,
        current_step: int,
        total_steps: int,
        step_desc: str,
        elapsed: float,
    ) -> Optional[str]:
        """
        å°è¯•å°† Thinker çš„é˜¶æ®µæ ‡è®°è¾“å‡ºè½¬æ¢ä¸º Talker é£æ ¼çš„æ’­æŠ¥

        æ£€æµ‹ Thinker è¾“å‡ºçš„é˜¶æ®µæ ‡è®°ï¼ˆå¦‚"[æ­¥éª¤ 1] xxx"ã€"[æ€è€ƒ] xxx"ã€"[è§„åˆ’] xxx"ï¼‰ï¼Œ
        ç”± Talker é‡æ–°ç»„ç»‡è¯­è¨€åæ˜¾ç¤ºï¼Œä½¿ç”¨æˆ·æ„ŸçŸ¥æ›´ä¸€è‡´ã€æ›´å‹å¥½ã€‚

        ä¼˜å…ˆçº§é‡å†™è§„åˆ™ï¼š
        1. é™é»˜å¤„ç†ï¼ˆæ— æ„ä¹‰æ ‡è®°ï¼‰
        2. æ­¥éª¤æ ‡è®°ï¼ˆæœ€å…·ä½“ï¼Œä¼˜å…ˆåŒ¹é…ï¼‰
        3. æ•´åˆ/ç­”æ¡ˆæ ‡è®°ï¼ˆä½¿ç”¨ç»Ÿä¸€æ˜ å°„è¡¨ï¼‰
        4. æ€è€ƒ/è§„åˆ’/åˆ†ææ ‡è®°

        Returns:
            Optional[str]: å¦‚æœæ£€æµ‹åˆ°é˜¶æ®µæ ‡è®°åˆ™è¿”å›é‡å†™åçš„æ’­æŠ¥ï¼Œå¦åˆ™è¿”å› None
        """
        chunk_stripped = chunk.strip()

        # ä¼˜å…ˆçº§ 1: é™é»˜å¤„ç†ï¼ˆæ— æ„ä¹‰æ ‡è®°ï¼‰
        if self._is_silent_marker(chunk_stripped):
            return None

        # ä¼˜å…ˆçº§ 2: æ­¥éª¤æ ‡è®°ï¼ˆæœ€å…·ä½“ï¼Œä¼˜å…ˆåŒ¹é…ï¼‰
        rewrite = self._try_rewrite_step_marker(chunk_stripped, total_steps)
        if rewrite:
            return rewrite

        # ä¼˜å…ˆçº§ 3: æ•´åˆ/ç­”æ¡ˆæ ‡è®°ï¼ˆä½¿ç”¨ç»Ÿä¸€æ˜ å°„è¡¨ï¼‰
        rewrite = self._try_rewrite_synthesize_marker(chunk_stripped)
        if rewrite:
            return rewrite

        # ç©ºç™½å­—ç¬¦å®¹é”™ï¼šç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦åå†åŒ¹é…
        normalized = re.sub(r'\s+', '', chunk_stripped)

        # === æ£€æµ‹ Thinker é˜¶æ®µæ ‡è®° ===

        # "å¼€å§‹å¤„ç†..." â†’ å·²å¯åŠ¨ï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼‰
        if chunk_stripped.startswith("å¼€å§‹å¤„ç†") or re.search(r'å¼€å§‹\s*å¤„ç†', chunk_stripped) or 'å¼€å§‹å¤„ç†' in normalized:
            return "å·²å¯åŠ¨ï¼Œæ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..."

        # "å¼€å§‹ xxx..." é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("å¼€å§‹") and "..." in chunk_stripped:
            action = chunk_stripped[2:].split('.')[0].strip()
            return f"å¼€å§‹{action}ï¼Œè¯·ç¨å€™..."

        # "æ­£åœ¨ xxx..." â†’ æ­£åœ¨ xxxï¼Œè¯·ç¨å€™...ï¼ˆæ”¯æŒæ›´å®½æ¾çš„æ£€æµ‹ï¼‰
        if chunk_stripped.startswith("æ­£åœ¨") and "..." in chunk_stripped:
            return f"{chunk_stripped}è¯·ç¨å€™..."

        # "æ­£åœ¨ xxx" æ²¡æœ‰çœç•¥å·çš„å˜ä½“
        if chunk_stripped.startswith("æ­£åœ¨") and len(chunk_stripped) > 4:
            return f"{chunk_stripped}ï¼Œè¯·ç¨å€™..."

        # "æ•´åˆç»“æœï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ..." â†’ å³å°†å®Œæˆ
        if "æ•´åˆ" in chunk_stripped and "ç­”æ¡ˆ" in chunk_stripped:
            return "å³å°†å®Œæˆï¼Œæ­£åœ¨æ•´åˆç­”æ¡ˆ..."

        # "æ•´åˆ xxx" é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("æ•´åˆ"):
            return "æ­£åœ¨æ•´åˆå†…å®¹ï¼Œè¯·ç¨å€™..."

        # "æ£€æŸ¥ç­”æ¡ˆè´¨é‡..." â†’ è´¨é‡æ£€æŸ¥ä¸­
        if "æ£€æŸ¥" in chunk_stripped and "è´¨é‡" in chunk_stripped:
            return "æ­£åœ¨è¿›è¡Œè´¨é‡æ£€æŸ¥..."

        # "æ£€æŸ¥ xxx" é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("æ£€æŸ¥") and "..." in chunk_stripped:
            return f"æ­£åœ¨{chunk_stripped}ï¼Œè¯·ç¨å€™..."

        # "ç­”æ¡ˆéœ€è¦æ”¹è¿›ï¼Œæ­£åœ¨ä¼˜åŒ–..." â†’ ä¼˜åŒ–ä¸­
        if "ä¼˜åŒ–" in chunk_stripped and "ç­”æ¡ˆ" in chunk_stripped:
            return "æ­£åœ¨ä¼˜åŒ–ç­”æ¡ˆï¼Œè¯·ç¨å€™..."

        # "ä¼˜åŒ– xxx" é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("ä¼˜åŒ–") and "..." in chunk_stripped:
            return f"æ­£åœ¨{chunk_stripped}ï¼Œè¯·ç¨å€™..."

        # [æ­¥éª¤ X] æ­¥éª¤åç§°...ï¼ˆæ”¯æŒä¸­æ–‡æ‹¬å·å’Œç©ºæ ¼å˜ä½“ï¼‰
        step_match = re.match(r'[\[ï¼»] æ­¥éª¤\s*(\d+)[\]ï¼½]\s*([^\.\.]+)\.\.\.', chunk_stripped)
        if step_match and total_steps > 0:
            step_num = int(step_match.group(1))
            step_name = step_match.group(2).strip()
            progress_pct = int((step_num / total_steps) * 100)
            return f"æ­¥éª¤{step_num}/{total_steps}: {step_name}ï¼ˆ{progress_pct}%ï¼‰"

        # [æ­¥éª¤ X] æ²¡æœ‰çœç•¥å·çš„å˜ä½“
        step_no_dots = re.match(r'[\[ï¼»] æ­¥éª¤\s*(\d+)[\]ï¼½]\s*(.+)', chunk_stripped)
        if step_no_dots and total_steps > 0 and '...' not in chunk_stripped:
            step_num = int(step_no_dots.group(1))
            step_name = step_no_dots.group(2).strip()
            progress_pct = int((step_num / total_steps) * 100)
            return f"æ­¥éª¤{step_num}/{total_steps}: {step_name}ï¼ˆ{progress_pct}%ï¼‰"

        # [æ€è€ƒ] æ­£åœ¨ xxx...ï¼ˆæ”¯æŒä¸­æ–‡æ‹¬å·ï¼‰
        thinking_match = re.match(r'[\[ï¼»] æ€è€ƒ[\]ï¼½]\s*(.+)\.\.\.', chunk_stripped)
        if thinking_match:
            action = thinking_match.group(1)
            # æ ¹æ®é˜¶æ®µç»™å‡ºæ›´å‹å¥½çš„æè¿°
            if stage == ThinkerStage.ANALYZING:
                return f"æ­£åœ¨{action}ï¼Œè¯·ç¨å€™..."
            elif stage == ThinkerStage.PLANNING:
                return f"å·²ç†è§£éœ€æ±‚ï¼Œ{action}..."
            elif stage == ThinkerStage.EXECUTING:
                return f"{action}ï¼Œè¿›åº¦{current_step}/{total_steps}..."
            else:
                return f"æ­£åœ¨{action}..."

        # [æ€è€ƒ] æ²¡æœ‰çœç•¥å·çš„å˜ä½“
        thinking_no_dots = re.match(r'[\[ï¼»] æ€è€ƒ[\]ï¼½]\s*(.+)', chunk_stripped)
        if thinking_no_dots and '...' not in chunk_stripped:
            action = thinking_no_dots.group(1).strip()
            return f"æ­£åœ¨{action}ï¼Œè¯·ç¨å€™..."

        # [è§„åˆ’] ä»»åŠ¡ç›®æ ‡ï¼šxxx
        plan_target_match = re.match(r'[\[ï¼»] è§„åˆ’[\]ï¼½]\s*ä»»åŠ¡ç›®æ ‡:\s*(.+)', chunk_stripped)
        if plan_target_match:
            target = plan_target_match.group(1)
            return f"å·²ç†è§£ä»»åŠ¡ç›®æ ‡ï¼š{target}"

        # [è§„åˆ’] å…± X ä¸ªæ­¥éª¤
        plan_steps_match = re.match(r'[\[ï¼»] è§„åˆ’[\]ï¼½]\s*å…±\s*(\d+)\s*ä¸ªæ­¥éª¤', chunk_stripped)
        if plan_steps_match:
            num_steps = int(plan_steps_match.group(1))
            return f"ä»»åŠ¡å·²åˆ†è§£ä¸º{num_steps}ä¸ªæ­¥éª¤ï¼Œå¼€å§‹æ‰§è¡Œ..."

        # [è§„åˆ’] é€šç”¨æ¨¡å¼
        if chunk_stripped.startswith("[è§„åˆ’]") or chunk_stripped.startswith("ï¼»è§„åˆ’ï¼½"):
            return "æ­£åœ¨è§„åˆ’ä»»åŠ¡æ‰§è¡Œæ–¹æ¡ˆ..."

        # [åˆ†æ] é€šç”¨æ¨¡å¼ï¼ˆæ–°å¢æ”¯æŒï¼‰
        if chunk_stripped.startswith("[åˆ†æ]") or chunk_stripped.startswith("ï¼»åˆ†æï¼½"):
            return "æ­£åœ¨åˆ†æé—®é¢˜ï¼Œè¯·ç¨å€™..."

        # [ç­”æ¡ˆ] xxx - æœ€ç»ˆç­”æ¡ˆï¼Œé™é»˜å¤„ç†ï¼Œç”±åç»­é€»è¾‘å¤„ç†
        answer_match = re.match(r'[\[ï¼»] ç­”æ¡ˆ[\]ï¼½]\s*(.+)', chunk_stripped)
        if answer_match:
            # æœ€ç»ˆç­”æ¡ˆå†…å®¹ï¼Œè¿”å› None è®©æ­£å¸¸æµç¨‹å¤„ç†
            return None

        # é€šç”¨é˜¶æ®µæ ‡è®°å¤„ç† - fallback æœºåˆ¶
        # æ£€æŸ¥æ˜¯å¦æ˜¯ Thinker çš„é˜¶æ®µæ ‡è®°æ ¼å¼ï¼š[é˜¶æ®µå] å†…å®¹
        stage_marker_match = re.match(r'[\[ï¼»](æ­¥éª¤ | æ€è€ƒ | è§„åˆ’ | åˆ†æ | æ‰§è¡Œ | æ•´åˆ | ç­”æ¡ˆ)[\]ï¼½]\s*(.+)', chunk_stripped)
        if stage_marker_match:
            stage_type = stage_marker_match.group(1)
            content = stage_marker_match.group(2)
            # é€šç”¨çš„é˜¶æ®µæ ‡è®°å¤„ç†
            return "æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."

        # ç©ºç™½å­—ç¬¦å®¹é”™æ£€æµ‹ï¼šå¯¹äºçŸ­å†…å®¹ï¼Œä½¿ç”¨ normalized å†æ¬¡æ£€æµ‹
        if len(normalized) < 20:
            if 'å¼€å§‹å¤„ç†' in normalized:
                return "å·²å¯åŠ¨ï¼Œæ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..."
            if 'æ­£åœ¨åˆ†æ' in normalized:
                return "æ­£åœ¨åˆ†æé—®é¢˜ï¼Œè¯·ç¨å€™..."
            if 'æ•´åˆç­”æ¡ˆ' in normalized:
                return "å³å°†å®Œæˆï¼Œæ­£åœ¨æ•´åˆç­”æ¡ˆ..."

        # æœªæ£€æµ‹åˆ°é˜¶æ®µæ ‡è®°ï¼Œè¿”å› None è®©åŸå§‹è¾“å‡ºæ˜¾ç¤º
        return None

    def _format_progress_bar(self, current: int, total: int, width: int = 20) -> str:
        """
        ç”Ÿæˆè¿›åº¦æ¡å­—ç¬¦ä¸²

        Args:
            current: å½“å‰æ­¥éª¤
            total: æ€»æ­¥éª¤æ•°
            width: è¿›åº¦æ¡å®½åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰

        Returns:
            è¿›åº¦æ¡å­—ç¬¦ä¸²ï¼Œå¦‚ï¼š[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60%
        """
        if total <= 0:
            return ""

        percent = current / total
        filled = int(width * percent)
        empty = width - filled

        # ä½¿ç”¨ Unicode å—å­—ç¬¦åˆ›å»ºè¿›åº¦æ¡
        bar = "â–ˆ" * filled + "â–‘" * empty
        return f"[{bar}] {int(percent * 100)}%"

    def _get_emotional_broadcast_suffix(self, elapsed: float, user_complaint: bool = False) -> str:
        """
        æ ¹æ®å·²è€—æ—¶å’Œç”¨æˆ·æƒ…ç»ªç”Ÿæˆæ’­æŠ¥åç¼€ï¼ˆå®‰æŠšæ€§è¯è¯­ï¼‰

        Args:
            elapsed: å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰
            user_complaint: ç”¨æˆ·æ˜¯å¦è¡¨è¾¾äº†ä¸æ»¡

        Returns:
            å®‰æŠšæ€§åç¼€å­—ç¬¦ä¸²
        """
        if user_complaint:
            # ç”¨æˆ·æœ‰æŠ±æ€¨ï¼Œä½¿ç”¨æ›´å®‰æŠšçš„è¯­æ°”
            if elapsed < 30:
                return "ï¼Œé©¬ä¸Šå°±å¥½~"
            elif elapsed < 60:
                return "ï¼Œå†ç»™æˆ‘ä¸€ç‚¹æ—¶é—´~"
            else:
                return "ï¼Œè¿™ä¸ªä»»åŠ¡ç¡®å®æœ‰ç‚¹å¤æ‚ï¼Œæ„Ÿè°¢æ‚¨çš„è€å¿ƒï¼"
        else:
            # æ­£å¸¸è¯­æ°”
            if elapsed < 30:
                return "ï¼Œè¯·ç¨å€™..."
            elif elapsed < 60:
                return "ï¼Œè¿˜éœ€ä¸€ç‚¹æ—¶é—´..."
            else:
                return "ï¼Œå¤æ‚ä»»åŠ¡éœ€è¦æ›´å¤šæ—¶é—´ï¼Œæ„Ÿè°¢ç­‰å¾…~"

    def _extract_topic(self, query: str) -> str:
        """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–ä¸»é¢˜"""
        query_lower = query.lower()

        # è¯é¢˜å…³é”®è¯é…ç½®ï¼šæŒ‰ä¼˜å…ˆçº§æ’åºï¼Œå…·ä½“è¯é¢˜åœ¨å‰ï¼Œé€šç”¨è¯é¢˜åœ¨å
        # æ¯ä¸ªè¯é¢˜çš„å…³é”®è¯æŒ‰ç‰¹å¼‚æ€§æ’åºï¼Œå…·ä½“è¯åœ¨å‰ï¼Œé€šç”¨è¯åœ¨å
        topic_keywords = [
            # å…·ä½“è¯é¢˜ä¼˜å…ˆï¼ˆé¿å…è¢«é€šç”¨è¯é¢˜è¦†ç›–ï¼‰
            ("å¥¶èŒ¶", ["å¥¶èŒ¶", "æ³¢éœ¸", "çç å¥¶èŒ¶", "é²œå¥¶èŒ¶"]),
            ("å’–å•¡", ["å’–å•¡", "æ‹¿é“", "æ˜Ÿå·´å…‹", "ç‘å¹¸", "ç¾å¼", "å¡å¸ƒå¥‡è¯º"]),
            ("æ‰“è½¦", ["æ‰“è½¦", "æ»´æ»´", "é«˜å¾·", "ä¸“è½¦", "å¿«è½¦", "ç½‘çº¦è½¦"]),
            ("é€‰è½¦", ["è½¦", "æ±½è½¦", "è½¦å‹", "å“ç‰Œ", "suv", "è½¿è½¦", "ä¹°è½¦", "é€‰è½¦", "æ–°èƒ½æºè½¦"]),
            ("æ—…æ¸¸", ["æ—…æ¸¸", "æ—…è¡Œ", "æ™¯ç‚¹", "é…’åº—", "æœºç¥¨", "å»å“ªç©", "å‡ºå»ç©"]),
            ("ç¾é£Ÿ", ["ç¾é£Ÿ", "é¤å…", "é¤é¦†", "èœ", "åƒ", "æ¨èèœ", "å°åƒ", "ç”œå“"]),
            # é€šç”¨è¯é¢˜æ”¾æœ€åï¼ˆé¿å…è¿‡åº¦åŒ¹é…ï¼‰
            ("è´­ç‰©", ["è´­ç‰©", "ä»·æ ¼", "ä¾¿å®œ", "å¯¹æ¯”", "ä¹°ä¸œè¥¿"]),
        ]

        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…å…·ä½“è¯é¢˜
        for topic, keywords in topic_keywords:
            if any(kw in query_lower for kw in keywords):
                return topic

        # ç¬¬äºŒè½®ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«"ä¹°"å­—ä½†æ²¡æœ‰å…·ä½“è¯é¢˜
        # å¦‚æœæŸ¥è¯¢ä¸­æœ‰å…·ä½“ç‰©å“ï¼ˆå¦‚"ä¹°å¥¶èŒ¶"ï¼‰ï¼Œæå–ç‰©å“åä½œä¸ºè¯é¢˜
        if "ä¹°" in query_lower:
            # å°è¯•æå–"ä¹°"åé¢çš„ç‰©å“
            match = re.search(r'ä¹° ([\u4e00-\u9fa5]{2,6})', query_lower)
            if match:
                return match.group(1)

        # ç¬¬ä¸‰è½®ï¼šæå–é—®é¢˜ä¸­çš„å…³é”®è¯ä½œä¸ºä¸»é¢˜
        words = re.findall(r'[\u4e00-\u9fa5]{2,4}', query)
        if words:
            return words[0]
        return "æ‚¨çš„é—®é¢˜"

    def _extract_user_preferences(self, text: str) -> Dict[str, Any]:
        """ä»è¾“å…¥ä¸­æå–å¯æŒä¹…åŒ–çš„ç”¨æˆ·åå¥½ï¼ˆé€šç”¨å»ºæ¨¡ï¼Œä¸å¼ºç»‘å®šå…·ä½“åœºæ™¯ï¼‰ã€‚"""
        text = (text or "").lower().strip()
        prefs: Dict[str, Any] = {}
        likes: List[str] = []
        dislikes: List[str] = []
        constraints: List[str] = []

        for pat in [r"æˆ‘å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"åå¥½([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"æ›´å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            likes.extend([m.strip() for m in re.findall(pat, text) if m.strip()])
        for pat in [r"æˆ‘ä¸å–œæ¬¢([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"ä¸è¦([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"é¿å…([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            dislikes.extend([m.strip() for m in re.findall(pat, text) if m.strip()])
        for pat in [r"å¸Œæœ›([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"æœ€å¥½([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})", r"éœ€è¦([^ï¼Œã€‚ï¼›,!?ï¼Ÿ]{1,20})"]:
            constraints.extend([m.strip() for m in re.findall(pat, text) if m.strip()])

        if likes:
            prefs["likes"] = list(dict.fromkeys(likes))
        if dislikes:
            prefs["dislikes"] = list(dict.fromkeys(dislikes))
        if constraints:
            prefs["constraints"] = list(dict.fromkeys(constraints))

        # å…¼å®¹æ—¢æœ‰é«˜é¢‘åå¥½å­—æ®µ
        if any(k in text for k in ["å–œæ¬¢åƒè¾£", "çˆ±åƒè¾£", "èƒ½åƒè¾£", "å£å‘³é‡"]):
            prefs["taste"] = "å–œæ¬¢åƒè¾£"
        elif any(k in text for k in ["ä¸åƒè¾£", "ä¸èƒ½åƒè¾£", "æ¸…æ·¡"]):
            prefs["taste"] = "åæ¸…æ·¡/ä¸åƒè¾£"

        budget_match = re.search(r"(\d{1,3})\s*ä¸‡", text)
        if budget_match:
            prefs["budget"] = f"{budget_match.group(1)}ä¸‡"
        amount_match = re.search(r"(\d{2,6})\s*(å…ƒ|å—)", text)
        if amount_match and "budget" not in prefs:
            prefs["budget"] = f"{amount_match.group(1)}{amount_match.group(2)}"

        if "suv" in text or "è¶Šé‡" in text:
            prefs["car_type"] = "åå¥½SUV"
        elif "è½¿è½¦" in text:
            prefs["car_type"] = "åå¥½è½¿è½¦"
        return prefs

    def _merge_user_preferences(self, base: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶åå¥½ï¼šåˆ—è¡¨å»é‡å¹¶ä¿åºï¼Œå­—å…¸é€’å½’åˆå¹¶ï¼Œæ ‡é‡è¦†ç›–ã€‚"""
        merged: Dict[str, Any] = dict(base or {})
        for k, v in (new or {}).items():
            if k not in merged:
                merged[k] = v
                continue
            old = merged[k]
            if isinstance(old, list) and isinstance(v, list):
                merged[k] = list(dict.fromkeys([*old, *v]))
            elif isinstance(old, dict) and isinstance(v, dict):
                merged[k] = {**old, **v}
            else:
                merged[k] = v
        return merged

    async def persist_user_preferences(self, text: str) -> Dict[str, Any]:
        """æå–å¹¶æŒä¹…åŒ–ç”¨æˆ·åå¥½ï¼Œè¿”å›æœ€æ–°åå¥½ã€‚"""
        global_pref_sid = "__global_user__"
        persisted_prefs = await self.session_context.get_session_data(
            global_pref_sid, "user_preferences", {}
        ) or {}
        extracted_prefs = self._extract_user_preferences(text)
        if extracted_prefs:
            persisted_prefs = self._merge_user_preferences(persisted_prefs, extracted_prefs)
            await self.session_context.set_session_data(
                global_pref_sid, "user_preferences", persisted_prefs, ttl=86400 * 30
            )
        return persisted_prefs

    def _should_broadcast(
        self,
        new_stage: ThinkerStage,
        current_step: int,
        elapsed_time: float,
        content_hash: str,
        message_text: str = "",  # æ–°å¢ï¼šå¾…æ’­æŠ¥çš„æ¶ˆæ¯æ–‡æœ¬
        force_check: bool = False,
    ) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ’­æŠ¥

        Args:
            new_stage: å½“å‰é˜¶æ®µ
            current_step: å½“å‰æ­¥éª¤
            elapsed_time: å·²è€—æ—¶
            message_text: å¾…æ’­æŠ¥çš„æ¶ˆæ¯æ–‡æœ¬ï¼ˆç”¨äºè¯­ä¹‰å»é‡ï¼‰
            force_check: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥ï¼ˆå¿½ç•¥æœ€å°é—´éš”ï¼‰

        Returns:
            tuple: (æ˜¯å¦æ’­æŠ¥, åŸå› )
        """
        state = self._progress_state
        current_time = time.time()

        # é˜¶æ®µå˜åŒ–ï¼Œç«‹å³æ’­æŠ¥
        if new_stage != state.current_stage:
            return True, "stage_changed"

        # æ­¥éª¤å˜åŒ–ï¼ˆæ‰§è¡Œé˜¶æ®µï¼‰
        if new_stage == ThinkerStage.EXECUTING and current_step != state.current_step and current_step > 0:
            return True, "step_changed"

        # æ— è¿›åº¦å˜åŒ–æ—¶ï¼Œé™ä½æ’­æŠ¥é¢‘ç‡ï¼ˆä»…ä¿ç•™å¿ƒè·³æ’­æŠ¥ï¼‰
        if content_hash == state.last_content_hash:
            if current_time - state.last_broadcast < 15:
                return False, "no_progress"
            return True, "heartbeat"


        # è¯­ä¹‰å»é‡æ£€æŸ¥
        if message_text and self._is_semantic_duplicate(message_text):
            return False, "semantic_duplicate"

        # æ£€æŸ¥è¯¥é˜¶æ®µå·²ä½¿ç”¨çš„æ¨¡æ¿æ•°é‡
        stage_key = new_stage.value
        template_count = len(state.used_message_templates.get(stage_key, set()))
        max_templates_per_stage = 4  # æ¯é˜¶æ®µæœ€å¤š4æ¡ä¸åŒæ¶ˆæ¯

        if template_count >= max_templates_per_stage:
            return False, "max_templates_reached"

        return True, "interval_elapsed"

    def _hash_broadcast_content(self, stage: ThinkerStage, step: int, elapsed: float) -> str:
        """ç”Ÿæˆæ’­æŠ¥å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        # ä½¿ç”¨é˜¶æ®µå’Œæ­¥éª¤çš„æ•´æ•°éƒ¨åˆ†ä½œä¸ºå“ˆå¸ŒåŸºç¡€
        elapsed_bucket = int(elapsed // 5) * 5  # æ¯5ç§’ä¸€ä¸ªæ¡¶
        return f"{stage.value}_{step}_{elapsed_bucket}"

    def set_callbacks(
        self,
        on_response: Optional[Callable] = None,
        on_handoff: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
    ) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_response = on_response
        self._on_handoff = on_handoff
        self._on_progress = on_progress

    async def process(
        self,
        user_input: str,
        session_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        received_time: Optional[float] = None,
    ) -> AsyncIterator[str]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡
            received_time: æ¶ˆæ¯æ¥æ”¶æ—¶é—´

        Yields:
            str: å“åº”å†…å®¹
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        if received_time is None:
            received_time = start_time

        # åˆå§‹åŒ–ä¼šè¯
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())

        # ä½¿ç”¨SessionContextè·å–ä¼šè¯ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        session = await self._get_or_create_session(session_id)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°SessionContext
        user_message = Message(
            role="user",
            content=user_input,
            timestamp=time.time(),
        )
        await self.session_context.add_message(session_id, user_message)

        # åˆ›å»º/è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = self._get_or_create_shared_context(session_id)
        persisted_prefs = await self.persist_user_preferences(user_input)
        shared.user_preferences = persisted_prefs
        if not shared.needs_clarification():
            shared.user_input = user_input
            shared.clarified_intent = user_input
        shared.is_processing = True

        effective_input = user_input

        # === æ£€æŸ¥æ˜¯å¦æ˜¯å›ç­”æ¾„æ¸…é—®é¢˜ ===
        if shared.needs_clarification():
            # ç”¨æˆ·å¯èƒ½æ˜¯åœ¨å›ç­”æ¾„æ¸…é—®é¢˜
            pending = shared.get_pending_clarification()
            if pending:
                # è®°å½•å›ç­”
                shared.answer_clarification(user_input)
                # æ›´æ–°æ„å›¾
                shared.update_intent_with_clarification(user_input)
                effective_input = shared.clarified_intent or shared.user_input or user_input

                # ç»™ç”¨æˆ·ç¡®è®¤åé¦ˆ
                ts = time.strftime("%H:%M:%S", time.localtime())
                ms = int((time.time() % 1) * 1000)
                yield f"\n[{ts}.{ms:03d}] Talker: æ”¶åˆ°ï¼Œå·²æ›´æ–°æ‚¨çš„éœ€æ±‚ä¿¡æ¯"
                shared.add_talker_interaction("æ”¶åˆ°ï¼Œå·²æ›´æ–°æ‚¨çš„éœ€æ±‚ä¿¡æ¯", "clarification")

                # æ ‡è®°ä¸ºç»§ç»­å¤„ç†ï¼Œä½†ä½¿ç”¨æ›´æ–°åçš„æ„å›¾
                # å¦‚æœæ¾„æ¸…åçš„æ„å›¾è¶³å¤Ÿç®€å•ï¼Œå¯ä»¥è®©Talkerå¤„ç†
                # å¦åˆ™ç»§ç»­äº¤ç»™Thinker

        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å…±äº«ä¸Šä¸‹æ–‡å’Œæ‘˜è¦ï¼‰
        # è·å–ä¼šè¯æ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        session_summary = await self.session_context.get_summary(session_id)

        # å¦‚æœæ²¡æœ‰æ‘˜è¦ä¸”æ¶ˆæ¯è¾ƒå¤šï¼Œç”Ÿæˆæ‘˜è¦
        messages = await self.session_context.get_messages(session_id, limit=50)
        if not session_summary and len(messages) >= settings.SUMMARY_THRESHOLD:
            session_summary = await self.summarizer.summarize_recent_messages(messages)
            if session_summary:
                await self.session_context.set_summary(session_id, session_summary)

        full_context = {
            **(context or {}),
            "session_id": session_id,
            "messages": session["messages"],
            "received_time": received_time,
            "shared": shared,  # æ·»åŠ å…±äº«ä¸Šä¸‹æ–‡
            "session_summary": session_summary,  # æ·»åŠ ä¼šè¯æ‘˜è¦
            "effective_input": effective_input,
            "user_preferences": persisted_prefs,
        }

        # æ”¶é›†åŠ©æ‰‹å“åº”ç”¨äºä¿å­˜åˆ°ä¼šè¯
        assistant_response_chunks = []

        try:
            # ä½¿ç”¨Talkerè¿›è¡Œæ„å›¾åˆ†ç±»
            classification = await self.talker.classify_intent(effective_input, full_context)

            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
            if classification.complexity == TaskComplexity.COMPLEX:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨åä½œæ¨¡å¼
                self._stats["thinker_handled"] += 1
                async for chunk in self._collaboration_handoff(
                    effective_input, full_context, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk
            else:
                # ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼šTalkerå¤„ç†
                self._stats["talker_handled"] += 1
                async for chunk in self._delegation_handoff(
                    effective_input, full_context, classification, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk

        except Exception as e:
            self._stats["errors"] += 1
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            assistant_response_chunks.append(error_msg)
            yield error_msg

        finally:
            # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°ä¼šè¯ï¼ˆæ¸…ç†æ‰å…ƒæ•°æ®æ ‡è®°ï¼‰
            assistant_response = "".join(assistant_response_chunks)
            # ç§»é™¤æ—¶é—´æˆ³å’ŒAgentæ ‡è¯†ç­‰å…ƒæ•°æ®ï¼Œåªä¿ç•™å®é™…å›å¤å†…å®¹
            # ç§»é™¤ç±»ä¼¼ [HH:MM:SS.mmm] Talker: çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[\d{2}:\d{2}:\d{2}\.\d{3}\]\s*(Talker|Thinker):\s*', '', assistant_response)
            # ç§»é™¤ç±»ä¼¼ [Talker] ... çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker\][^\n]*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker\][^\n]*', '', clean_response)
            # ç§»é™¤ [Talker -> Thinker | ...] çš„æ ‡è®°
            clean_response = re.sub(r'\n?\[Talker[^\]]*\]\s*', '', clean_response)
            clean_response = re.sub(r'\n?\[Thinker[^\]]*\]\s*', '', clean_response)
            # ç§»é™¤æ€§èƒ½æŒ‡æ ‡åŒºå—ï¼ˆåŒ…å«ğŸ“Šç¬¦å·çš„éƒ¨åˆ†ï¼‰
            clean_response = re.sub(r'\n-{10,}.*?-{10,}', '', clean_response, flags=re.DOTALL)
            # ç§»é™¤å‰©ä½™çš„æŒ‡æ ‡è¡Œ
            clean_response = re.sub(r'\n\s*ğŸ“Š[^\n]*', '', clean_response)
            clean_response = re.sub(r'\n\s*(Tokens|TTFT|TPOT|TPS|æ€»ç”Ÿæˆæ—¶å»¶|LLMè¯·æ±‚æ—¶é—´)[^\n]*', '', clean_response)
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            clean_response = re.sub(r'\n{3,}', '\n\n', clean_response)
            clean_response = clean_response.strip()

            if clean_response:
                # ä½¿ç”¨SessionContextä¿å­˜åŠ©æ‰‹å“åº”
                assistant_message = Message(
                    role="assistant",
                    content=clean_response,
                    timestamp=time.time(),
                )
                await self.session_context.add_message(session_id, assistant_message)

            # æ›´æ–°å…±äº«ä¸Šä¸‹æ–‡çŠ¶æ€
            shared.is_processing = False

            elapsed = (time.time() - start_time) * 1000
            await self.session_context.set_session_data(session_id, "last_latency_ms", elapsed)

    async def _delegation_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        classification,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        å§”æ‰˜æ¨¡å¼Handoff

        Talkerå¤„ç†ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å§”æ‰˜ç»™Thinker
        æ”¹è¿›ï¼šç‹¬ç«‹äºTalkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        # è®°å½•LLMè¯·æ±‚å‘é€æ—¶é—´
        llm_request_time = time.time()

        # ä½¿ç”¨é˜Ÿåˆ—æ”¶é›†Talkerè¾“å‡º
        talker_queue = asyncio.Queue()
        talker_complete = False

        async def run_talker():
            """è¿è¡ŒTalkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal talker_complete
            try:
                async for chunk in self.talker.process(user_input, context):
                    await talker_queue.put(chunk)
            except Exception as e:
                logger.error(f"Talker task error: {e}")
            finally:
                talker_complete = True

        # å¯åŠ¨Talkerä»»åŠ¡
        talker_task = asyncio.create_task(run_talker())
        TALKER_TIMEOUT = 120.0  # 120 ç§’è¶…æ—¶
        # å¾ªç¯ä¿æŠ¤ï¼šé˜²æ­¢æ— é™å¾ªç¯
        loop_iteration_count = 0
        max_loop_iterations = 10000  # æœ€å¤§å¾ªç¯æ¬¡æ•°


        # å¤„ç†Talkerè¾“å‡º
        first_token_time = None
        first_timestamp_shown = False
        last_broadcast_time = llm_request_time
        broadcast_count = 0
        used_broadcast_templates = set()  # è¿½è¸ªå·²ä½¿ç”¨çš„æ¶ˆæ¯æ¨¡æ¿

        def get_talker_broadcast_interval(elapsed: float) -> float:
            """åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš” - æ›´ä¿å®ˆ"""
            if elapsed < 15:
                return 4.0  # åˆå§‹4ç§’
            elif elapsed < 30:
                return 6.0  # ä¸­æœŸ6ç§’
            else:
                return 8.0  # åæœŸ8ç§’

        while not talker_complete or not talker_queue.empty():
            loop_iteration_count += 1

            # å¾ªç¯æ¬¡æ•°ä¿æŠ¤
            if loop_iteration_count > max_loop_iterations:
                logger.warning(f"Talker loop exceeded {max_loop_iterations} iterations, breaking")
                break

            current_time = time.time()
            elapsed = current_time - llm_request_time
            
            # è¶…æ—¶ä¿æŠ¤
            # è¶…æ—¶ä¿æŠ¤
            if elapsed > TALKER_TIMEOUT:
                logger.warning(f"Talker task timeout ({TALKER_TIMEOUT}s), cancelling...")
                talker_task.cancel()
                break

            # === æ’­æŠ¥æ£€æŸ¥ ===
            broadcast_interval = get_talker_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                ts = format_timestamp(current_time)

                # æ ¹æ®æ—¶é—´é€‰æ‹©æ’­æŠ¥æ¨¡æ¿
                if elapsed < 15:
                    templates = ["æ­£åœ¨å¤„ç†", "æ€è€ƒä¸­"]
                elif elapsed < 30:
                    templates = ["ä»åœ¨å¤„ç†ä¸­", "è¯·ç¨å€™"]
                else:
                    templates = ["å“åº”è¾ƒæ…¢"]  # æ¨¡æ¿ä¸å«æ—¶é—´

                # é€‰æ‹©æœªä½¿ç”¨çš„æ¨¡æ¿
                template = None
                for t in templates:
                    if t not in used_broadcast_templates:
                        template = t
                        used_broadcast_templates.add(t)
                        break

                if template is None:
                    # æ‰€æœ‰æ¨¡æ¿éƒ½ç”¨è¿‡äº†ï¼Œç”¨é»˜è®¤
                    template = "å¤„ç†ä¸­"

                # ç”Ÿæˆå®Œæ•´æ¶ˆæ¯
                if template == "å“åº”è¾ƒæ…¢":
                    msg = f"{template} ({elapsed:.0f}s)..."
                else:
                    msg = f"{template}..."

                yield f"\n[{ts}] Talker: {msg}"
                last_broadcast_time = current_time
                broadcast_count += 1

                # é™åˆ¶æœ€å¤§æ’­æŠ¥æ¬¡æ•°
                if broadcast_count >= 5:
                    break

            # å°è¯•è·å–è¾“å‡º
            try:
                chunk = await asyncio.wait_for(talker_queue.get(), timeout=0.1)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äº¤ç»™Thinker
                if "[NEEDS_THINKER]" in chunk:
                    # è®°å½•Handoff
                    self._record_handoff(
                        HandoffType.DELEGATION,
                        "talker",
                        "thinker",
                        "ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡Talkerèƒ½åŠ›",
                    )

                    # åˆ‡æ¢åˆ°åä½œæ¨¡å¼
                    async for thinker_chunk in self._collaboration_handoff(
                        user_input, context, llm_request_time, received_time=received_time
                    ):
                        yield thinker_chunk
                    return

                # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå†…å®¹çš„æ—¶é—´
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                    # åœ¨å†…å®¹å‰æ˜¾ç¤ºTalkeræ—¶é—´æˆ³
                    if settings.SHOW_AGENT_IDENTITY and not first_timestamp_shown:
                        yield f"\n[{format_timestamp(first_token_time)}] Talker: "
                        first_timestamp_shown = True

                yield chunk

            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯æ£€æŸ¥æ’­æŠ¥
                continue

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, llm_request_time, first_token_time)

    def _format_metrics(self, metrics: dict, llm_request_time: float, first_token_time: float = None) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        lines = ["-" * 50]
        lines.append("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")

        # Tokenç»Ÿè®¡
        input_tokens = metrics.get("input_tokens", 0)
        output_tokens = metrics.get("output_tokens", 0)
        if input_tokens or output_tokens:
            lines.append(f"  Tokens: è¾“å…¥={input_tokens} | è¾“å‡º={output_tokens}")

        # æ—¶å»¶æŒ‡æ ‡
        ttft = metrics.get("ttft_ms", 0)
        tpot = metrics.get("tpot_ms", 0)
        total_time = metrics.get("total_time_ms", 0)

        if ttft:
            lines.append(f"  TTFT(é¦–Tokenå“åº”æ—¶å»¶): {ttft:.0f}ms")
        if total_time:
            lines.append(f"  å“åº”æ—¶å»¶(ç”Ÿæˆæ€»è€—æ—¶): {total_time:.0f}ms")
        if tpot:
            lines.append(f"  TPOT(å¹³å‡æ¯Tokenæ—¶å»¶): {tpot:.1f}ms")

        # TPSåå
        tps = metrics.get("tps", 0)
        if tps:
            lines.append(f"  TPS(æ¨¡å‹åå): {tps:.1f} tokens/s")

        # æ—¶é—´æˆ³
        lines.append(f"  LLMè¯·æ±‚å‘é€æ—¶é—´: {format_timestamp(llm_request_time)}")
        if first_token_time:
            lines.append(f"  LLMé¦–Tokenæ—¶é—´: {format_timestamp(first_token_time)}")
        lines.append("-" * 50)

        return "\n".join(lines)

    async def _collaboration_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        llm_request_time: float = None,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        åä½œæ¨¡å¼Handoff

        Talkeræ”¶é›†ä¿¡æ¯ï¼ŒThinkeræ·±åº¦å¤„ç†ï¼ŒTalkeræ’­æŠ¥
        å…³é”®æ”¹è¿›ï¼šç‹¬ç«‹äºThinkerè¾“å‡ºé¢‘ç‡è¿›è¡Œå®šæ—¶æ’­æŠ¥
        """
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        thinker_start = time.time()
        if llm_request_time is None:
            llm_request_time = thinker_start

        # é‡ç½®è¿›åº¦çŠ¶æ€
        self._progress_state = ProgressState()
        self._progress_state.last_stage_change = thinker_start
        self._progress_state.last_broadcast = thinker_start - 3  # å…è®¸ç«‹å³æ’­æŠ¥

        # è·å–å…±äº«ä¸Šä¸‹æ–‡
        shared = context.get("shared")

        # ç¡®ä¿Thinkeræœ‰å…±äº«ä¸Šä¸‹æ–‡çš„å¼•ç”¨
        if shared:
            self.thinker.set_shared_context(shared)

        # Talkeré¦–å…ˆç»™ç”¨æˆ·åé¦ˆ
        if settings.SHOW_AGENT_IDENTITY:
            timestamp = format_timestamp(thinker_start)
            yield f"\n[{timestamp}] Talker: å¥½çš„ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦æ·±åº¦æ€è€ƒï¼Œå·²è½¬äº¤ç»™æ·±åº¦æ€è€ƒæ¨¡å—å¤„ç†"

        # === æ¾„æ¸…æœºåˆ¶ï¼šæ£€æµ‹æ˜¯å¦éœ€è¦æ¾„æ¸…ï¼ˆå¸¦ä¸»åŠ¨æ’­æŠ¥ï¼‰ ===
        async def run_precheck():
            quick_plan = await self.thinker.plan_task(user_input, context)
            needs_clarification, reason, missing_info = await self.thinker.needs_clarification(
                user_input, quick_plan, context
            )
            question = None
            if needs_clarification and missing_info and shared:
                question = await self.thinker.generate_clarification_question(
                    user_input, missing_info, context
                )
            return quick_plan, needs_clarification, reason, missing_info, question

        precheck_task = asyncio.create_task(run_precheck())
        precheck_last_broadcast = thinker_start
        # é¢„æ£€æŸ¥é˜¶æ®µæ’­æŠ¥æ¨¡æ¿ï¼ˆæœ‰é™é›†åˆï¼ŒæŒ‰é¡ºåºä½¿ç”¨ï¼‰
        precheck_templates = ["æ­£åœ¨åˆ†æå…³é”®ä¿¡æ¯", "æ­£åœ¨æ ¸å¯¹å¿…è¦æ¡ä»¶", "å³å°†è¿›å…¥è¯¦ç»†æ¨ç†"]
        precheck_idx = 0
        last_precheck_template = ""
        precheck_timed_out = False
        precheck_first_feedback_shown = False  # ç¡®ä¿ 2 ç§’å†…æœ‰é¦–æ¬¡åé¦ˆ

        while not precheck_task.done():
            now = time.time()
            elapsed_since_start = now - thinker_start

            # è¶…æ—¶å¤„ç†
            if now - thinker_start >= self._precheck_timeout_s:
                precheck_timed_out = True
                precheck_task.cancel()
                ts = format_timestamp(now)
                timeout_msg = "é¢„åˆ†æè€—æ—¶è¾ƒé•¿ï¼Œå…ˆè¿›å…¥è¯¦ç»†å¤„ç†"
                yield f"\n[{ts}] Talker: {timeout_msg}..."
                if shared:
                    shared.add_talker_interaction(timeout_msg, "broadcast")
                break

            # ç¡®ä¿ 2 ç§’å†…æœ‰é¦–æ¬¡åé¦ˆï¼ˆSLAï¼‰
            if not precheck_first_feedback_shown and elapsed_since_start >= 2.0:
                ts = format_timestamp(now)
                yield f"\n[{ts}] Talker: æ­£åœ¨åŒæ­¥ä¸Šä¸‹æ–‡å¹¶è§„åˆ’æ­¥éª¤ï¼Œè¯·ç¨å€™..."
                if shared:
                    shared.add_talker_interaction("æ­£åœ¨åŒæ­¥ä¸Šä¸‹æ–‡å¹¶è§„åˆ’æ­¥éª¤", "broadcast")
                precheck_first_feedback_shown = True
                precheck_last_broadcast = now
                continue

            # å¸¸è§„æ’­æŠ¥ï¼ˆ5 ç§’é—´éš”ï¼‰
            if now - precheck_last_broadcast >= 5.0:
                if precheck_idx < len(precheck_templates):
                    msg = precheck_templates[precheck_idx]
                    msg_template = f"precheck_{precheck_idx}"
                else:
                    elapsed = int(now - thinker_start)
                    msg = f"é¢„åˆ†æè¿›è¡Œä¸­ï¼ˆ{elapsed}sï¼‰"
                    msg_template = f"precheck_elapsed_{elapsed // 10}"
                if msg_template != last_precheck_template:
                    ts = format_timestamp(now)
                    yield f"\n[{ts}] Talker: {msg}..."
                    if shared:
                        shared.add_talker_interaction(msg, "broadcast")
                    last_precheck_template = msg_template
                precheck_last_broadcast = now
                precheck_idx += 1
            await asyncio.sleep(0.1)

        quick_plan = None
        try:
            if not precheck_timed_out:
                quick_plan, needs_clarification, reason, missing_info, question = await precheck_task
                if not needs_clarification and quick_plan and getattr(quick_plan, "steps", None):
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Talker: æ·±åº¦æ€è€ƒæ¨¡å—å·²å®Œæˆè§„åˆ’ï¼Œé¢„è®¡{len(quick_plan.steps)}æ­¥æ‰§è¡Œ"
                if needs_clarification and missing_info and shared and question:
                    ts = format_timestamp(time.time())
                    yield f"\n[{ts}] Talker: {question}"
                    shared.add_talker_interaction(question, "clarification")
                    shared.add_clarification_request(question, reason or "", [])
                    shared.clarification_status = ClarificationStatus.PENDING
                    return
        except asyncio.CancelledError:
            pass
        except Exception:
            pass

        # è®°å½•Handoffåˆ°Thinker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "talker",
            "thinker",
            "å¯åŠ¨åä½œæ¨¡å¼",
        )

        # Thinker å¼€å§‹å·¥ä½œçš„æç¤º - ç”± Talker æ’­æŠ¥ï¼Œåç»­åŠ«æŒæœºåˆ¶ä¼šå¤„ç†

        # æ”¶é›†Thinkerçš„è¾“å‡º
        thinker_output = []
        thinker_complete = False
        accumulated_output = ""
        thinker_first_token_shown = False
        # æ ‡è®°ï¼šprecheck è¶…æ—¶åå·²æ’­æŠ¥ï¼Œé¿å…ä¸ Thinker åŠ«æŒè¾“å‡ºé‡å¤
        precheck_timeout_broadcast = precheck_timed_out

        # æ’­æŠ¥æ§åˆ¶ - ä½¿ç”¨ç‹¬ç«‹çš„æ—¶é—´æ£€æŸ¥ï¼ˆåŠ¨æ€é—´éš”ï¼‰
        last_broadcast_time = thinker_start

        def get_broadcast_interval(elapsed: float) -> float:
            """æ ¹æ®å·²è€—æ—¶åŠ¨æ€è®¡ç®—æ’­æŠ¥é—´éš” - æ›´ä¿å®ˆ"""
            if elapsed < 15:
                return 4.0  # åˆå§‹4ç§’
            elif elapsed < 30:
                return 6.0  # ä¸­æœŸ6ç§’
            else:
                return 8.0  # åæœŸ8ç§’
        output_index = 0

        async def run_thinker():
            """è¿è¡ŒThinkerå¹¶æ”¶é›†è¾“å‡º"""
            nonlocal thinker_complete
            try:
                async for chunk in self.thinker.process(user_input, context):
                    thinker_output.append(chunk)
            except Exception as e:
                logger.error(f"Thinker task error: {e}")
            finally:
                thinker_complete = True

        # å¯åŠ¨Thinkerä»»åŠ¡
        thinker_task = asyncio.create_task(run_thinker())
        THINKER_TIMEOUT = 300.0  # 300 ç§’è¶…æ—¶

        # ä¸»å¾ªç¯ï¼šå¤„ç†Thinkerè¾“å‡ºå’Œæ’­æŠ¥
        # æ·»åŠ è¶…æ—¶ä¿æŠ¤å˜é‡
        last_output_time = thinker_start
        max_wait_time = 30.0  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        # å¾ªç¯ä¿æŠ¤ï¼šé˜²æ­¢æ— é™å¾ªç¯
        loop_iteration_count = 0
        max_loop_iterations = 10000  # æœ€å¤§å¾ªç¯æ¬¡æ•°

        while not thinker_complete or output_index < len(thinker_output):
            loop_iteration_count += 1

            # å¾ªç¯æ¬¡æ•°ä¿æŠ¤
            if loop_iteration_count > max_loop_iterations:
                logger.warning(f"Loop exceeded {max_loop_iterations} iterations, breaking")
                break

            current_time = time.time()
            elapsed = current_time - thinker_start
            
            # è¶…æ—¶ä¿æŠ¤ 1: æ•´ä½“ä»»åŠ¡è¶…æ—¶
            if elapsed > THINKER_TIMEOUT:
                logger.warning(f"Thinker task timeout ({THINKER_TIMEOUT}s), cancelling...")
                thinker_task.cancel()
                break
            
            # è¶…æ—¶ä¿æŠ¤ 2: Thinker å·²å®Œæˆä½†è¾“å‡ºå¤„ç†å¡ä½
            if thinker_complete and current_time - last_output_time > max_wait_time:
                logger.warning(f"Thinker output processing timeout ({max_wait_time}s), breaking loop...")
                break

            # === æ’­æŠ¥æ£€æŸ¥ ===
            broadcast_interval = get_broadcast_interval(elapsed)
            if current_time - last_broadcast_time >= broadcast_interval:
                # ä¼˜å…ˆä½¿ç”¨SharedContextä¸­çš„å®æ—¶è¿›åº¦ï¼Œå›é€€åˆ°è¾“å‡ºè§£æ
                if shared and shared.thinker_progress.current_stage != "idle":
                    new_stage = self._stage_from_shared_progress(shared.thinker_progress.current_stage)
                    current_step = shared.thinker_progress.current_step
                    total_steps = shared.thinker_progress.total_steps
                    step_desc = self._latest_shared_step_desc(shared)
                else:
                    new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’­æŠ¥
                content_hash = f"{new_stage.value}:{current_step}:{total_steps}:{step_desc[:20]}"
                should_broadcast, reason = self._should_broadcast(
                    new_stage,
                    current_step,
                    elapsed,
                    content_hash,
                )

                if should_broadcast:
                    # ç”Ÿæˆæ’­æŠ¥æ¶ˆæ¯å’Œæ¨¡æ¿
                    if reason == "heartbeat":
                        # åŸºäºçœŸå®è¿›åº¦ç”Ÿæˆæ’­æŠ¥ï¼Œè€Œä¸æ˜¯æœºæ¢°çš„"ä»åœ¨ xx é˜¶æ®µ"
                        stage_zh = {
                            ThinkerStage.ANALYZING: "åˆ†æ",
                            ThinkerStage.PLANNING: "è§„åˆ’",
                            ThinkerStage.EXECUTING: "æ‰§è¡Œ",
                            ThinkerStage.SYNTHESIZING: "æ•´åˆ",
                            ThinkerStage.IDLE: "å‡†å¤‡",
                            ThinkerStage.COMPLETED: "æ”¶å°¾",
                        }.get(new_stage, "å¤„ç†")

                        # ä¼˜å…ˆæ˜¾ç¤ºè¯¦ç»†è¿›åº¦ä¿¡æ¯ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
                        if total_steps > 0 and current_step > 0:
                            progress_pct = int((current_step / total_steps) * 100)
                            progress_bar = self._format_progress_bar(current_step, total_steps)
                            if step_desc:
                                # æœ‰æ­¥éª¤æè¿°ï¼šæ˜¾ç¤ºå…·ä½“æ­¥éª¤ä¿¡æ¯ + è¿›åº¦æ¡
                                broadcast_msg = f"æ­¥éª¤{current_step}/{total_steps}: {step_desc} {progress_bar}"
                                msg_template = f"step_{current_step}_{total_steps}"
                            else:
                                # æ— æ­¥éª¤æè¿°ï¼šæ˜¾ç¤ºè¿›åº¦æ¡
                                broadcast_msg = f"æ‰§è¡Œä¸­ {progress_bar}ï¼ˆ{current_step}/{total_steps} æ­¥ï¼‰"
                                msg_template = f"progress_{current_step}_{total_steps}"
                        elif shared and shared.thinker_progress.partial_results:
                            # æœ‰ä¸­é—´ç»“æœï¼šæ˜¾ç¤ºæœ€æ–°ç»“æœ
                            latest = shared.thinker_progress.partial_results[-1]
                            if latest and len(latest) < 50:
                                broadcast_msg = f"{stage_zh}ä¸­ï¼š{latest}"
                                msg_template = f"result_{hash(latest) % 1000}"
                            else:
                                # æœ‰ä¸­é—´ç»“æœä½†å¤ªé•¿ï¼Œæ˜¾ç¤ºæ—¶é—´ + å®‰æŠš
                                user_complaint = shared and shared.get_user_emotion() == "complaint"
                                suffix = self._get_emotional_broadcast_suffix(elapsed, user_complaint=user_complaint)
                                broadcast_msg = f"ä»åœ¨{stage_zh}é˜¶æ®µï¼ˆ{elapsed:.0f}sï¼‰{suffix}"
                                msg_template = f"heartbeat_{new_stage.value}_{int(elapsed // 15)}"
                        else:
                            # é™çº§ï¼šæ˜¾ç¤ºæ—¶é—´å’Œé˜¶æ®µ + å®‰æŠš
                            user_complaint = shared and shared.get_user_emotion() == "complaint"
                            suffix = self._get_emotional_broadcast_suffix(elapsed, user_complaint=user_complaint)
                            broadcast_msg = f"ä»åœ¨{stage_zh}é˜¶æ®µï¼ˆ{elapsed:.0f}sï¼‰{suffix}"
                            msg_template = f"heartbeat_{new_stage.value}_{int(elapsed // 15)}"
                    else:
                        # ä»å…±äº«ä¸Šä¸‹æ–‡è·å–ä¸­é—´ç»“æœ
                        partials = shared.thinker_progress.partial_results if shared else []
                        broadcast_msg, msg_template = self._generate_stage_broadcast(
                            stage=new_stage,
                            user_query=user_input,
                            elapsed_time=elapsed,
                            current_step=current_step,
                            total_steps=total_steps,
                            step_desc=step_desc,
                            partial_results=partials,
                        )

                    # åŸºäºæ¨¡æ¿å»é‡ï¼ˆä¸æ˜¯å®Œæ•´æ¶ˆæ¯ï¼‰
                    if msg_template != self._progress_state.last_broadcast_msg_template:
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Talker: {broadcast_msg}"
                        if shared:
                            shared.add_talker_interaction(broadcast_msg, "broadcast")
                        self._progress_state.last_broadcast = current_time
                        self._progress_state.last_broadcast_msg_template = msg_template
                        self._progress_state.broadcast_count += 1

                    # æ›´æ–°çŠ¶æ€
                    if new_stage != self._progress_state.current_stage:
                        self._progress_state.current_stage = new_stage
                        self._progress_state.last_stage_change = current_time
                        # é˜¶æ®µå˜åŒ–æ—¶é‡ç½®æ¨¡æ¿é›†åˆ
                        self._progress_state.used_message_templates = {}
                    self._progress_state.current_step = current_step
                    self._progress_state.total_steps = total_steps
                    self._progress_state.last_content_hash = content_hash

                last_broadcast_time = current_time

            # === å¤„ç†Thinkerè¾“å‡º ===
            if output_index < len(thinker_output):
                chunk = thinker_output[output_index]
                output_index += 1
                accumulated_output += chunk
                last_output_time = current_time  # æ›´æ–°æœ€åè¾“å‡ºæ—¶é—´

                # è§£æé˜¶æ®µï¼ˆç”¨äºçŠ¶æ€æ›´æ–°ï¼‰
                if shared and shared.thinker_progress.current_stage != "idle":
                    new_stage = self._stage_from_shared_progress(shared.thinker_progress.current_stage)
                    current_step = shared.thinker_progress.current_step
                    total_steps = shared.thinker_progress.total_steps
                    step_desc = self._latest_shared_step_desc(shared)
                else:
                    new_stage, current_step, total_steps, step_desc = self._parse_thinker_stage(accumulated_output)

                # æ›´æ–°çŠ¶æ€
                if new_stage != self._progress_state.current_stage:
                    self._progress_state.current_stage = new_stage
                    self._progress_state.last_stage_change = current_time
                self._progress_state.current_step = current_step
                self._progress_state.total_steps = total_steps
                self._progress_state.last_content_hash = f"{new_stage.value}:{current_step}:{total_steps}:{step_desc[:20]}"

                # === Thinker è¾“å‡ºåŠ«æŒï¼šTalker é‡æ–°ç»„ç»‡è¯­è¨€ ===
                # æ£€æµ‹ Thinker çš„é˜¶æ®µæ ‡è®°è¾“å‡ºï¼Œç”± Talker é‡æ–°ç»„ç»‡åæ˜¾ç¤º
                if chunk.strip():
                    talker_rewrite = self._try_rewrite_thinker_output(
                        chunk, new_stage, current_step, total_steps, step_desc, elapsed
                    )
                    if talker_rewrite:
                        # é¿å…é‡å¤æ’­æŠ¥ï¼šå¦‚æœ precheck è¶…æ—¶å·²æ’­æŠ¥"å…ˆè¿›å…¥è¯¦ç»†å¤„ç†"ï¼Œ
                        # ä¸” Thinker è¾“å‡ºæ˜¯"å¼€å§‹å¤„ç†"ï¼Œåˆ™è·³è¿‡åŠ«æŒï¼ˆé™é»˜å¤„ç†ï¼‰
                        if precheck_timeout_broadcast and "Thinker å·²å¯åŠ¨" in talker_rewrite:
                            # é™é»˜å¤„ç†ï¼Œä¸é‡å¤æ’­æŠ¥ï¼Œä½†é‡ç½® heartbeat è®¡æ—¶å™¨
                            last_broadcast_time = current_time
                            continue

                        # è¯­ä¹‰å»é‡æ£€æŸ¥ï¼šå¦‚æœä¸æœ€è¿‘æ’­æŠ¥é‡å¤ï¼Œåˆ™è·³è¿‡
                        if self._is_semantic_duplicate(talker_rewrite):
                            # è·³è¿‡æ’­æŠ¥ï¼Œä½†é‡ç½®è®¡æ—¶å™¨
                            last_broadcast_time = current_time
                            continue

                        # Talker åŠ«æŒè¾“å‡ºï¼Œé‡æ–°ç»„ç»‡è¯­è¨€
                        # é‡ç½® heartbeat è®¡æ—¶å™¨ï¼Œé¿å…é‡å¤æ’­æŠ¥
                        last_broadcast_time = current_time

                        # æ¯ä¸ªé˜¶æ®µæ ‡è®°éƒ½ä½œä¸ºç‹¬ç«‹çš„æ¶ˆæ¯æ˜¾ç¤ºï¼Œå¸¦æœ‰è‡ªå·±çš„æ—¶é—´æˆ³å’Œ Talker å‰ç¼€
                        ts = format_timestamp(current_time)
                        yield f"\n[{ts}] Talker: {talker_rewrite}"
                    else:
                        # éé˜¶æ®µæ ‡è®°è¾“å‡ºï¼Œä½¿ç”¨ Talker é£æ ¼æ’­æŠ¥
                        # æ ¹æ®å†…å®¹åˆ¤æ–­æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                        if chunk.strip() and not chunk.startswith('[ç­”æ¡ˆ]'):
                            # æ™®é€šå†…å®¹ï¼Œä½¿ç”¨é€šç”¨çš„ Talker æ’­æŠ¥
                            ts = format_timestamp(current_time)
                            yield f"\n[{ts}] Talker: "
                            # çŸ­å†…å®¹ç›´æ¥æ˜¾ç¤ºï¼Œé•¿å†…å®¹æˆªæ–­
                            if len(chunk.strip()) > 50:
                                yield f"{chunk.strip()[:50]}..."
                            else:
                                yield chunk.strip()
                        else:
                            # ç­”æ¡ˆå†…å®¹æˆ–ç©ºå†…å®¹ï¼Œç›´æ¥æ˜¾ç¤º
                            if chunk.strip():
                                ts = format_timestamp(current_time)
                                yield f"\n[{ts}] Talker: "
                            yield chunk
            else:
                # æ²¡æœ‰æ–°è¾“å‡ºæ—¶çŸ­æš‚ç­‰å¾…
                await asyncio.sleep(0.05)

        # ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½å·²å¤„ç†
        while output_index < len(thinker_output):
            chunk = thinker_output[output_index]
            output_index += 1
            if chunk.strip():
                ts = format_timestamp(time.time())
                yield f"\n[{ts}] Talker: {chunk}"

        # è®°å½•Handoffå›Talker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "thinker",
            "talker",
            "Thinkerå¤„ç†å®Œæˆ",
        )

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, thinker_start, thinker_start)

    async def _parallel_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        å¹¶è¡Œæ¨¡å¼Handoff

        Talkerå’ŒThinkeråŒæ—¶å·¥ä½œ
        """
        # å¹¶è¡Œå¯åŠ¨
        talker_task = asyncio.create_task(
            self._collect_stream(self.talker.process(user_input, context))
        )
        thinker_task = asyncio.create_task(
            self._collect_stream(self.thinker.process(user_input, context))
        )

        # å…ˆè¿”å›Talkerçš„å¿«é€Ÿå“åº”
        talker_result = await talker_task
        yield "".join(talker_result)

        # ç­‰å¾…Thinkerå®Œæˆ
        thinker_result = await thinker_task

        # å¦‚æœThinkerçš„ç­”æ¡ˆæ›´å¥½ï¼Œè¡¥å……è¯´æ˜
        if thinker_result:
            yield "\n\nã€è¡¥å……è¯´æ˜ã€‘\n"
            yield "".join(thinker_result)

    async def _iterative_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        è¿­ä»£æ¨¡å¼Handoff

        Talkeræä¾›åˆæ­¥ç­”æ¡ˆï¼ŒThinkeræ ¹æ®ç”¨æˆ·åé¦ˆæ”¹è¿›
        """
        # Talkerå…ˆæä¾›åˆæ­¥ç­”æ¡ˆ
        yield "ã€åˆæ­¥ç­”æ¡ˆã€‘\n"
        async for chunk in self.talker.process(user_input, context):
            yield chunk

        yield "\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚"

    async def _collect_stream(self, stream: AsyncIterator[str]) -> List[str]:
        """æ”¶é›†æµå¼è¾“å‡º"""
        result = []
        async for chunk in stream:
            result.append(chunk)
        return result

    async def _get_or_create_session(self, session_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆä½¿ç”¨SessionContextæŒä¹…åŒ–ï¼‰"""
        if not await self.session_context.exists(session_id):
            await self.session_context.set_session_data(session_id, "created_at", time.time())
            await self.session_context.set_session_data(session_id, "state", "active")

        # è¿”å›å…¼å®¹æ ¼å¼
        messages = await self.session_context.get_messages(session_id, limit=100)
        return {
            "messages": [m.to_dict() for m in messages],
            "created_at": await self.session_context.get_session_data(session_id, "created_at", time.time()),
            "state": await self.session_context.get_session_data(session_id, "state", "active"),
        }

    def _get_or_create_shared_context(self, session_id: str, user_input: str = "") -> SharedContext:
        """è·å–æˆ–åˆ›å»ºå…±äº«ä¸Šä¸‹æ–‡"""
        if session_id not in self._shared_contexts:
            self._shared_contexts[session_id] = SharedContext(user_input=user_input)
        elif user_input:
            self._shared_contexts[session_id].user_input = user_input
        return self._shared_contexts[session_id]

    def get_shared_context(self, session_id: str) -> Optional[SharedContext]:
        """è·å–ä¼šè¯å…±äº«ä¸Šä¸‹æ–‡ï¼ˆåªè¯»è®¿é—®ï¼‰ã€‚"""
        return self._shared_contexts.get(session_id)

    def _record_handoff(
        self,
        handoff_type: HandoffType,
        from_agent: str,
        to_agent: str,
        reason: str,
    ) -> None:
        """è®°å½•Handoff"""
        self._stats["handoffs"] += 1
        handoff = HandoffContext(
            handoff_type=handoff_type,
            from_agent=from_agent,
            to_agent=to_agent,
            reason=reason,
        )
        self._handoff_history.append(handoff)

        # è§¦å‘å›è°ƒ
        if self._on_handoff:
            asyncio.create_task(self._on_handoff(handoff))

    async def _handle_progress(self, progress_info: Dict[str, Any]) -> None:
        """å¤„ç†è¿›åº¦æ›´æ–°"""
        if self._on_progress:
            await self._on_progress(progress_info)

    async def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        if await self.session_context.exists(session_id):
            return await self._get_or_create_session(session_id)
        return None

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "active_sessions": len(self._shared_contexts),
            "recent_handoffs": len(self._handoff_history[-10:]),
            "talker_stats": self.talker.get_stats(),
            "thinker_stats": self.thinker.get_stats(),
        }

    def get_handoff_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–Handoffå†å²"""
        return [
            {
                "type": h.handoff_type.value,
                "from": h.from_agent,
                "to": h.to_agent,
                "reason": h.reason,
                "timestamp": h.timestamp,
            }
            for h in self._handoff_history[-limit:]
        ]

    async def clear_session(self, session_id: str) -> None:
        """æ¸…é™¤ä¼šè¯"""
        await self.session_context.delete_session(session_id)
        if session_id in self._shared_contexts:
            del self._shared_contexts[session_id]

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self.talker.reset_stats()
        self.thinker.reset_stats()
