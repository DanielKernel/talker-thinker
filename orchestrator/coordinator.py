"""
Orchestrator - åè°ƒå™¨
ç®¡ç†Talkerå’ŒThinkerçš„ååŒå·¥ä½œ
"""
import asyncio
import re
import time
from dataclasses import dataclass, field
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

from config import settings
from context.types import AgentRole, HandoffType, Message, ResponseLayer, Task, TaskComplexity
from agents.talker.agent import TalkerAgent
from agents.thinker.agent import ThinkerAgent
from orchestrator.scheduler import TaskScheduler, ComplexityBasedScheduler


@dataclass
class HandoffContext:
    """Handoffä¸Šä¸‹æ–‡"""
    handoff_type: HandoffType
    from_agent: str
    to_agent: str
    reason: str
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)


class Orchestrator:
    """
    Orchestrator - åè°ƒå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. ä»»åŠ¡è°ƒåº¦å’Œè·¯ç”±
    2. Agentä¹‹é—´çš„Handoffç®¡ç†
    3. ä¸Šä¸‹æ–‡åŒæ­¥
    4. çŠ¶æ€ç»´æŠ¤
    """

    def __init__(
        self,
        talker: Optional[TalkerAgent] = None,
        thinker: Optional[ThinkerAgent] = None,
        task_scheduler: Optional[TaskScheduler] = None,
    ):
        # Agentå®ä¾‹
        self.talker = talker or TalkerAgent()
        self.thinker = thinker or ThinkerAgent()

        # è°ƒåº¦å™¨
        self.task_scheduler = task_scheduler or TaskScheduler()
        self.complexity_scheduler = ComplexityBasedScheduler()

        # ä¼šè¯çŠ¶æ€
        self._sessions: Dict[str, Dict[str, Any]] = {}
        self._handoff_history: List[HandoffContext] = []

        # å›è°ƒå‡½æ•°
        self._on_response: Optional[Callable] = None
        self._on_handoff: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None

        # è®¾ç½®è¿›åº¦å›è°ƒ
        self.talker.set_progress_callback(self._handle_progress)
        self.thinker.set_progress_callback(self._handle_progress)

        # ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }

    def set_callbacks(
        self,
        on_response: Optional[Callable] = None,
        on_handoff: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
    ) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self._on_response = on_response
        self._on_handoff = on_handoff
        self._on_progress = on_progress

    async def process(
        self,
        user_input: str,
        session_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        received_time: Optional[float] = None,
    ) -> AsyncIterator[str]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡
            received_time: æ¶ˆæ¯æ¥æ”¶æ—¶é—´

        Yields:
            str: å“åº”å†…å®¹
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        if received_time is None:
            received_time = start_time

        # åˆå§‹åŒ–ä¼šè¯
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())

        session = self._get_or_create_session(session_id)
        session["messages"].append({
            "role": "user",
            "content": user_input,
            "timestamp": time.time(),
        })

        # æ„å»ºä¸Šä¸‹æ–‡
        full_context = {
            **(context or {}),
            "session_id": session_id,
            "messages": session["messages"],
            "received_time": received_time,
        }

        # æ”¶é›†åŠ©æ‰‹å“åº”ç”¨äºä¿å­˜åˆ°ä¼šè¯
        assistant_response_chunks = []

        try:
            # ä½¿ç”¨Talkerè¿›è¡Œæ„å›¾åˆ†ç±»
            classification = await self.talker.classify_intent(user_input, full_context)

            # æ ¹æ®å¤æ‚åº¦é€‰æ‹©å¤„ç†ç­–ç•¥
            if classification.complexity == TaskComplexity.COMPLEX:
                # å¤æ‚ä»»åŠ¡ï¼šä½¿ç”¨åä½œæ¨¡å¼
                self._stats["thinker_handled"] += 1
                async for chunk in self._collaboration_handoff(
                    user_input, full_context, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk
            else:
                # ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼šTalkerå¤„ç†
                self._stats["talker_handled"] += 1
                async for chunk in self._delegation_handoff(
                    user_input, full_context, classification, received_time=received_time
                ):
                    assistant_response_chunks.append(chunk)
                    yield chunk

        except Exception as e:
            self._stats["errors"] += 1
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            assistant_response_chunks.append(error_msg)
            yield error_msg

        finally:
            # ä¿å­˜åŠ©æ‰‹å“åº”åˆ°ä¼šè¯ï¼ˆæ¸…ç†æ‰å…ƒæ•°æ®æ ‡è®°ï¼‰
            assistant_response = "".join(assistant_response_chunks)
            # ç§»é™¤æ—¶é—´æˆ³å’ŒAgentæ ‡è¯†ç­‰å…ƒæ•°æ®ï¼Œåªä¿ç•™å®é™…å›å¤å†…å®¹
            # ç§»é™¤ç±»ä¼¼ [Talker | ç®€å•ä»»åŠ¡] çš„æ ‡è®°
            clean_response = re.sub(r'\[Talker[^\]]*\]\s*', '', assistant_response)
            # ç§»é™¤ç±»ä¼¼ [Thinker | LLMè¯·æ±‚: ...] çš„æ ‡è®°
            clean_response = re.sub(r'\[Thinker[^\]]*\]\s*', '', clean_response)
            # ç§»é™¤ç±»ä¼¼ [LLMè¯·æ±‚: ...] çš„æ ‡è®°
            clean_response = re.sub(r'\[LLMè¯·æ±‚: [^\]]+\]\s*', '', clean_response)
            # ç§»é™¤æ€§èƒ½æŒ‡æ ‡åŒºå—ï¼ˆåŒ…å«ğŸ“Šç¬¦å·çš„éƒ¨åˆ†ï¼‰
            clean_response = re.sub(r'\n-{10,}.*?-{10,}', '', clean_response, flags=re.DOTALL)
            # ç§»é™¤å‰©ä½™çš„æŒ‡æ ‡è¡Œ
            clean_response = re.sub(r'\n\s*ğŸ“Š[^\n]*', '', clean_response)
            clean_response = re.sub(r'\n\s*(Tokens|TTFT|TPOT|TPS|æ€»ç”Ÿæˆæ—¶å»¶|LLMè¯·æ±‚æ—¶é—´)[^\n]*', '', clean_response)
            clean_response = clean_response.strip()

            if clean_response:
                session["messages"].append({
                    "role": "assistant",
                    "content": clean_response,
                    "timestamp": time.time(),
                })

            elapsed = (time.time() - start_time) * 1000
            session["last_latency_ms"] = elapsed

    async def _delegation_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        classification,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        å§”æ‰˜æ¨¡å¼Handoff

        Talkerå¤„ç†ç®€å•/ä¸­ç­‰ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å§”æ‰˜ç»™Thinker
        """
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        # æ˜¾ç¤ºAgentèº«ä»½æ ‡è¯†
        if settings.SHOW_AGENT_IDENTITY:
            complexity_str = {
                TaskComplexity.SIMPLE: "ç®€å•",
                TaskComplexity.MEDIUM: "ä¸­ç­‰",
                TaskComplexity.COMPLEX: "å¤æ‚",
            }.get(classification.complexity, "æœªçŸ¥")
            yield f"[Talker | {complexity_str}ä»»åŠ¡]\n"

        # è®°å½•LLMè¯·æ±‚å‘é€æ—¶é—´
        llm_request_time = time.time()
        if settings.SHOW_AGENT_IDENTITY:
            yield f"[LLMè¯·æ±‚: {format_timestamp(llm_request_time)}]\n"

        # è¶…æ—¶æ£€æµ‹ï¼šå¦‚æœTTFTè¶…è¿‡2ç§’ï¼Œæç¤ºç”¨æˆ·
        first_chunk_time = None
        chunk_count = 0
        should_handoff = False

        async for chunk in self.talker.process(user_input, context):
            chunk_count += 1

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬äº¤ç»™Thinker
            if "[NEEDS_THINKER]" in chunk:
                # è®°å½•Handoff
                self._record_handoff(
                    HandoffType.DELEGATION,
                    "talker",
                    "thinker",
                    "ä»»åŠ¡å¤æ‚åº¦è¶…è¿‡Talkerèƒ½åŠ›",
                )

                # åˆ‡æ¢åˆ°åä½œæ¨¡å¼
                async for thinker_chunk in self._collaboration_handoff(
                    user_input, context, llm_request_time, received_time=received_time
                ):
                    yield thinker_chunk
                return

            # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå†…å®¹çš„æ—¶é—´
            if first_chunk_time is None and chunk.strip() and "æ”¶åˆ°" not in chunk and "å¥½çš„" not in chunk:
                first_chunk_time = time.time()
                # å¦‚æœTTFTè¶…è¿‡2ç§’ï¼Œè­¦å‘Šå¹¶è€ƒè™‘è½¬äº¤
                ttft = (first_chunk_time - llm_request_time) * 1000
                if ttft > 2000 and settings.SHOW_AGENT_IDENTITY:
                    yield f"\n[âš ï¸ å“åº”è¾ƒæ…¢({ttft:.0f}ms)ï¼Œå»ºè®®æ­¤ç±»ä»»åŠ¡äº¤ç”±Thinkerå¤„ç†]\n"

            yield chunk

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, llm_request_time)

    def _format_metrics(self, metrics: dict, llm_request_time: float) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        lines = ["-" * 50]
        lines.append("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")

        # Tokenç»Ÿè®¡
        input_tokens = metrics.get("input_tokens", 0)
        output_tokens = metrics.get("output_tokens", 0)
        if input_tokens or output_tokens:
            lines.append(f"  Tokens: è¾“å…¥={input_tokens} | è¾“å‡º={output_tokens}")

        # æ—¶å»¶æŒ‡æ ‡
        ttft = metrics.get("ttft_ms", 0)
        tpot = metrics.get("tpot_ms", 0)
        total_time = metrics.get("total_time_ms", 0)

        if ttft:
            lines.append(f"  TTFT(é¦–Tokenå“åº”æ—¶å»¶): {ttft:.0f}ms")
        if total_time:
            lines.append(f"  å“åº”æ—¶å»¶(ç”Ÿæˆæ€»è€—æ—¶): {total_time:.0f}ms")
        if tpot:
            lines.append(f"  TPOT(å¹³å‡æ¯Tokenæ—¶å»¶): {tpot:.1f}ms")

        # TPSåå
        tps = metrics.get("tps", 0)
        if tps:
            lines.append(f"  TPS(æ¨¡å‹åå): {tps:.1f} tokens/s")

        lines.append(f"  LLMè¯·æ±‚å‘é€æ—¶é—´: {format_timestamp(llm_request_time)}")
        lines.append("-" * 50)

        return "\n".join(lines)

    async def _collaboration_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
        llm_request_time: float = None,
        received_time: float = None,
    ) -> AsyncIterator[str]:
        """
        åä½œæ¨¡å¼Handoff

        Talkeræ”¶é›†ä¿¡æ¯ï¼ŒThinkeræ·±åº¦å¤„ç†ï¼ŒTalkeræ’­æŠ¥
        """
        def format_timestamp(t):
            ts = time.strftime("%H:%M:%S", time.localtime(t))
            ms = int((t % 1) * 1000)
            return f"{ts}.{ms:03d}"

        thinker_start = time.time()
        if llm_request_time is None:
            llm_request_time = thinker_start

        # Talkeré¦–å…ˆç»™ç”¨æˆ·åé¦ˆ
        if settings.SHOW_AGENT_IDENTITY:
            yield "[Talker -> Thinker | å¤æ‚ä»»åŠ¡è½¬äº¤]\n"
        yield "å¥½çš„ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦æˆ‘æ·±åº¦æ€è€ƒä¸€ä¸‹...\n\n"

        # è®°å½•Handoffåˆ°Thinker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "talker",
            "thinker",
            "å¯åŠ¨åä½œæ¨¡å¼",
        )

        # æ˜¾ç¤ºThinkerèº«ä»½æ ‡è¯†å’ŒLLMè¯·æ±‚æ—¶é—´
        if settings.SHOW_AGENT_IDENTITY:
            yield f"[Thinker | LLMè¯·æ±‚: {format_timestamp(thinker_start)}]\n"

        # æ”¶é›†Thinkerçš„è¾“å‡º
        thinker_output = []
        async for chunk in self.thinker.process(user_input, context):
            thinker_output.append(chunk)
            yield chunk

        # å®Œæ•´çš„Thinkerè¾“å‡º
        full_output = "".join(thinker_output)

        # è®°å½•Handoffå›Talker
        self._record_handoff(
            HandoffType.COLLABORATION,
            "thinker",
            "talker",
            "Thinkerå¤„ç†å®Œæˆ",
        )

        # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
        if settings.SHOW_AGENT_IDENTITY:
            metrics = context.get("_llm_metrics", {}) if context else {}
            yield "\n" + self._format_metrics(metrics, thinker_start)

    async def _parallel_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        å¹¶è¡Œæ¨¡å¼Handoff

        Talkerå’ŒThinkeråŒæ—¶å·¥ä½œ
        """
        # å¹¶è¡Œå¯åŠ¨
        talker_task = asyncio.create_task(
            self._collect_stream(self.talker.process(user_input, context))
        )
        thinker_task = asyncio.create_task(
            self._collect_stream(self.thinker.process(user_input, context))
        )

        # å…ˆè¿”å›Talkerçš„å¿«é€Ÿå“åº”
        talker_result = await talker_task
        yield "".join(talker_result)

        # ç­‰å¾…Thinkerå®Œæˆ
        thinker_result = await thinker_task

        # å¦‚æœThinkerçš„ç­”æ¡ˆæ›´å¥½ï¼Œè¡¥å……è¯´æ˜
        if thinker_result:
            yield "\n\nã€è¡¥å……è¯´æ˜ã€‘\n"
            yield "".join(thinker_result)

    async def _iterative_handoff(
        self,
        user_input: str,
        context: Dict[str, Any],
    ) -> AsyncIterator[str]:
        """
        è¿­ä»£æ¨¡å¼Handoff

        Talkeræä¾›åˆæ­¥ç­”æ¡ˆï¼ŒThinkeræ ¹æ®ç”¨æˆ·åé¦ˆæ”¹è¿›
        """
        # Talkerå…ˆæä¾›åˆæ­¥ç­”æ¡ˆ
        yield "ã€åˆæ­¥ç­”æ¡ˆã€‘\n"
        async for chunk in self.talker.process(user_input, context):
            yield chunk

        yield "\n\nå¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚"

    async def _collect_stream(self, stream: AsyncIterator[str]) -> List[str]:
        """æ”¶é›†æµå¼è¾“å‡º"""
        result = []
        async for chunk in stream:
            result.append(chunk)
        return result

    def _get_or_create_session(self, session_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id not in self._sessions:
            self._sessions[session_id] = {
                "messages": [],
                "created_at": time.time(),
                "state": "active",
            }
        return self._sessions[session_id]

    def _record_handoff(
        self,
        handoff_type: HandoffType,
        from_agent: str,
        to_agent: str,
        reason: str,
    ) -> None:
        """è®°å½•Handoff"""
        self._stats["handoffs"] += 1
        handoff = HandoffContext(
            handoff_type=handoff_type,
            from_agent=from_agent,
            to_agent=to_agent,
            reason=reason,
        )
        self._handoff_history.append(handoff)

        # è§¦å‘å›è°ƒ
        if self._on_handoff:
            asyncio.create_task(self._on_handoff(handoff))

    async def _handle_progress(self, progress_info: Dict[str, Any]) -> None:
        """å¤„ç†è¿›åº¦æ›´æ–°"""
        if self._on_progress:
            await self._on_progress(progress_info)

    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        return self._sessions.get(session_id)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self._stats,
            "active_sessions": len(self._sessions),
            "recent_handoffs": len(self._handoff_history[-10:]),
            "talker_stats": self.talker.get_stats(),
            "thinker_stats": self.thinker.get_stats(),
        }

    def get_handoff_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """è·å–Handoffå†å²"""
        return [
            {
                "type": h.handoff_type.value,
                "from": h.from_agent,
                "to": h.to_agent,
                "reason": h.reason,
                "timestamp": h.timestamp,
            }
            for h in self._handoff_history[-limit:]
        ]

    def clear_session(self, session_id: str) -> None:
        """æ¸…é™¤ä¼šè¯"""
        if session_id in self._sessions:
            del self._sessions[session_id]

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self._stats = {
            "total_requests": 0,
            "talker_handled": 0,
            "thinker_handled": 0,
            "handoffs": 0,
            "errors": 0,
        }
        self.talker.reset_stats()
        self.thinker.reset_stats()
